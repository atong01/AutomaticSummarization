<article title='Control_theory'><paragraph><template><target>About</target><arg>control theory in engineering</arg><arg>control theory in linguistics</arg><arg>control (linguistics)</arg><arg>control theory in psychology and sociology</arg><arg>control theory (sociology)</arg><arg>and</arg><arg>Perceptual control theory</arg></template><template><target>more footnotes</target><arg name="date">November 2014</arg></template></paragraph><paragraph><link><target>File:Feedback loop with descriptions.svg</target><part>thumb</part><part>right</part><part>400px</part><part>The concept of the feedback loop to control the dynamic behavior of the system: this is negative feedback, because the sensed value is subtracted from the desired value to create the error signal, which is amplified by the controller.</part></link></paragraph><paragraph><bold>Control theory</bold><space/>is an interdisciplinary branch of engineering and<space/><link><target>mathematics</target></link><space/>that deals with the behavior of<space/><link><target>dynamical system</target><trail>s</trail></link><space/>with inputs, and how their behavior is modified by<space/><link><target>feedback</target></link>. The usual objective of control theory is to control a system, often called the<space/><italics><link><target>Plant (control theory)</target><part>plant</part></link></italics>, so its output follows a desired control signal, called the<space/><italics><link><target>reference</target></link></italics>, which may be a fixed or changing value. To do this a<space/><italics><link><target>Controller (control theory)</target><part>controller</part></link></italics><space/>is designed, which monitors the output and compares it with the reference. The difference between actual and desired output, called the<space/><italics>error</italics><space/>signal, is applied as<space/><link><target>feedback</target></link><space/>to the input of the system, to bring the actual output closer to the reference. Some topics studied in control theory are<space/><link><target>Stability theory</target><part>stability</part></link><space/>(whether the output will converge to the reference value or oscillate about it),<space/><link><target>controllability</target></link><space/>and<space/><link><target>observability</target></link>.</paragraph><paragraph>Extensive use is usually made of a diagrammatic style known as the<space/><link><target>block diagram</target></link>. The<space/><link><target>transfer function</target></link>, also known as the system function or network function, is a mathematical representation of the relation between the input and output based on the<space/><link><target>differential equation</target><trail>s</trail></link><space/>describing the system.</paragraph><paragraph>Although a major application of control theory is in<space/><link><target>control systems engineering</target></link>, which deals with the design of<space/><link><target>process control</target></link><space/>systems for industry, other applications range far beyond this. As the general theory of<space/><link><target>feedback</target></link><space/>systems, control theory is useful wherever feedback occurs. A few examples are in<space/><link><target>physiology</target></link>,<space/><link><target>electronics</target></link>,<space/><link><target>climate model</target><trail>ing</trail></link>,<space/><link><target>machine design</target></link>,<space/><link><target>ecosystem</target><trail>s</trail></link>,<space/><link><target>navigation</target></link>,<space/><link><target>neural network</target><trail>s</trail></link>,<space/><link><target>predator-prey interaction</target></link>,<space/><link><target>gene expression</target></link>, and<space/><link><target>production theory</target></link>.<extension extension_name='ref'><template><target>cite journal</target><arg name="last1">Antunes</arg><arg name="first1">Ricardo</arg><arg name="last2">Gonzalez</arg><arg name="first2">Vicente</arg><arg name="title">A Production Model for Construction: A Theoretical Framework</arg><arg name="journal">Buildings</arg><arg name="date">3 March 2015</arg><arg name="volume">5</arg><arg name="issue">1</arg><arg name="pages">209â€“228</arg><arg name="doi">10.3390/buildings5010209</arg></template></extension></paragraph><heading level='2'>Overview</heading><paragraph><link><target>File:Smooth nonlinear trajectory planning control on a dual pendula system.png</target><part>thumbnail</part><part>Smooth nonlinear trajectory planning with linear quadratic Gaussian feedback (LQR) control on a dual pendula system.</part></link></paragraph><paragraph>Control theory is</paragraph><list type='bullet'><listitem>a theory that deals with influencing the behavior of<space/><link><target>dynamical system</target><trail>s</trail></link></listitem><listitem>an interdisciplinary subfield of science, which originated in<space/><link><target>engineering</target></link><space/>and<space/><link><target>mathematics</target></link>, and evolved into use by the social sciences,<template><target>citation needed</target><arg name="date">May 2015</arg></template><space/>such as<space/><link><target>economics</target></link>,<space/><link><target>psychology</target></link>,<space/><link><target>control theory (sociology)</target><part>sociology</part></link>,<space/><link><target>criminology</target></link><space/>and in the<space/><link><target>financial system</target></link>.</listitem></list><paragraph>Control systems may be thought of as having four functions: measure, compare, compute and correct.<template><target>citation needed</target><arg name="date">August 2014</arg></template><space/>These four functions are completed by five elements:<space/><link><target>detector</target></link>,<space/><link><target>transducer</target></link>,<space/><link><target>transmitter</target></link>,<space/><link><target>Controller (control theory)</target><part>controller</part></link><space/>and final control element.<template><target>citation needed</target><arg name="date">August 2014</arg></template><space/>The measuring function is completed by the detector, transducer and transmitter. In practical applications these three elements are typically contained in one unit. A standard example of a measuring unit is a<space/><link><target>resistance thermometer</target></link>. The compare and compute functions are completed within the controller, which may be implemented electronically by<space/><link><target>proportional control</target></link>, a<space/><link><target>PI controller</target></link>,<space/><link><target>PID controller</target></link>, bistable, hysteretic control or<space/><link><target>programmable logic controller</target></link>. Older controller units have been mechanical, as in a<space/><link><target>centrifugal governor</target></link><space/>or a<space/><link><target>carburetor</target></link>. The correct function is completed with a final control element. The final control element changes an input or output in the control system that affects the manipulated or controlled variable.</paragraph><heading level='3'>An example</heading><paragraph>An example of a control system is a car's<space/><link><target>cruise control</target></link>, which is a device designed to maintain vehicle speed at a constant<space/><italics>desired</italics><space/>or<space/><italics>reference</italics><space/>speed provided by the driver. The<space/><italics>controller</italics><space/>is the cruise control, the<space/><italics>plant</italics><space/>is the car, and the<space/><italics>system</italics><space/>is the car and the cruise control. The system output is the car's speed, and the control itself is the engine's<space/><link><target>throttle</target></link><space/>position which determines how much power the engine delivers.</paragraph><paragraph>A primitive way to implement cruise control is simply to lock the throttle position when the driver engages cruise control. However, if the cruise control is engaged on a stretch of flat road, then the car will travel slower going uphill and faster when going downhill. This type of controller is called an<space/><italics><link><target>open-loop controller</target></link></italics><space/>because there is no<space/><link><target>feedback</target></link>; no measurement of the system output (the car's speed) is used to alter the control (the throttle position.) As a result, the controller cannot compensate for changes acting on the car, like a change in the slope of the road.</paragraph><paragraph>In a<space/><italics><link><target>closed-loop controller</target><part>closed-loop control system</part></link></italics>, data from a sensor monitoring the car's speed (the system output) enters a controller which continuously subtracts the quantity representing the speed from the reference quantity representing the desired speed. The difference, called the error, determines the throttle position (the control). The result is to match the car's speed to the reference speed (maintain the desired system output). Now, when the car goes uphill, the difference between the input (the sensed speed) and the reference continuously determines the throttle position. As the sensed speed drops below the reference, the difference increases, the throttle opens, and engine power increases, speeding up the vehicle. In this way, the controller dynamically counteracts changes to the car's speed. The central idea of these control systems is the<space/><italics>feedback loop</italics>, the controller affects the system output, which in turn is measured and fed back to the controller.</paragraph><heading level='2'>Classification</heading><heading level='3'>Linear versus nonlinear control theory</heading><paragraph>The field of control theory can be divided into two branches:</paragraph><list type='bullet'><listitem><italics><link><target>Linear control theory</target></link></italics><space/>- This applies to systems made of devices which obey the<space/><link><target>superposition principle</target></link>, which means roughly that the output is proportional to the input. They are governed by<space/><link><target>linear equation</target><part>linear</part></link><space/><link><target>differential equation</target><trail>s</trail></link>. A major subclass is systems which in addition have parameters which do not change with time, called<space/><italics><link><target>linear time invariant</target></link></italics><space/>(LTI) systems. These systems are amenable to powerful<space/><link><target>frequency domain</target></link><space/>mathematical techniques of great generality, such as the<space/><link><target>Laplace transform</target></link>,<space/><link><target>Fourier transform</target></link>,<space/><link><target>Z transform</target></link>,<space/><link><target>Bode plot</target></link>,<space/><link><target>root locus</target></link>, and<space/><link><target>Nyquist stability criterion</target></link>. These lead to a description of the system using terms like<space/><link><target>Bandwidth (signal processing)</target><part>bandwidth</part></link>,<space/><link><target>frequency response</target></link>,<space/><link><target>eigenvalue</target><trail>s</trail></link>,<space/><link><target>gain (electronics)</target><part>gain</part></link>,<space/><link><target>resonant frequency</target><part>resonant frequencies</part></link>,<space/><link><target>pole (complex analysis)</target><part>pole</part><trail>s</trail></link>, and<space/><link><target>zero (complex analysis)</target><part>zero</part><trail>s</trail></link>, which give solutions for system response and design techniques for most systems of interest.<space/></listitem><listitem><italics><link><target>Nonlinear control theory</target></link></italics><space/>- This covers a wider class of systems that do not obey the superposition principle, and applies to more real-world systems, because all real control systems are nonlinear. These systems are often governed by<space/><link><target>nonlinear differential equation</target><trail>s</trail></link>. The few mathematical techniques which have been developed to handle them are more difficult and much less general, often applying only to narrow categories of systems. These include<space/><link><target>limit cycle</target></link><space/>theory,<space/><link><target>Poincar map</target><trail>s</trail></link>,<space/><link><target>Lyapunov function</target><part>Lyapunov stability theorem</part></link>, and<space/><link><target>describing function</target><trail>s</trail></link>. Nonlinear systems are often analyzed using<space/><link><target>numerical method</target><trail>s</trail></link><space/>on<space/><link><target>computer</target><trail>s</trail></link>, for example by<space/><link><target>simulation</target><part>simulating</part></link><space/>their operation using a<space/><link><target>simulation language</target></link>. If only solutions near a stable point are of interest, nonlinear systems can often be<space/><link><target>linearization</target><part>linearized</part></link><space/>by approximating them by a linear system using<space/><link><target>perturbation theory</target></link>, and linear techniques can be used.<extension extension_name='ref'><link type='external' href='http://www.mathworks.com/help/toolbox/simulink/slref/trim.html'>trim point</link></extension></listitem></list><heading level='3'>Frequency domain versus time domain</heading><paragraph>Mathematical techniques for analyzing and designing control systems fall into two different categories:</paragraph><list type='bullet'><listitem><italics><link><target>Frequency domain</target></link></italics><space/>- In this type the values of the<space/><link><target>state variable</target><trail>s</trail></link>, the mathematical<space/><link><target>variable (mathematics)</target><part>variable</part><trail>s</trail></link><space/>representing the system's input, output and feedback are represented as functions of<space/><link><target>frequency</target></link>. The input signal and the system's<space/><link><target>transfer function</target></link><space/>are converted from time functions to functions of frequency by a<space/><link><target>transform (mathematics)</target><part>transform</part></link><space/>such as the<space/><link><target>Fourier transform</target></link>,<space/><link><target>Laplace transform</target></link>, or<space/><link><target>Z transform</target></link>. The advantage of this technique is that it results in a simplification of the mathematics; the<space/><italics><link><target>differential equation</target><trail>s</trail></link></italics><space/>that represent the system are replaced by<space/><italics><link><target>algebraic equation</target><trail>s</trail></link></italics><space/>in the frequency domain which are much simpler to solve. However, frequency domain techniques can only be used with linear systems, as mentioned above.</listitem><listitem><italics><link><target>Time-domain state space representation</target></link></italics><space/>- In this type the values of the<space/><link><target>state variable</target><trail>s</trail></link><space/>are represented as functions of time. With this model the system being analyzed is represented by one or more<space/><link><target>differential equation</target><trail>s</trail></link>. Since frequency domain techniques are limited to<space/><link><target>linear function</target><part>linear</part></link><space/>systems, time domain is widely used to analyze real-world nonlinear systems. Although these are more difficult to solve, modern computer simulation techniques such as<space/><link><target>simulation language</target><trail>s</trail></link><space/>have made their analysis routine.</listitem></list><heading level='3'>SISO vs MIMO</heading><paragraph>Control systems can be divided into different categories depending on the number of inputs and outputs.</paragraph><list type='bullet'><listitem><link><target>Single-input single-output system</target><part>Single-input single-output</part></link><space/>(SISO) - This is the simplest and most common type, in which one output is controlled by one control signal. Examples are the cruise control example above, or an<space/><link><target>audio system</target></link>, in which the control input is the input audio signal and the output is the sound waves from the speaker.<space/></listitem><listitem><link><target>Multiple-input multiple-output system</target><part>Multiple-input multiple-output</part></link><space/>(MIMO) - These are found in more complicated systems. For example, modern large<space/><link><target>telescope</target><trail>s</trail></link><space/>such as the<space/><link><target>Keck telescopes</target><part>Keck</part></link><space/>and<space/><link><target>Multiple mirror telescope</target><part>MMT</part></link><space/>have mirrors composed of many separate segments each controlled by an<space/><link><target>actuator</target></link>. The shape of the entire mirror is constantly adjusted by a MIMO<space/><link><target>active optics</target></link><space/>control system using input from multiple sensors at the focal plane, to compensate for changes in the mirror shape due to thermal expansion, contraction, stresses as it is rotated and distortion of the<space/><link><target>wavefront</target></link><space/>due to turbulence in the atmosphere. Complicated systems such as<space/><link><target>nuclear reactor</target><trail>s</trail></link><space/>and human<space/><link><target>cell (biology)</target><part>cell</part><trail>s</trail></link><space/>are simulated by computer as large MIMO control systems.</listitem></list><heading level='2'>History</heading><paragraph><link><target>File:Boulton and Watt centrifugal governor-MJ.jpg</target><part>thumb</part><part>right</part><part><link><target>Centrifugal governor</target></link><space/>in a<space/><link><target>Boulton &amp; Watt engine</target></link><space/>of 1788</part></link></paragraph><paragraph>Although control systems of various types date back to antiquity, a more formal analysis of the field began with a dynamics analysis of the<space/><link><target>centrifugal governor</target></link>, conducted by the physicist<space/><link><target>James Clerk Maxwell</target></link><space/>in 1868, entitled<space/><italics>On Governors</italics>.<extension extension_name='ref' name="Maxwell1867"><template><target>cite journal</target><arg name="author"><space/>Maxwell, J.C.
<space/></arg><arg name="year"><space/>1868
<space/></arg><arg name="title"><space/>On Governors
<space/></arg><arg name="journal"><space/>Proceedings of the Royal Society of London
<space/></arg><arg name="volume"><space/>16
<space/></arg><arg name="pages"><space/>270â€“283
<space/></arg><arg name="accessdate"><space/>2008-04-14
<space/></arg><arg name="doi"><space/>10.1098/rspl.1867.0055
<space/></arg><arg name="jstor">112510
</arg></template></extension><space/>This described and analyzed the phenomenon of<space/><link><target>self-oscillation</target></link>, in which lags in the system may lead to overcompensation and unstable behavior. This generated a flurry of interest in the topic, during which Maxwell's classmate,<space/><link><target>Edward John Routh</target></link>, abstracted Maxwell's results for the general class of linear systems.<extension extension_name='ref' name="Routh1975"><template><target>cite book</target><arg name="author"><space/>Routh, E.J.
<space/></arg><arg name="author2">Fuller, A.T.
<space/></arg><arg name="year"><space/>1975
<space/></arg><arg name="title"><space/>Stability of motion
<space/></arg><arg name="publisher"><space/>Taylor & Francis
<space/></arg><arg name="isbn">
</arg></template></extension><space/>Independently,<space/><link><target>Adolf Hurwitz</target></link><space/>analyzed system stability using differential equations in 1877, resulting in what is now known as the<space/><link><target>RouthHurwitz theorem</target></link>.<extension extension_name='ref' name="Routh1877"><template><target>cite book</target><arg name="author"><space/>Routh, E.J.
<space/></arg><arg name="year"><space/>1877
<space/></arg><arg name="title"><space/>A Treatise on the Stability of a Given State of Motion, Particularly Steady Motion: Particularly Steady Motion
<space/></arg><arg name="publisher"><space/>Macmillan and co.
<space/></arg><arg name="isbn">
</arg></template></extension><extension extension_name='ref' name="Hurwitz1964"><template><target>cite journal</target><arg name="author"><space/>Hurwitz, A.
<space/></arg><arg name="year"><space/>1964
<space/></arg><arg name="title"><space/>On The Conditions Under Which An Equation Has Only Roots With Negative Real Parts
<space/></arg><arg name="journal"><space/>Selected Papers on Mathematical Trends in Control Theory
</arg></template></extension></paragraph><paragraph>A notable application of dynamic control was in the area of manned flight. The<space/><link><target>Wright brothers</target></link><space/>made their first successful test flights on December 17, 1903 and were distinguished by their ability to control their flights for substantial periods (more so than the ability to produce lift from an airfoil, which was known). Continuous, reliable control of the airplane was necessary for flights lasting longer than a few seconds.</paragraph><paragraph>By<space/><link><target>World War II</target></link>, control theory was an important part of<space/><link><target>fire-control system</target><trail>s</trail></link>,<space/><link><target>guidance system</target><trail>s</trail></link><space/>and<space/><link><target>electronics</target></link>.</paragraph><paragraph>Sometimes, mechanical methods are used to improve the stability of systems. For example,<space/><link><target>Stabilizer (ship)</target><part>ship stabilizers</part></link><space/>are fins mounted beneath the waterline and emerging laterally. In contemporary vessels, they may be gyroscopically controlled active fins, which have the capacity to change their angle of attack to counteract roll caused by wind or waves acting on the ship.</paragraph><paragraph>The<space/><link><target>Sidewinder missile</target></link><space/>uses small control surfaces placed at the rear of the missile with spinning disks on their outer surfaces and these are known as<space/><link><target>rolleron</target><trail>s</trail></link>. Airflow over the disks spins them to a high speed. If the missile starts to roll, the gyroscopic force of the disks drives the control surface into the airflow, cancelling the motion. Thus, the Sidewinder team replaced a potentially complex control system with a simple mechanical solution.</paragraph><paragraph>The<space/><link><target>Space Race</target></link><space/>also depended on accurate spacecraft control, and control theory has also seen an increasing use in fields such as<space/><link><target>economics</target></link>.</paragraph><heading level='2'>People in systems and control</heading><paragraph><template><target>Main</target><arg>People in systems and control</arg></template>Many active and historical figures made significant contribution to control theory including:</paragraph><list type='bullet'><listitem><link><target>Pierre-Simon Laplace</target></link><space/>(1749-1827) invented the<space/><link><target>Z-transform</target></link><space/>in his work on<space/><link><target>probability theory</target></link>, now used to solve discrete-time control theory problems. The Z-transform is a discrete-time equivalent of the<space/><link><target>Laplace transform</target></link><space/>which is named after him.</listitem><listitem><link><target>Alexander Lyapunov</target></link><space/>(18571918) in the 1890s marks the beginning of<space/><link><target>stability theory</target></link>.</listitem><listitem><link><target>Harold Stephen Black</target><part>Harold S. Black</part></link><space/>(18981983), invented the concept of<space/><link><target>negative feedback amplifier</target><trail>s</trail></link><space/>in 1927. He managed to develop stable negative feedback amplifiers in the 1930s.</listitem><listitem><link><target>Harry Nyquist</target></link><space/>(18891976) developed the<space/><link><target>Nyquist stability criterion</target></link><space/>for feedback systems in the 1930s.</listitem><listitem><link><target>Richard Bellman</target></link><space/>(19201984) developed<space/><link><target>dynamic programming</target></link><space/>since the 1940s.<extension extension_name='ref'><link><target>Richard Bellman</target></link><space/>(1964)<space/><link type='external' href='http://www.nature.com/scientificamerican/journal/v211/n3/pdf/scientificamerican0964-186.pdf'>Control Theory</link>,<space/><link><target>Scientific American</target></link><space/>211(3):186200</extension></listitem><listitem><link><target>Andrey Kolmogorov</target></link><space/>(19031987) co-developed the<space/><link><target>Wiener filter</target><part>WienerKolmogorov filter</part></link><space/>in 1941.</listitem><listitem><link><target>Norbert Wiener</target></link><space/>(18941964) co-developed the WienerKolmogorov filter and coined the term<space/><link><target>cybernetics</target></link><space/>in the 1940s.</listitem><listitem><link><target>John R. Ragazzini</target></link><space/>(19121988) introduced<space/><link><target>digital control</target></link><space/>and the use of<space/><link><target>Z-transform</target></link><space/>in control theory (invented by Laplace) in the 1950s.</listitem><listitem><link><target>Lev Pontryagin</target></link><space/>(19081988) introduced the<space/><link><target>Pontryagin's minimum principle</target><part>maximum principle</part></link><space/>and the<space/><link><target>Bang-bang control</target><part>bang-bang principle</part></link>.</listitem><listitem><link><target>Pierre-Louis Lions</target></link><space/>(1956) developed<space/><link><target>viscosity solutions</target></link><space/>into stochastic control and<space/><link><target>optimal control</target></link><space/>methods.</listitem></list><heading level='2'>Classical control theory</heading><paragraph>To overcome the limitations of the<space/><link><target>open-loop controller</target></link>, control theory introduces<space/><link><target>feedback</target></link>.A<space/><link><target>closed-loop controller</target></link><space/>uses feedback to control<space/><link><target>state (controls)</target><part>states</part></link><space/>or<space/><link><target>Negative feedback#Overview</target><part>output</part><trail>s</trail></link><space/>of a<space/><link><target>dynamical system</target></link>. Its name comes from the information path in the system: process inputs (e.g.,<space/><link><target>voltage</target></link><space/>applied to an<space/><link><target>electric motor</target></link>) have an effect on the process outputs (e.g., speed or torque of the motor), which is measured with<space/><link><target>sensor</target><trail>s</trail></link><space/>and processed by the controller; the result (the control signal) is &quot;fed back&quot; as input to the process, closing the loop.</paragraph><paragraph>Closed-loop controllers have the following advantages over<space/><link><target>open-loop controller</target><trail>s</trail></link>:</paragraph><list type='bullet'><listitem>disturbance rejection (such as hills in the cruise control example above)</listitem><listitem>guaranteed performance even with<space/><link><target>mathematical model</target><part>model</part></link><space/>uncertainties, when the model structure does not match perfectly the real process and the model parameters are not exact</listitem><listitem><link><target>instability</target><part>unstable</part></link><space/>processes can be stabilized</listitem><listitem>reduced sensitivity to parameter variations</listitem><listitem>improved reference tracking performance</listitem></list><paragraph>In some systems, closed-loop and open-loop control are used simultaneously. In such systems, the open-loop control is termed<space/><link><target>feed forward (control)</target><part>feedforward</part></link><space/>and serves to further improve reference tracking performance.</paragraph><paragraph>A common closed-loop controller architecture is the<space/><link><target>PID controller</target></link>.</paragraph><heading level='3'>Closed-loop transfer function</heading><paragraph><template><target>details</target><arg>closed-loop transfer function</arg></template>The output of the system<space/><italics>y(t)</italics><space/>is fed back through a sensor measurement<space/><italics>F</italics><space/>to the reference value<space/><italics>r(t)</italics>. The controller<space/><italics>C</italics><space/>then takes the error<space/><italics>e</italics><space/>(difference) between the reference and the output to change the inputs<space/><italics>u</italics><space/>to the system under control<space/><italics>P</italics>. This is shown in the figure. This kind of controller is a closed-loop controller or feedback controller.</paragraph><paragraph>This is called a single-input-single-output (<italics>SISO</italics>) control system;<space/><italics>MIMO</italics><space/>(i.e., Multi-Input-Multi-Output) systems, with more than one input/output, are common. In such cases variables are represented through<space/><link><target>coordinate vector</target><part>vectors</part></link><space/>instead of simple<space/><link><target>scalar (mathematics)</target><part>scalar</part></link><space/>values. For some<space/><link><target>distributed parameter systems</target></link><space/>the vectors may be infinite-<link><target>Dimension (vector space)</target><part>dimensional</part></link><space/>(typically functions).</paragraph><paragraph><link><target>File:simple feedback control loop2.svg</target><part>center</part><part>A simple feedback control loop</part></link></paragraph><paragraph>If we assume the controller<space/><italics>C</italics>, the plant<space/><italics>P</italics>, and the sensor<space/><italics>F</italics><space/>are<space/><link><target>linear</target></link><space/>and<space/><link><target>time-invariant</target></link><space/>(i.e., elements of their<space/><link><target>transfer function</target></link><space/><italics>C(s)</italics>,<space/><italics>P(s)</italics>, and<space/><italics>F(s)</italics><space/>do not depend on time), the systems above can be analysed using the<space/><link><target>Laplace transform</target></link><space/>on the variables. This gives the following relations:</paragraph><list type='ident'><listitem><extension extension_name='math'>Y(s) = P(s) U(s)\,\!</extension></listitem><listitem><extension extension_name='math'>U(s) = C(s) E(s)\,\!</extension></listitem><listitem><extension extension_name='math'>E(s) = R(s) - F(s)Y(s).\,\!</extension></listitem></list><paragraph>Solving for<space/><italics>Y</italics>(<italics>s</italics>) in terms of<space/><italics>R</italics>(<italics>s</italics>) gives:</paragraph><list type='ident'><listitem><extension extension_name='math'>Y(s) = \left( \frac{P(s)C(s)}{1 + F(s)P(s)C(s)} \right) R(s) = H(s)R(s).</extension></listitem></list><paragraph>The expression<space/><extension extension_name='math'>H(s) = \frac{P(s)C(s)}{1 + F(s)P(s)C(s)}</extension><space/>is referred to as the<space/><italics>closed-loop transfer function</italics><space/>of the system. The numerator is the forward (open-loop) gain from<space/><italics>r</italics><space/>to<space/><italics>y</italics>, and the denominator is one plus the gain in going around the feedback loop, the so-called loop gain. If<space/><extension extension_name='math'>|P(s)C(s)| \gg 1</extension>, i.e., it has a large<space/><link><target>norm (mathematics)</target><part>norm</part></link><space/>with each value of<space/><italics>s</italics>, and if<space/><extension extension_name='math'>|F(s)| \approx 1</extension>, then<space/><italics>Y(s)</italics><space/>is approximately equal to<space/><italics>R(s)</italics><space/>and the output closely tracks the reference input.</paragraph><heading level='3'>PID controller</heading><paragraph><template><target>details</target><arg>PID controller</arg></template>The<space/><link><target>PID controller</target></link><space/>is probably the most-used feedback control design.<space/><italics>PID</italics><space/>is an initialism for<space/><italics>Proportional-Integral-Derivative</italics>, referring to the three terms operating on the error signal to produce a control signal. If<space/><italics>u(t)</italics><space/>is the control signal sent to the system,<space/><italics>y(t)</italics><space/>is the measured output and<space/><italics>r(t)</italics><space/>is the desired output, and tracking error<space/><extension extension_name='math'>e(t)=r(t)- y(t)</extension>, a PID controller has the general form</paragraph><list type='ident'><listitem><extension extension_name='math'>u(t) = K_P e(t) + K_I \int e(t)\text{d}t + K_D \frac{\text{d}}{\text{d}t}e(t).</extension></listitem></list><paragraph>The desired closed loop dynamics is obtained by adjusting the three parameters<space/><extension extension_name='math'><space/>K_P</extension>,<space/><extension extension_name='math'><space/>K_I</extension><space/>and<space/><extension extension_name='math'><space/>K_D</extension>, often iteratively by &quot;tuning&quot; and without specific knowledge of a plant model. Stability can often be ensured using only the proportional term. The integral term permits the rejection of a step disturbance (often a striking specification in<space/><link><target>process control</target></link>). The derivative term is used to provide damping or shaping of the response. PID controllers are the most well established class of control systems: however, they cannot be used in several more complicated cases, especially if<space/><link><target>MIMO</target></link><space/>systems are considered.</paragraph><paragraph>Applying Laplace transformation results in the transformed PID controller equation</paragraph><list type='ident'><listitem><extension extension_name='math'>u(s) = K_P e(s) + K_I \frac{1}{s} e(s) + K_D s e(s)</extension></listitem><listitem><extension extension_name='math'>u(s) = \left(K_P + K_I \frac{1}{s} + K_D s\right) e(s)</extension></listitem></list><paragraph>with the PID controller transfer function</paragraph><list type='ident'><listitem><extension extension_name='math'>C(s) = \left(K_P + K_I \frac{1}{s} + K_D s\right).</extension></listitem></list><paragraph>There exists a nice example of the closed-loop system discussed above. If we take:</paragraph><paragraph>PID controller transfer function in series form</paragraph><list type='ident'><listitem><extension extension_name='math'>C(s) = K \left(1 + \frac{1}{sT_i}\right)(1 + sT_d)</extension></listitem></list><paragraph>1st order filter in feedback loop</paragraph><list type='ident'><listitem><extension extension_name='math'>F(s) = \frac{1}{1 + sT_f}</extension></listitem></list><paragraph>linear actuator with filtered input</paragraph><list type='ident'><listitem><extension extension_name='math'>P(s) = \frac{A}{1 + sT_p}</extension>, A = const</listitem></list><paragraph>and insert all this into expression for closed-loop transfer function H(s), then tuning is very easy: simply put</paragraph><list type='ident'><listitem><extension extension_name='math'>K = \frac{1}{A}, T_i = T_f, T_d = T_p</extension></listitem></list><paragraph>and get H(s) = 1 identically.</paragraph><paragraph>For practical PID controllers, a pure differentiator is neither physically realisable nor desirable<extension extension_name='ref'>Ang, K.H., Chong, G.C.Y., and Li, Y. (2005).<space/><link type='external' href='http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=1453566'>PID control system analysis, design, and technology, ''IEEE Trans Control Systems Tech'', 13(4), pp.559-576</link>.</extension><space/>due to amplification of noise and resonant modes in the system. Therefore, a phase-lead compensator type approach is used instead, or a differentiator with low-pass roll-off.</paragraph><heading level='2'>Modern control theory</heading><paragraph>In contrast to the frequency domain analysis of the classical control theory, modern control theory utilizes the time-domain<space/><link><target>state space (controls)</target><part>state space</part></link><space/>representation, a mathematical model of a physical system as a set of input, output and state variables related by first-order differential equations. To abstract from the number of inputs, outputs and states, the variables are expressed as vectors and the differential and algebraic equations are written in matrix form (the latter only being possible when the dynamical system is linear). The state space representation (also known as the &quot;time-domain approach&quot;) provides a convenient and compact way to model and analyze systems with multiple inputs and outputs. With inputs and outputs, we would otherwise have to write down Laplace transforms to encode all the information about a system. Unlike the frequency domain approach, the use of the state-space representation is not limited to systems with linear components and zero initial conditions. &quot;State space&quot; refers to the space whose axes are the state variables. The state of the system can be represented as a vector within that space.<extension extension_name='ref'><template><target>cite book</target><arg name="title">State space & linear systems</arg><arg name="series">Schaum's outline series<space/></arg><arg name="publisher">McGraw Hill</arg><arg name="author">Donald M Wiberg</arg><arg name="isbn">0-07-070096-6</arg></template></extension><extension extension_name='ref'><template><target>cite journal</target><arg name="author">Terrell, William</arg><arg name="title">Some fundamental control theory I: Controllability, observability, and duality â€”ANDâ€” Some fundamental control Theory II: Feedback linearization of single input nonlinear systems</arg><arg name="journal">Amer. Math. Monthly</arg><arg name="volume">106</arg><arg name="year">1999</arg><arg name="pages">705â€“719 and 812â€“828</arg><arg name="url">http://www.maa.org/programs/maa-awards/writing-awards/some-fundamental-control-theory-i-controllability-observability-and-duality-and-some-fundamental</arg><arg name="doi">10.2307/2589614</arg></template></extension></paragraph><heading level='2'>Topics in control theory</heading><heading level='3'>Stability</heading><paragraph>The<space/><italics>stability</italics><space/>of a general<space/><link><target>dynamical system</target></link><space/>with no input can be described with<space/><link><target>Lyapunov stability</target></link><space/>criteria.<space/></paragraph><list type='bullet'><listitem>A<space/><link><target>linear system</target></link><space/>is called<space/><link><target>BIBO stability</target><part>bounded-input bounded-output (BIBO) stable</part></link><space/>if its output will stay<space/><link><target>bounded function</target><part>bounded</part></link><space/>for any bounded input.<space/></listitem><listitem>Stability for<space/><link><target>nonlinear system</target><trail>s</trail></link><space/>that take an input is<space/><link><target>input-to-state stability</target></link><space/>(ISS), which combines Lyapunov stability and a notion similar to BIBO stability.</listitem></list><paragraph>For simplicity, the following descriptions focus on continuous-time and discrete-time<space/><bold>linear systems</bold>.</paragraph><paragraph>Mathematically, this means that for a causal linear system to be stable all of the<space/><link><target>Pole (complex analysis)</target><part>poles</part></link><space/>of its<space/><link><target>transfer function</target></link><space/>must have negative-real values, i.e. the real part of each pole must be less than zero. Practically speaking, stability requires that the transfer function complex poles reside:</paragraph><list type='bullet'><listitem>in the open left half of the<space/><link><target>complex plane</target></link><space/>for continuous time, when the<space/><link><target>Laplace transform</target></link><space/>is used to obtain the transfer function.</listitem><listitem>inside the<space/><link><target>unit circle</target></link><space/>for discrete time, when the<space/><link><target>Z-transform</target></link><space/>is used.</listitem></list><paragraph>The difference between the two cases is simply due to the traditional method of plotting continuous time versus discrete time transfer functions. The continuous Laplace transform is in<space/><link><target>Cartesian coordinates</target></link><space/>where the<space/><extension extension_name='math'>x</extension><space/>axis is the real axis and the discrete Z-transform is in<space/><link><target>circular coordinates</target></link><space/>where the<space/><extension extension_name='math'>\rho</extension><space/>axis is the real axis.</paragraph><paragraph>When the appropriate conditions above are satisfied a system is said to be<space/><link><target>asymptotic stability</target><part>asymptotically stable</part></link>: the variables of an asymptotically stable control system always decrease from their initial value and do not show permanent oscillations. Permanent oscillations occur when a pole has a real part exactly equal to zero (in the continuous time case) or a modulus equal to one (in the discrete time case). If a simply stable system response neither decays nor grows over time, and has no oscillations, it is<space/><link><target>marginal stability</target><part>marginally stable</part></link>: in this case the system transfer function has non-repeated poles at complex plane origin (i.e. their real and complex component is zero in the continuous time case). Oscillations are present when poles with real part equal to zero have an imaginary part not equal to zero.</paragraph><paragraph>If a system in question has an<space/><link><target>impulse response</target></link><space/>of</paragraph><list type='ident'><listitem><extension extension_name='math'>\ x[n] = 0.5^n u[n]</extension></listitem></list><paragraph>then the Z-transform (see<space/><link><target>Z-transform#Example 2 (causal ROC)</target><part>this example</part></link>), is given by</paragraph><list type='ident'><listitem><extension extension_name='math'>\ X(z) = \frac{1}{1 - 0.5z^{-1}}\<space/></extension></listitem></list><paragraph>which has a pole in<space/><extension extension_name='math'>z = 0.5</extension><space/>(zero<space/><link><target>imaginary number</target><part>imaginary part</part></link>). This system is BIBO (asymptotically) stable since the pole is<space/><italics>inside</italics><space/>the unit circle.</paragraph><paragraph>However, if the impulse response was</paragraph><list type='ident'><listitem><extension extension_name='math'>\ x[n] = 1.5^n u[n]</extension></listitem></list><paragraph>then the Z-transform is</paragraph><list type='ident'><listitem><extension extension_name='math'>\ X(z) = \frac{1}{1 - 1.5z^{-1}}\<space/></extension></listitem></list><paragraph>which has a pole at<space/><extension extension_name='math'>z = 1.5</extension><space/>and is not BIBO stable since the pole has a modulus strictly greater than one.</paragraph><paragraph>Numerous tools exist for the analysis of the poles of a system. These include graphical systems like the<space/><link><target>root locus</target></link>,<space/><link><target>Bode plot</target><trail>s</trail></link><space/>or the<space/><link><target>Nyquist plot</target><trail>s</trail></link>.</paragraph><paragraph>Mechanical changes can make equipment (and control systems) more stable. Sailors add ballast to improve the stability of ships. Cruise ships use<space/><link><target>Ship stability#Stabilizer fins</target><part>antiroll fins</part></link><space/>that extend transversely from the side of the ship for perhaps 30 feet (10 m) and are continuously rotated about their axes to develop forces that oppose the roll.</paragraph><heading level='3'>Controllability and observability</heading><paragraph><template><target>Main</target><arg><space/>Controllability</arg><arg>Observability</arg></template></paragraph><paragraph><link><target>Controllability</target></link><space/>and<space/><link><target>observability</target></link><space/>are main issues in the analysis of a system before deciding the best control strategy to be applied, or whether it is even possible to control or stabilize the system. Controllability is related to the possibility of forcing the system into a particular state by using an appropriate control signal. If a state is not controllable, then no signal will ever be able to control the state. If a state is not controllable, but its dynamics are stable, then the state is termed<space/><italics>stabilizable</italics>. Observability instead is related to the possibility of<space/><italics>observing</italics>, through output measurements, the state of a system. If a state is not observable, the controller will never be able to determine the behaviour of an unobservable state and hence cannot use it to stabilize the system. However, similar to the stabilizability condition above, if a state cannot be observed it might still be detectable.</paragraph><paragraph>From a geometrical point of view, looking at the states of each variable of the system to be controlled, every &quot;bad&quot; state of these variables must be controllable and observable to ensure a good behaviour in the closed-loop system. That is, if one of the<space/><link><target>eigenvalues</target></link><space/>of the system is not both controllable and observable, this part of the dynamics will remain untouched in the closed-loop system. If such an eigenvalue is not stable, the dynamics of this eigenvalue will be present in the closed-loop system which therefore will be unstable. Unobservable poles are not present in the transfer function realization of a state-space representation, which is why sometimes the latter is preferred in dynamical systems analysis.</paragraph><paragraph>Solutions to problems of uncontrollable or unobservable system include adding actuators and sensors.</paragraph><heading level='3'>Control specification</heading><paragraph>Several different control strategies have been devised in the past years. These vary from extremely general ones (<link><target>PID controller</target></link>), to others devoted to very particular classes of systems (especially<space/><link><target>robotics</target></link><space/>or<space/><link><target>aircraft</target></link><space/>cruise control).</paragraph><paragraph>A control problem can have several specifications. Stability, of course, is always present: the controller must ensure that the closed-loop system is stable, regardless of the open-loop stability. A poor choice of controller can even worsen the stability of the open-loop system, which must normally be avoided. Sometimes it would be desired to obtain particular dynamics in the closed loop: i.e. that the poles have &lt;math&gt;Re[\lambda] &lt; -\overline{\lambda}&lt;/math&gt;, where<space/><extension extension_name='math'>\overline{\lambda}</extension><space/>is a fixed value strictly greater than zero, instead of simply asking that &lt;math&gt;Re[\lambda]&lt;0&lt;/math&gt;.</paragraph><paragraph>Another typical specification is the rejection of a step disturbance; including an<space/><link><target>integrator</target></link><space/>in the open-loop chain (i.e. directly before the system under control) easily achieves this. Other classes of disturbances need different types of sub-systems to be included.</paragraph><paragraph>Other &quot;classical&quot; control theory specifications regard the time-response of the closed-loop system: these include the<space/><link><target>rise time</target></link><space/>(the time needed by the control system to reach the desired value after a perturbation), peak<space/><link><target>overshoot (signal)</target><part>overshoot</part></link><space/>(the highest value reached by the response before reaching the desired value) and others (<link><target>settling time</target></link>, quarter-decay). Frequency domain specifications are usually related to<space/><link><target>robust control</target><part>robustness</part></link><space/>(see after).</paragraph><paragraph>Modern performance assessments use some variation of integrated tracking error (IAE,ISA,CQI).</paragraph><heading level='3'>Model identification and robustness</heading><paragraph>A control system must always have some robustness property. A<space/><link><target>robust control</target><trail>ler</trail></link><space/>is such that its properties do not change much if applied to a system slightly different from the mathematical one used for its synthesis. This specification is important: no real physical system truly behaves like the series of differential equations used to represent it mathematically. Typically a simpler mathematical model is chosen in order to simplify calculations, otherwise the true system dynamics can be so complicated that a complete model is impossible.</paragraph><list type='def'><listitem><defkey>System identification</defkey></listitem></list><paragraph><template><target>details</target><arg>System identification</arg></template>The process of determining the equations that govern the model's dynamics is called<space/><link><target>system identification</target></link>. This can be done off-line: for example, executing a series of measures from which to calculate an approximated mathematical model, typically its<space/><link><target>transfer function</target></link><space/>or matrix. Such identification from the output, however, cannot take account of unobservable dynamics. Sometimes the model is built directly starting from known physical equations: for example, in the case of a<space/><link><target>Damping#Example: massspringdamper</target><part>mass-spring-damper</part></link><space/>system we know that<space/><extension extension_name='math'><space/>m \ddot{{x}}(t) = - K x(t) - \Beta \dot{x}(t)</extension>. Even assuming that a &quot;complete&quot; model is used in designing the controller, all the parameters included in these equations (called &quot;nominal parameters&quot;) are never known with absolute precision; the control system will have to behave correctly even when connected to physical system with true parameter values away from nominal.</paragraph><paragraph>Some advanced control techniques include an &quot;on-line&quot; identification process (see later). The parameters of the model are calculated (&quot;identified&quot;) while the controller itself is running: in this way, if a drastic variation of the parameters ensues (for example, if the robot's arm releases a weight), the controller will adjust itself consequently in order to ensure the correct performance.</paragraph><list type='def'><listitem><defkey>Analysis</defkey></listitem></list><paragraph>Analysis of the robustness of a SISO (single input single output) control system can be performed in the frequency domain, considering the system's transfer function and using<space/><link><target>Nyquist diagram</target><part>Nyquist</part></link><space/>and<space/><link><target>Bode diagram</target><trail>s</trail></link>. Topics include<space/><link><target>Bode plot#Gain margin and phase margin</target><part>gain and phase margin</part></link><space/>and amplitude margin. For MIMO (multi input multi output) and, in general, more complicated control systems one must consider the theoretical results devised for each control technique (see next section): i.e., if particular robustness qualities are needed, the engineer must shift his attention to a control technique by including them in its properties.</paragraph><list type='def'><listitem><defkey>Constraints</defkey></listitem></list><paragraph>A particular robustness issue is the requirement for a control system to perform properly in the presence of input and state constraints. In the physical world every signal is limited. It could happen that a controller will send control signals that cannot be followed by the physical system: for example, trying to rotate a valve at excessive speed. This can produce undesired behavior of the closed-loop system, or even damage or break actuators or other subsystems. Specific control techniques are available to solve the problem:<space/><link><target>model predictive control</target></link><space/>(see later), and<space/><link><target>anti-wind up system (control)</target><part>anti-wind up systems</part></link>. The latter consists of an additional control block that ensures that the control signal never exceeds a given threshold.</paragraph><heading level='2'>System classifications</heading><heading level='3'>Linear systems control</heading><paragraph><template><target>Main</target><arg>State space (controls)</arg></template>For MIMO systems, pole placement can be performed mathematically using a<space/><link><target>State space (controls)</target><part>state space representation</part></link><space/>of the open-loop system and calculating a feedback matrix assigning poles in the desired positions. In complicated systems this can require computer-assisted calculation capabilities, and cannot always ensure robustness. Furthermore, all system states are not in general measured and so observers must be included and incorporated in pole placement design.</paragraph><heading level='3'>Nonlinear systems control</heading><paragraph><template><target>Main</target><arg>Nonlinear control</arg></template>Processes in industries like<space/><link><target>robotics</target></link><space/>and the<space/><link><target>aerospace industry</target></link><space/>typically have strong nonlinear dynamics. In control theory it is sometimes possible to linearize such classes of systems and apply linear techniques, but in many cases it can be necessary to devise from scratch theories permitting control of nonlinear systems. These, e.g.,<space/><link><target>feedback linearization</target></link>,<space/><link><target>backstepping</target></link>,<space/><link><target>sliding mode control</target></link>, trajectory linearization control normally take advantage of results based on<space/><link><target>Lyapunov's theory</target></link>.<space/><link><target>Differential geometry</target></link><space/>has been widely used as a tool for generalizing well-known linear control concepts to the non-linear case, as well as showing the subtleties that make it a more challenging problem. Control theory has also been used to decipher the neural mechanism that directs cognitive states.<space/><extension extension_name='ref' name="Shi_Gu_et_al"><template><target>cite journal</target><arg name="author1"><space/>Gu Shi</arg><arg name="author2"><space/>et al.</arg><arg name="year"><space/>2015<space/></arg><arg name="title"><space/>Controllability of structural brain networks (Article Number 8414)<space/></arg><arg name="journal"><space/>Nature Communications<space/></arg><arg name="quote"><space/>Here we use tools from control and network theories to offer a mechanistic explanation for how the brain moves between cognitive states drawn from the network organization of white matter microstructure.<space/></arg><arg name="laysummary"><space/>http://www.nature.com/ncomms/2015/151001/ncomms9414/full/ncomms9414.html<space/></arg><arg name="doi"><space/>10.1038/ncomms9414</arg><arg name="issue"><space/>6<space/></arg></template></extension></paragraph><heading level='3'>Decentralized systems control</heading><paragraph><template><target>Main</target><arg>Distributed control system</arg></template>When the system is controlled by multiple controllers, the problem is one of decentralized control. Decentralization is helpful in many ways, for instance, it helps control systems to operate over a larger geographical area. The agents in decentralized control systems can interact using communication channels and coordinate their actions.</paragraph><heading level='3'>Deterministic and stochastic systems control</heading><paragraph><template><target>Main</target><arg>Stochastic control</arg></template></paragraph><paragraph>A stochastic control problem is one in which the evolution of the state variables is subjected to random shocks from outside the system. A deterministic control problem is not subject to external random shocks.</paragraph><heading level='2'>Main control strategies</heading><paragraph>Every control system must guarantee first the stability of the closed-loop behavior. For<space/><link><target>linear system</target><trail>s</trail></link>, this can be obtained by directly placing the poles. Non-linear control systems use specific theories (normally based on<space/><link><target>Aleksandr Lyapunov</target></link>'s Theory) to ensure stability without regard to the inner dynamics of the system. The possibility to fulfill different specifications varies from the model considered and the control strategy chosen.</paragraph><list type='def'><listitem><defkey>List of the main control techniques</defkey></listitem></list><list type='bullet'><listitem><link><target>Adaptive control</target></link><space/>uses on-line identification of the process parameters, or modification of controller gains, thereby obtaining strong robustness properties. Adaptive controls were applied for the first time in the<space/><link><target>aerospace industry</target></link><space/>in the 1950s, and have found particular success in that field.</listitem></list><list type='bullet'><listitem>A<space/><link><target>hierarchical control system</target></link><space/>is a type of<space/><link><target>control system</target></link><space/>in which a set of devices and governing software is arranged in a<space/><link><target>hierarchical</target></link><space/><link><target>tree (data structure)</target><part>tree</part></link>. When the links in the tree are implemented by a<space/><link><target>computer network</target></link>, then that hierarchical control system is also a form of<space/><link><target>networked control system</target></link>.</listitem></list><list type='bullet'><listitem><link><target>Intelligent control</target></link><space/>uses various AI computing approaches like<space/><link><target>neural networks</target></link>,<space/><link><target>Bayesian probability</target></link>,<space/><link><target>fuzzy logic</target></link>,<extension extension_name='ref'><template><target>cite journal</target><arg name="title">A novel fuzzy framework for nonlinear system control</arg><arg name="journal">Fuzzy Sets and Systems<space/></arg><arg name="year">2010<space/></arg><arg name="last">Liu<space/></arg><arg name="first1">Jie<space/></arg><arg name="author2">Wilson Wang<space/></arg><arg name="author3">Farid Golnaraghi<space/></arg><arg name="author4">Eric Kubica<space/></arg><arg name="volume">161<space/></arg><arg name="issue">21<space/></arg><arg name="pages">2746â€“2759<space/></arg><arg name="doi">10.1016/j.fss.2010.04.009</arg></template></extension><space/><link><target>machine learning</target></link>,<space/><link><target>evolutionary computation</target></link><space/>and<space/><link><target>genetic algorithms</target></link><space/>to control a<space/><link><target>dynamic system</target></link>.</listitem></list><list type='bullet'><listitem><link><target>Optimal control</target></link><space/>is a particular control technique in which the control signal optimizes a certain &quot;cost index&quot;: for example, in the case of a satellite, the jet thrusts needed to bring it to desired trajectory that consume the least amount of fuel. Two optimal control design methods have been widely used in industrial applications, as it has been shown they can guarantee closed-loop stability. These are<space/><link><target>Model Predictive Control</target></link><space/>(MPC) and<space/><link><target>linear-quadratic-Gaussian control</target></link><space/>(LQG). The first can more explicitly take into account constraints on the signals in the system, which is an important feature in many industrial processes. However, the &quot;optimal control&quot; structure in MPC is only a means to achieve such a result, as it does not optimize a true performance index of the closed-loop control system. Together with PID controllers, MPC systems are the most widely used control technique in<space/><link><target>process control</target></link>.</listitem></list><list type='bullet'><listitem><link><target>Robust control</target></link><space/>deals explicitly with uncertainty in its approach to controller design. Controllers designed using<space/><italics>robust control</italics><space/>methods tend to be able to cope with small differences between the true system and the nominal model used for design. The early methods of<space/><link><target>Hendrik Wade Bode</target><part>Bode</part></link><space/>and others were fairly robust; the state-space methods invented in the 1960s and 1970s were sometimes found to lack robustness. Examples of modern robust control techniques include<space/><link><target>H-infinity loop-shaping</target></link><space/>developed by<space/><link><target>Duncan McFarlane</target></link><space/>and<space/><link><target>Keith Glover</target></link><space/>of<space/><link><target>Cambridge University</target></link>,<space/><link><target>United Kingdom</target></link><space/>and<space/><link><target>Sliding mode control</target></link><space/>(SMC) developed by<space/><link><target>Vadim Utkin</target></link>. Robust methods aim to achieve robust performance and/or<space/><link><target>Stability theory</target><part>stability</part></link><space/>in the presence of small modeling errors.</listitem></list><list type='bullet'><listitem><link><target>Stochastic control</target></link><space/>deals with control design with uncertainty in the model. In typical stochastic control problems, it is assumed that there exist random noise and disturbances in the model and the controller, and the control design must take into account these random deviations.</listitem></list><list type='bullet'><listitem><link><target>Energy-shaping control</target></link><space/>view the plant and the controller as energy-transformation devices. The control strategy is formulated in terms of interconnection (in a power-preserving manner) in order to achieve a desired behavior.</listitem></list><list type='bullet'><listitem><link><target>Self-organized criticality control</target></link><space/>may be defined as attempts to interfere in the processes by which the<space/><link><target>self-organized</target></link><space/>system dissipates energy.</listitem></list><heading level='2'>See also</heading><paragraph><template><target>multicol</target></template></paragraph><list type='def'><listitem><defkey>Examples of control systems</defkey></listitem></list><list type='bullet'><listitem><link><target>Automation</target></link></listitem><listitem><link><target>Deadbeat controller</target></link></listitem><listitem><link><target>Distributed parameter systems</target></link></listitem><listitem><link><target>Fractional-order control</target></link></listitem><listitem><link><target>H-infinity loop-shaping</target></link></listitem><listitem><link><target>Hierarchical control system</target></link></listitem><listitem><link><target>Model predictive control</target></link></listitem><listitem><link><target>PID controller</target></link></listitem><listitem><link><target>Process control</target></link></listitem><listitem><link><target>Robust control</target></link></listitem><listitem><link><target>Servomechanism</target></link></listitem><listitem><link><target>State space (controls)</target></link></listitem><listitem><link><target>Vector control (motor)</target><part>Vector control</part></link></listitem></list><paragraph><template><target>multicol-break</target></template></paragraph><list type='def'><listitem><defkey>Topics in control theory</defkey></listitem></list><list type='bullet'><listitem><link><target>Coefficient diagram method</target></link></listitem><listitem><link><target>Control reconfiguration</target></link></listitem><listitem><link><target>Cut-insertion theorem</target></link></listitem><listitem><link><target>Feedback</target></link></listitem><listitem><link><target>H infinity</target></link></listitem><listitem><link><target>Hankel singular value</target></link></listitem><listitem><link><target>Krener's theorem</target></link></listitem><listitem><link><target>Lead-lag compensator</target></link></listitem><listitem><link><target>Minor loop feedback</target></link></listitem><listitem><link><target>Minor loop feedback</target><part>Multi-loop feedback</part></link></listitem><listitem><link><target>Positive systems</target></link></listitem><listitem><link><target>Radial basis function</target></link></listitem><listitem><link><target>Root locus</target></link></listitem><listitem><link><target>Signal-flow graph</target><trail>s</trail></link></listitem><listitem><link><target>Stable polynomial</target></link></listitem><listitem><link><target>State space representation</target></link></listitem><listitem><link><target>Underactuation</target></link></listitem><listitem><link><target>YoulaKucera parametrization</target></link></listitem><listitem><link><target>Markov chain approximation method</target></link></listitem></list><paragraph><template><target>multicol-break</target></template><template><target>Portal</target><arg>Systems science</arg></template></paragraph><list type='def'><listitem><defkey>Other related topics</defkey></listitem></list><list type='bullet'><listitem><link><target>Automation and remote control</target></link></listitem><listitem><link><target>Bond graph</target></link></listitem><listitem><link><target>Control engineering</target></link></listitem><listitem><link><target>Controlfeedbackabort loop</target></link></listitem><listitem><link><target>Controller (control theory)</target></link></listitem><listitem><link><target>Cybernetics</target></link></listitem><listitem><link><target>Intelligent control</target></link></listitem><listitem><link><target>Mathematical system theory</target></link></listitem><listitem><link><target>Negative feedback amplifier</target></link></listitem><listitem><link><target>People in systems and control</target></link></listitem><listitem><link><target>Perceptual control theory</target></link></listitem><listitem><link><target>Systems theory</target></link></listitem><listitem><link><target>Time scale calculus</target></link></listitem></list><paragraph><template><target>multicol-end</target></template></paragraph><heading level='2'>References</heading><paragraph><template><target>Reflist</target></template></paragraph><heading level='2'>Further reading</heading><list type='bullet'><listitem><template><target>cite book</target><arg name="editor-last"><space/>Levine
<space/></arg><arg name="editor-first"><space/>William S.
<space/></arg><arg name="title"><space/>The Control Handbook
<space/></arg><arg name="publisher"><space/>CRC Press
<space/></arg><arg name="place"><space/>New York
<space/></arg><arg name="year"><space/>1996
<space/></arg><arg name="isbn"><space/>978-0-8493-8570-4
</arg></template></listitem><listitem><template><target>cite book</target><arg name="author"><space/>Karl J. Ã…strÃ¶m and Richard M. Murray</arg><arg name="year"><space/>2008<space/></arg><arg name="title"><space/>Feedback Systems: An Introduction for Scientists and Engineers.</arg><arg name="publisher"><space/>Princeton University Press<space/></arg><arg name="url"><space/>http://www.cds.caltech.edu/~murray/books/AM08/pdf/am08-complete_28Sep12.pdf<space/></arg><arg name="isbn"><space/>0-691-13576-2</arg></template></listitem><listitem><template><target>cite book</target><arg name="author"><space/>Christopher Kilian<space/></arg><arg name="title"><space/>Modern Control Technology<space/></arg><arg name="publisher"><space/>Thompson Delmar Learning<space/></arg><arg name="year"><space/>2005<space/></arg><arg name="isbn">1-4018-5806-6<space/></arg></template></listitem><listitem><template><target>cite book</target><arg name="author"><space/>Vannevar Bush<space/></arg><arg name="title"><space/>Operational Circuit Analysis<space/></arg><arg name="publisher"><space/>John Wiley and Sons, Inc.<space/></arg><arg name="year"><space/>1929<space/></arg></template></listitem><listitem><template><target>cite book</target><arg name="author"><space/>Robert F. Stengel<space/></arg><arg name="title"><space/>Optimal Control and Estimation<space/></arg><arg name="publisher"><space/>Dover Publications<space/></arg><arg name="year"><space/>1994<space/></arg><arg name="isbn">0-486-68200-5</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Franklin<space/></arg><arg name="authorlink"><space/></arg><arg name="others"><space/></arg><arg name="title">Feedback Control of Dynamic Systems<space/></arg><arg name="origyear"><space/></arg><arg name="url"><space/></arg><arg name="accessdate"><space/></arg><arg name="edition">4<space/></arg><arg name="year">2002<space/></arg><arg name="publisher">Prentice Hall<space/></arg><arg name="location">New Jersey<space/></arg><arg name="language"><space/></arg><arg name="isbn">0-13-032393-4<space/></arg><arg name="doi"><space/></arg><arg name="pages"><space/></arg><arg name="chapter"><space/></arg><arg name="chapterurl"><space/></arg><arg name="quote"><space/></arg><arg name="display-authors">etal</arg></template></listitem><listitem><template><target>cite book</target><arg name="author"><space/>Joseph L. Hellerstein, Dawn M. Tilbury, and Sujay Parekh<space/></arg><arg name="title"><space/>Feedback Control of Computing Systems<space/></arg><arg name="publisher"><space/>John Wiley and Sons<space/></arg><arg name="year"><space/>2004<space/></arg><arg name="isbn">0-471-26637-X</arg></template></listitem><listitem><template><target>cite book</target><arg name="author"><space/>[[Diederich Hinrichsen]] and Anthony J. Pritchard<space/></arg><arg name="title"><space/>Mathematical Systems Theory I - Modelling, State Space Analysis, Stability and Robustness<space/></arg><arg name="publisher"><space/>Springer<space/></arg><arg name="year"><space/>2005<space/></arg><arg name="isbn">3-540-44125-5</arg></template></listitem><listitem><template><target>cite journal</target><arg name="author"><space/>Andrei, Neculai<space/></arg><arg name="title"><space/>Modern Control Theory - A historical Perspective<space/></arg><arg name="version"><space/></arg><arg name="publisher"><space/></arg><arg name="year"><space/>2005<space/></arg><arg name="url"><space/>http://camo.ici.ro/neculai/history.pdf<space/></arg><arg name="accessdate"><space/>2007-10-10<space/></arg></template></listitem><listitem><template><target>cite book</target><arg name="last"><space/>Sontag<space/></arg><arg name="first"><space/>Eduardo<space/></arg><arg name="authorlink"><space/>Eduardo D. Sontag<space/></arg><arg name="year"><space/>1998<space/></arg><arg name="title"><space/>Mathematical Control Theory: Deterministic Finite Dimensional Systems. Second Edition<space/></arg><arg name="publisher"><space/>Springer<space/></arg><arg name="url"><space/>http://www.math.rutgers.edu/~sontag/FTP_DIR/sontag_mathematical_control_theory_springer98.pdf<space/></arg><arg name="isbn"><space/>0-387-98489-5</arg></template></listitem><listitem><template><target>cite book</target><arg name="last"><space/>Goodwin<space/></arg><arg name="first"><space/>Graham<space/></arg><arg name="authorlink"><space/></arg><arg name="year"><space/>2001<space/></arg><arg name="title"><space/>Control System Design<space/></arg><arg name="publisher"><space/>Prentice Hall<space/></arg><arg name="isbn"><space/>0-13-958653-9</arg></template></listitem><listitem><template><target>cite book</target><arg name="author"><space/>Christophe Basso<space/></arg><arg name="year"><space/>2012<space/></arg><arg name="title"><space/>Designing Control Loops for Linear and Switching Power Supplies: A Tutorial Guide.</arg><arg name="publisher"><space/>Artech House<space/></arg><arg name="url"><space/>http://cbasso.pagesperso-orange.fr/Spice.htm<space/></arg><arg name="isbn"><space/>978-1608075577</arg></template></listitem><listitem><template><target>cite book</target><arg name="author"><space/>Briat, Corentin<space/></arg><arg name="year"><space/>2015<space/></arg><arg name="title"><space/>Linear Parameter-Varying and Time-Delay Systems. Analysis, Observation, Filtering & Control<space/></arg><arg name="publisher"><space/>Springer Verlag Heidelberg<space/></arg><arg name="isbn"><space/>978-3-662-44049-0</arg></template></listitem></list><paragraph>For Chemical Engineering</paragraph><list type='bullet'><listitem><template><target>cite book</target><arg name="last"><space/>Luyben<space/></arg><arg name="first"><space/>William<space/></arg><arg name="authorlink"><space/></arg><arg name="year"><space/>1989<space/></arg><arg name="title"><space/>Process Modeling, Simulation, and Control for Chemical Engineers<space/></arg><arg name="publisher"><space/>Mc Graw Hill<space/></arg><arg name="isbn"><space/>0-07-039159-9</arg></template></listitem></list><heading level='2'>External links</heading><paragraph><template><target>Wikibooks</target><arg>Control Systems</arg></template><template><target>Commons category</target><arg>Control theory</arg></template></paragraph><list type='bullet'><listitem><link type='external' href='http://www.engin.umich.edu/class/ctms/'>Control Tutorials for Matlab</link>, a set of worked-through control examples solved by several different methods.</listitem><listitem><link type='external' href='http://www.controlguru.com'>Control Tuning and Best Practices</link></listitem><listitem><link type='external' href='http://www.PIDlab.com'>Advanced control structures, free on-line simulators explaining the control theory</link></listitem></list><paragraph><template><target>Cybernetics</target></template><template><target>Systems</target></template><template><target>Areas of mathematics</target></template></paragraph><paragraph><template><target>Authority control</target></template></paragraph><paragraph><template><target>DEFAULTSORT:Control Theory</target></template><link><target>Category:Control theory</target><part></part></link><link><target>Category:Cybernetics</target></link><link><target>Category:Formal sciences</target></link></paragraph></article>