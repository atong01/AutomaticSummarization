<article title='AI-complete'><paragraph>In the field of<space/><link><target>artificial intelligence</target></link>, the most difficult problems are informally known as<space/><bold>AI-complete</bold><space/>or<space/><bold>AI-hard</bold>, implying that the difficulty of these computational problems is equivalent to that of solving the central artificial intelligence problemmaking computers as intelligent as people, or<space/><link><target>artificial general intelligence</target><part>strong AI</part></link>.<extension extension_name='ref' name="Shapiro92">Shapiro, Stuart C. (1992).<space/><link type='external' href='http://www.cse.buffalo.edu/~shapiro/Papers/ai.pdf'>Artificial Intelligence</link><space/>In Stuart C. Shapiro (Ed.),<space/><italics>Encyclopedia of Artificial Intelligence</italics><space/>(Second Edition, pp.&amp;nbsp;5457). New York: John Wiley. (Section 4 is on &quot;AI-Complete Tasks&quot;.)</extension><space/>To call a problem AI-complete reflects an attitude that it would not be solved by a simple specific algorithm.<space/></paragraph><paragraph>AI-complete problems are hypothesised to include<space/><link><target>computer vision</target></link>,<space/><link><target>natural language understanding</target></link>, and dealing with unexpected circumstances while solving any real world problem.<extension extension_name='ref'>Roman V. Yampolskiy. Turing Test as a Defining Feature of AI-Completeness . In Artificial Intelligence, Evolutionary Computation and Metaheuristics (AIECM) --In the footsteps of Alan Turing. Xin-She Yang (Ed.). pp. 3-17. (Chapter 1). Springer, London. 2013. http://cecs.louisville.edu/ry/TuringTestasaDefiningFeature04270003.pdf</extension></paragraph><paragraph>Currently, AI-complete problems cannot be solved with modern computer technology alone, but would also require<space/><link><target>human computation</target></link>. This property can be useful, for instance to test for the presence of humans as with<space/><link><target>CAPTCHA</target><trail>s</trail></link>, and for<space/><link><target>computer security</target></link><space/>to circumvent<space/><link><target>brute-force attack</target><trail>s</trail></link>.<extension extension_name='ref'>Luis von Ahn, Manuel Blum, Nicholas Hopper, and John Langford.<space/><link type='external' href='http://www.captcha.net/captcha_crypt.pdf'>CAPTCHA: Using Hard AI Problems for Security</link>. In Proceedings of Eurocrypt, Vol. 2656 (2003), pp. 294-311.</extension><extension extension_name='ref'><template><target>cite paper</target><arg name="first"><space/>Richard<space/></arg><arg name="last"><space/>Bergmair<space/></arg><arg name="title"><space/>Natural Language Steganography and an "AI-complete" Security Primitive<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.105.129}}<space/></arg><arg name="date"><space/>January 7, 2006<space/></arg></template><space/>(unpublished?)</extension></paragraph><heading level='2'>History</heading><paragraph>The term was coined by<space/><link><target>Fanya Montalvo</target></link><space/>by analogy with<space/><link><target>NP-complete</target></link><space/>and<space/><link><target>NP-hard</target></link><space/>in<space/><link><target>Computational complexity theory</target><part>complexity theory</part></link>, which formally describes the most famous class of difficult problems.<extension extension_name='ref'><template><target>Citation</target><arg name="last">Mallery<space/></arg><arg name="first">John C.<space/></arg><arg name="year">1988<space/></arg><arg name="url">http://citeseer.ist.psu.edu/mallery88thinking.html<space/></arg><arg name="contribution">Thinking About Foreign Policy: Finding an Appropriate Role for Artificially Intelligent Computers<space/></arg><arg name="title">The 1988 Annual Meeting of the International Studies Association.<space/></arg><arg name="location">St. Louis, MO<space/></arg></template>.</extension><space/>Early uses of the term are in Erik Mueller's 1987 Ph.D. dissertation<extension extension_name='ref'>Mueller, Erik T. (1987, March).<space/><link type='external' href='ftp://ftp.cs.ucla.edu/tech-report/198_-reports/870017.pdf'>''Daydreaming and Computation'' (Technical Report CSD-870017)</link><space/>Ph.D. dissertation, University of California, Los Angeles. (&quot;Daydreaming is but one more<space/><italics>AI-complete</italics><space/>problem: if we could solve any one artificial intelligence problem, we could solve all the others&quot;, p.&amp;nbsp;302)</extension><space/>and in<space/><link><target>Eric S. Raymond</target><part>Eric Raymond</part></link>'s 1991<space/><link><target>Jargon File</target></link>.<extension extension_name='ref'>Raymond, Eric S. (1991, March 22).<space/><link type='external' href='http://catb.org/esr/jargon/oldversions/jarg282.txt'>Jargon File Version 2.8.1</link><space/>(Definition of &quot;AI-complete&quot; first added to jargon file.)</extension></paragraph><heading level='2'>AI-complete problems</heading><paragraph>AI-complete problems are hypothesised to include:</paragraph><list type='bullet'><listitem><link><target>Computer vision</target></link><space/>(and subproblems such as<space/><link><target>object recognition</target></link>)</listitem><listitem><link><target>Natural language understanding</target></link><space/>(and subproblems such as<space/><link><target>text mining</target></link>,<space/><link><target>machine translation</target></link>, and<space/><link><target>word sense disambiguation</target></link>)</listitem><listitem>Dealing with unexpected circumstances while solving any real world problem, whether it's<space/><link><target>robotic mapping</target><part>navigation</part></link><space/>or<space/><link><target>automated planning and scheduling</target><part>planning</part></link><space/>or even the kind of<space/><link><target>reasoning</target></link><space/>done by<space/><link><target>expert system</target><trail>s</trail></link>.</listitem></list><heading level='3'>Machine translation</heading><paragraph><template><target>main</target><arg>Machine translation</arg></template></paragraph><paragraph>To translate accurately, a machine must be able to understand the text. It must be able to follow the author's argument, so it must have some ability to<space/><link><target>artificial intelligence#Deduction, reasoning, problem solving</target><part>reason</part></link>. It must have extensive<space/><link><target>commonsense knowledge</target><part>world knowledge</part></link><space/>so that it knows what is being discussed it must at least be familiar with all the same commonsense facts that the average human translator knows. Some of this knowledge is in the form of facts that can be explicitly represented, but some knowledge is unconscious and closely tied to the human body: for example, the machine may need to understand how an ocean makes one<space/><italics>feel</italics><space/>to accurately translate a specific metaphor in the text. It must also model the authors' goals, intentions, and emotional states to accurately reproduce them in a new language. In short, the machine is required to have wide variety of human intellectual skills, including<space/><link><target>artificial intelligence#Deduction, reasoning, problem solving</target><part>reason</part></link>,<space/><link><target>commonsense knowledge</target></link><space/>and the intuitions that underlie<space/><link><target>robotics</target><part>motion and manipulation</part></link>,<space/><link><target>machine perception</target><part>perception</part></link>, and<space/><link><target>artificial intelligence#Social intelligence</target><part>social intelligence</part></link>.<space/><link><target>Machine translation</target></link>, therefore, is believed to be AI-complete: it may require strong AI to be done as well as humans can do it.</paragraph><heading level='2'>Software brittleness</heading><paragraph><template><target>main</target><arg>Software brittleness</arg></template>Current AI systems can solve very simple restricted versions of AI-complete problems, but never in their full generality. When AI researchers attempt to &quot;scale up&quot; their systems to handle more complicated, real world situations, the programs tend to become excessively<space/><link><target>brittle (software)</target><part>brittle</part></link><space/>without<space/><link><target>commonsense knowledge</target></link><space/>or a rudimentary understanding of the situation: they fail as unexpected circumstances outside of its original problem context begin to appear. When human beings are dealing with new situations in the world, they are helped immensely by the fact that they know what to expect: they know what all things around them are, why they are there, what they are likely to do and so on. They can recognize unusual situations and adjust accordingly. A machine without strong AI has no other skills to fall back on.<extension extension_name='ref'><template><target>Citation</target><arg name="last">Lenat<space/></arg><arg name="first">Douglas<space/></arg><arg name="last2">Guha<space/></arg><arg name="first2">R. V.</arg><arg name="year"><space/>1989<space/></arg><arg name="title"><space/>Building Large Knowledge-Based Systems<space/></arg><arg name="publisher"><space/>Addison-Wesley</arg><arg name="author-link">Douglas Lenat</arg><arg name="pages">1â€“5</arg></template></extension></paragraph><heading level='2'>Formalization</heading><paragraph><link><target>Computational complexity theory</target></link><space/>deals with the relative computational difficulty of<space/><link><target>computable function</target><trail>s</trail></link>. By definition it does not cover problems whose solution is unknown or has not been characterised formally. Since many AI problems have no formalisation yet, conventional complexity theory does not allow the definition of AI-completeness.</paragraph><paragraph>To address this problem, a complexity theory for AI has been proposed.<extension extension_name='ref' name="ucl.ac.uk">Dafna Shahaf and Eyal Amir (2007)<space/><link type='external' href='http://www.cs.uiuc.edu/~eyal/papers/ai-complete-commonsense07.pdf'>Towards a theory of AI completeness</link>.<space/><link type='external' href='http://www.ucl.ac.uk/commonsense07'>Commonsense 2007, 8th International Symposium on Logical Formalizations of Commonsense Reasoning</link>.</extension><space/>It is based on a<space/><link><target>model of computation</target></link><space/>that splits the computational burden between a computer and a human: one part is solved by computer and the other part solved by human. This is formalised by a<space/><bold>human-assisted<space/><link><target>Turing machine</target></link></bold>. The formalisation defines algorithm complexity, problem complexity and reducibility which in turn allows<space/><link><target>equivalence class</target><trail>es</trail></link><space/>to be defined.</paragraph><paragraph>The complexity of executing an algorithm with a human-assisted Turing machine is given by a pair<space/><extension extension_name='math'>\langle\Phi_{H},\Phi_{M}\rangle</extension>, where the first element represents the complexity of the human's part and the second element is the complexity of the machine's part.</paragraph><heading level='3'>Results</heading><paragraph>The complexity of solving the following problems with a human-assisted Turing machine is:<extension extension_name='ref' name="ucl.ac.uk"></extension></paragraph><list type='bullet'><listitem><link><target>Optical character recognition</target></link><space/>for printed text:<space/><extension extension_name='math'>\langle O(1), poly(n) \rangle<space/></extension></listitem><listitem><link><target>Turing test</target></link>:<list type='bullet'><listitem>for an<space/><extension extension_name='math'>n</extension>-sentence conversation where the oracle remembers the conversation history (persistent oracle):<space/><extension extension_name='math'>\langle O(n), O(n) \rangle<space/></extension></listitem><listitem>for an<space/><extension extension_name='math'>n</extension>-sentence conversation where the conversation history must be retransmitted:<space/><extension extension_name='math'>\langle O(n), O(n^2) \rangle<space/></extension></listitem><listitem>for an<space/><extension extension_name='math'>n</extension>-sentence conversation where the conversation history must be retransmitted and the person takes linear time to read the query:<space/><extension extension_name='math'>\langle O(n^2), O(n^2) \rangle<space/></extension></listitem></list></listitem><listitem><link><target>ESP game</target></link>:<space/><extension extension_name='math'>\langle O(n), O(n) \rangle<space/></extension></listitem><listitem>Image labelling (based on the<space/><link><target>ArthurMerlin protocol</target></link>):<space/><extension extension_name='math'>\langle O(n), O(n) \rangle<space/></extension></listitem><listitem><link><target>Object categorization from image search</target><part>Image classification</part></link>: human only:<space/><extension extension_name='math'>\langle O(n), O(n) \rangle<space/></extension>, and with less reliance on the human:<space/><extension extension_name='math'>\langle O(\log n), O(n \log n) \rangle<space/></extension>.</listitem></list><heading level='2'>See also</heading><list type='bullet'><listitem><link><target>ASR-complete</target></link></listitem><listitem><link><target>List of unsolved problems in computer science</target></link></listitem><listitem><link><target>Synthetic intelligence</target></link></listitem></list><heading level='2'>References</heading><paragraph><extension extension_name='references'></extension></paragraph><paragraph><template><target>Unsolved problems</target></template><template><target>Natural Language Processing</target></template></paragraph><paragraph><template><target>DEFAULTSORT:Ai-Complete</target></template><link><target>Category:Artificial intelligence</target></link><link><target>Category:Computational problems</target></link></paragraph></article>