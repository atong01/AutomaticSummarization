<article title='Bayesian_probability'><paragraph><template><target>Bayesian statistics</target></template><bold>Bayesian probability</bold><space/>is one<space/><link><target>Probability interpretations</target><part>interpretation</part></link><space/>of the concept of<space/><link><target>probability</target></link>. In contrast to interpreting probability as<space/><link><target>frequentist probability</target><part>frequency</part></link><space/>or<space/><link><target>propensity probability</target><part>propensity</part></link><space/>of some phenomenon, Bayesian probability is a quantity that we assign for the purpose of representing a state of knowledge,<extension extension_name='ref' name="ghxaib">Jaynes, E.T. &quot;Bayesian Methods: General Background.&quot; In Maximum-Entropy and Bayesian Methods in Applied Statistics, by J. H. Justice (ed.). Cambridge: Cambridge Univ. Press, 1986</extension><space/>or a state of belief.<extension extension_name='ref' name="Finetti, B. 1974"></extension><space/>In the Bayesian view, a probability is assigned to a hypothesis, whereas under<space/><link><target>frequentist inference</target></link>, a hypothesis is typically<space/><link><target>hypothesis test</target><part>tested</part></link><space/>without being assigned a probability.</paragraph><paragraph>The Bayesian interpretation of probability can be seen as an extension of<space/><link><target>propositional logic</target></link><space/>that enables reasoning with hypotheses, i.e., the propositions whose<space/><link><target>truth value</target><part>truth or falsity</part></link><space/>is uncertain.</paragraph><paragraph>Bayesian probability belongs to the category of evidential probabilities; to evaluate the probability of a hypothesis, the Bayesian probabilist specifies some prior probability, which is then updated in the light of new, relevant<space/><link><target>data</target></link><space/>(evidence).<extension extension_name='ref' name="paulos"><link><target>John Allen Paulos</target><part>Paulos, John Allen</part></link>.<space/><link type='external' href='http://www.nytimes.com/2011/08/07/books/review/the-theory-that-would-not-die-by-sharon-bertsch-mcgrayne-book-review.html?_r=1&amp;amp;scp=1&amp;amp;sq=thomas%20bayes&amp;amp;st=cse'>''The Mathematics of Changing Your Mind,''</link><space/>New York Times (US). August 5, 2011; retrieved 2011-08-06</extension><space/>The Bayesian interpretation provides a standard set of procedures and formulae to perform this calculation.</paragraph><paragraph>The term &quot;Bayesian&quot; derives from the 18th century mathematician and theologian<space/><link><target>Thomas Bayes</target></link>, who provided the first mathematical treatment of a non-trivial problem of<space/><link><target>Bayesian inference</target></link>.<extension extension_name='ref'>Stigler, Stephen M. (1986)<space/><italics>The history of statistics.</italics><space/><link><target>Harvard University Press</target></link>. pg 131.</extension><space/>Mathematician<space/><link><target>Pierre-Simon Laplace</target></link><space/>pioneered and popularised what is now called Bayesian probability.<extension extension_name='ref'>Stigler, Stephen M. (1986)<space/><italics>The history of statistics.</italics>, Harvard University press. pp. 9798, 131.</extension></paragraph><paragraph>Broadly speaking, there are two views on Bayesian probability that interpret the<space/><italics>probability</italics><space/>concept in different ways. According to the<space/><italics>objectivist view</italics>, the rules of Bayesian statistics can be justified by<space/><link><target>Cox's theorem</target><part>requirements of rationality and consistency</part></link><space/>and interpreted as an extension of<space/><link><target>logic</target></link>.<extension extension_name='ref' name="ghxaib"></extension><extension extension_name='ref' name="vkdmsn">Cox, Richard T.<space/><italics>Algebra of Probable Inference</italics>, The Johns Hopkins University Press, 2001</extension><space/>According to the<space/><italics>subjectivist view</italics>, probability quantifies a &quot;personal belief&quot;.<extension extension_name='ref' name="Finetti, B. 1974">de Finetti, B. (1974)<space/><italics>Theory of probability</italics><space/>(2 vols.), J. Wiley &amp; Sons, Inc., New York</extension></paragraph><heading level='2'>Bayesian methodology</heading><paragraph>Bayesian methods are characterized by the following concepts and procedures:</paragraph><list type='bullet'><listitem>The use of random variables, or, more generally, unknown quantities,<extension extension_name='ref' name="rbp"></extension><space/>to model all sources of uncertainty in statistical models. This also includes uncertainty resulting from lack of information (see also the<space/><link><target>Uncertainty quantification#Aleatoric and epistemic uncertainty</target><part>aleatoric and epistemic uncertainty</part></link>).</listitem><listitem>The need to determine the<space/><italics>prior probability distribution</italics><space/>taking into account the available (prior) information.</listitem><listitem>The<space/><italics>sequential use of the<space/><link><target>Bayes' formula</target></link></italics>: when more data becomes available, calculate the<space/><italics>posterior distribution</italics><space/>using the Bayes' formula; subsequently, the posterior distribution becomes the next prior.</listitem><listitem>For the frequentist a<space/><link><target>null hypothesis</target><part>hypothesis</part></link><space/>is a<space/><link><target>Proposition#Treatment in logic</target><part>proposition</part></link><space/>(which must be<space/><link><target>principle of bivalence</target><part>either true or false</part></link>), so that the frequentist probability of a hypothesis is either one or zero. In Bayesian statistics, a probability can be assigned to a hypothesis that can differ from 0 or 1 if the truth value is uncertain.</listitem></list><heading level='2'>Objective and subjective Bayesian probabilities</heading><paragraph>Broadly speaking, there are two views on Bayesian probability that interpret the 'probability' concept in different ways. For<space/><italics><link><target>Objectivity (philosophy)</target><part>objectivists</part></link></italics>,<space/><italics>probability</italics><space/>objectively measures the plausibility of propositions, i.e. the probability of a proposition corresponds to a reasonable belief everyone (even a &quot;robot&quot;) sharing the same knowledge should share in accordance with the rules of Bayesian statistics, which can be justified by<space/><link><target>Cox's theorem</target><part>requirements of rationality and consistency</part></link>.<extension extension_name='ref' name="ghxaib"></extension><extension extension_name='ref' name="vkdmsn"></extension><space/>For<space/><italics><link><target>Subjectivism</target><part>subjectivists</part></link></italics>, probability corresponds to a 'personal belief'.<extension extension_name='ref' name="Finetti, B. 1974"></extension><space/>For subjectivists, rationality and coherence constrain the probabilities a subject may have, but allow for substantial variation within those constraints. The objective and subjective variants of Bayesian probability differ mainly in their interpretation and construction of the prior probability.</paragraph><heading level='2'>History</heading><paragraph><template><target>Main</target><arg>History of statistics#Bayesian statistics</arg></template></paragraph><paragraph>The term<space/><italics>Bayesian</italics><space/>refers to<space/><link><target>Thomas Bayes</target></link><space/>(17021761), who proved a special case of what is now called<space/><link><target>Bayes' theorem</target></link><space/>in a paper titled &quot;<link><target>An Essay towards solving a Problem in the Doctrine of Chances</target></link>&quot;.<extension extension_name='ref'>McGrayne, Sharon Bertsch. (2011).<space/><template><target>Google books</target><arg>_Kx5xVGuLRIC</arg><arg>''The Theory That Would Not Die,'' p. 10.</arg><arg name="page">10</arg></template></extension><space/>In that special case, the prior and posterior distributions were<space/><link><target>Beta distribution</target><trail>s</trail></link><space/>and the data came from<space/><link><target>Bernoulli trial</target><trail>s</trail></link>. It was<space/><link><target>Pierre-Simon Laplace</target></link><space/>(17491827) who introduced a general version of the theorem and used it to approach problems in<space/><link><target>celestial mechanics</target></link>, medical statistics,<space/><link><target>Reliability (statistics)</target><part>reliability</part></link>, and<space/><link><target>jurisprudence</target></link>.<extension extension_name='ref'>Stigler, Stephen M. (1986)<space/><italics>The history of statistics.</italics><space/>Harvard University press. Chapter 3.</extension><space/>Early Bayesian inference, which used uniform priors following Laplace's<space/><link><target>principle of insufficient reason</target></link>, was called &quot;<link><target>inverse probability</target></link>&quot; (because it<space/><link><target>Inductive reasoning</target><part>infer</part><trail>s</trail></link><space/>backwards from observations to parameters, or from effects to causes).<extension extension_name='ref' name="Fienberg2006">Fienberg, Stephen. E. (2006)<space/><link type='external' href='http://ba.stat.cmu.edu/journal/2006/vol01/issue01/fienberg.pdf'>''When did Bayesian Inference become &quot;Bayesian&quot;?''</link><space/><italics>Bayesian Analysis</italics>, 1 (1), 140. See page 5.</extension><space/>After the 1920s, &quot;inverse probability&quot; was largely supplanted by a collection of methods that came to be called<space/><link><target>frequentist statistics</target></link>.<extension extension_name='ref' name="Fienberg2006"></extension></paragraph><paragraph>In the 20th century, the ideas of Laplace were further developed in two different directions, giving rise to<space/><italics>objective</italics><space/>and<space/><italics>subjective</italics><space/>currents in Bayesian practice.<link><target>Harold Jeffreys</target></link>'<space/><italics>Theory of Probability</italics><space/>(first published in 1939) played an important role in the revival of the Bayesian view of probability, followed by works by<space/><link><target>Abraham Wald</target></link><space/>(1950) and<space/><link><target>Leonard J. Savage</target></link><space/>(1954). The adjective<space/><italics>Bayesian</italics><space/>itself dates to the 1950s; the derived<space/><italics>Bayesianism</italics>,<space/><italics>neo-Bayesianism</italics><space/>is of 1960s coinage.<extension extension_name='ref'><paragraph>&quot;The works of<space/><link><target>Abraham Wald</target><part>Wald</part></link>,<space/><italics>Statistical Decision Functions</italics><space/>(1950) and<space/><link><target>Leonard J. Savage</target><part>Savage</part></link>,<space/><italics>The Foundation of Statistics</italics><space/>(1954) are commonly regarded starting points for current Bayesian approaches&quot;;&quot;Recent developments of the so-called Bayesian approach to statistics&quot;Marshall Dees Harris,<space/><italics>Legal-economic research</italics>, University of Iowa. Agricultural Law Center (1959), p. 125 (fn. 52); p. 126.</paragraph><paragraph>&quot;This revolution, which may or may not succeed, is neo-Bayesianism. Jeffreys tried to introduce this approach, but did not succeed at the time in giving it general appeal.&quot;<space/><italics>Annals of the Computation Laboratory of Harvard University</italics><space/>31 (1962), p. 180.&quot;It is curious that even in its activities unrelated to ethics, humanity searches for a religion. At the present time, the religion being 'pushed' the hardest is Bayesianism.&quot;Oscar Kempthorne, 'The Classical Problem of InferenceGoodness of Fit',<space/><italics>Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability</italics><space/>(1967),<space/><link type='external' href='https://books.google.ch/books?id=IC4Ku_7dBFUC&amp;amp;pg=PA235#v=onepage&amp;amp;q&amp;amp;f=false'>p. 235</link>.</paragraph></extension>In the objectivist stream, the statistical analysis depends on only the model assumed and the data analysed.<extension extension_name='ref' name="Bernardo"><link><target>Jos-Miguel Bernardo</target><part>Bernardo, J.M.</part></link><space/>(2005),<space/><italics>Reference analysis</italics>,<space/><italics>Handbook of statistics</italics>, 25, 1790</extension><space/>No subjective decisions need to be involved. In contrast, &quot;subjectivist&quot; statisticians deny the possibility of fully objective analysis for the general case.</paragraph><paragraph>In the 1980s, there was a dramatic growth in research and applications of Bayesian methods, mostly attributed to the discovery of<space/><link><target>Markov chain Monte Carlo</target></link><space/>methods, which removed many of the computational problems, and an increasing interest in nonstandard, complex applications.<extension extension_name='ref'>Wolpert, R.L. (2004)<space/><italics>A conversation with James O. Berger</italics>, Statistical science, 9, 205218</extension><space/>Despite the growth of Bayesian research, most undergraduate teaching is still based on frequentist statistics.<extension extension_name='ref'><link><target>Jos-Miguel Bernardo</target><part>Bernardo, Jos M.</part></link><space/>(2006)<space/><link type='external' href='http://www.ime.usp.br/~abe/ICOTS7/Proceedings/PDFs/InvitedPapers/3I2_BERN.pdf'>''A Bayesian mathematical statistics primer''</link>. ICOTS-7</extension><template><target>citation needed</target><arg name="date">August 2012</arg></template><space/>Nonetheless, Bayesian methods are widely accepted and used, such as in the field of<space/><link><target>machine learning</target></link>.<extension extension_name='ref' name="ReferenceA">Bishop, C.M.<space/><italics>Pattern Recognition and Machine Learning.</italics><space/>Springer, 2007</extension></paragraph><heading level='2'>Justification of Bayesian probabilities</heading><paragraph>The use of Bayesian probabilities as the basis of<space/><link><target>Bayesian inference</target></link><space/>has been supported by several arguments, such as the<space/><link><target>Cox's theorem</target><part>Cox axioms</part></link>, the<space/><link><target>Dutch book</target><part>Dutch book argument</part></link>, arguments based on<space/><link><target>decision theory</target></link><space/>and<space/><link><target>de Finetti's theorem</target></link>.</paragraph><heading level='3'>Axiomatic approach</heading><paragraph><link><target>Richard Threlkeld Cox</target><part>Richard T. Cox</part></link><space/>showed that<extension extension_name='ref' name="vkdmsn"></extension><space/>Bayesian updating follows from several axioms, including two<space/><link><target>functional equations</target></link><space/>and a hypothesis of differentiability. The assumption of differentiability or even continuity is controversial; Halpern found a counterexample based on his observation that the Boolean algebra of statements may be finite.<extension extension_name='ref'>Halpern, J.<space/><italics>A counterexample to theorems of Cox and Fine</italics>, Journal of Artificial Intelligence Research, 10: 6785.</extension><space/>Other axiomatizations have been suggested by various authors to make the theory more rigorous.<extension extension_name='ref' name="rbp">Dupr, Maurice J., Tipler, Frank T.<space/><link type='external' href='http://ba.stat.cmu.edu/journal/2009/vol04/issue03/dupre.pdf'>''New Axioms For Bayesian Probability''</link>, Bayesian Analysis (2009), Number 3, pp. 599606</extension></paragraph><heading level='3'>Dutch book approach</heading><paragraph>The Dutch book argument was proposed by de Finetti, and is based on betting. A<space/><link><target>Dutch book</target></link><space/>is made when a clever gambler places a set of bets that guarantee a profit, no matter what the outcome of the bets. If a<space/><link><target>bookmaker</target></link><space/>follows the rules of the Bayesian calculus in the construction of his odds, a Dutch book cannot be made.</paragraph><paragraph>However,<space/><link><target>Ian Hacking</target></link><space/>noted that traditional Dutch book arguments did not specify Bayesian updating: they left open the possibility that non-Bayesian updating rules could avoid Dutch books. For example,<space/><link><target>Ian Hacking</target><part>Hacking</part></link><space/>writes<extension extension_name='ref'>Hacking (1967, Section 3, page 316), Hacking (1988, page 124)</extension><space/>&quot;And neither the Dutch book argument, nor any other in the personalist arsenal of proofs of the probability axioms, entails the dynamic assumption. Not one entails Bayesianism. So the personalist requires the dynamic assumption to be Bayesian. It is true that in consistency a personalist could abandon the Bayesian model of learning from experience. Salt could lose its savour.&quot;</paragraph><paragraph>In fact, there are non-Bayesian updating rules that also avoid Dutch books (as discussed in the literature on &quot;probability kinematics&quot; following the publication of<space/><link><target>Richard Jeffrey</target><part>Richard C. Jeffreys</part></link>' rule, which is itself regarded as Bayesian<space/><extension extension_name='ref'><template><target>cite web</target><arg name="url">http://plato.stanford.edu/entries/bayes-theorem/</arg><arg name="title">Bayes' Theorem</arg><arg name="work">stanford.edu</arg></template></extension>). The additional hypotheses sufficient to (uniquely) specify Bayesian updating are substantial, complicated, and unsatisfactory.<extension extension_name='ref'><link><target>Bas van Fraassen</target><part>van Frassen, B.</part></link><space/>(1989)<space/><italics>Laws and Symmetry</italics>, Oxford University Press. ISBN 0-19-824860-1</extension></paragraph><heading level='3'>Decision theory approach</heading><paragraph>A<space/><link><target>statistical decision theory</target><part>decision-theoretic</part></link><space/>justification of the use of Bayesian inference (and hence of Bayesian probabilities) was given by<space/><link><target>Abraham Wald</target></link>, who proved that every<space/><link><target>admissible decision rule</target><part>admissible</part></link><space/>statistical procedure is either a Bayesian procedure or a limit of Bayesian procedures.<extension extension_name='ref'>Wald, Abraham.<space/><italics>Statistical Decision Functions.</italics><space/>Wiley 1950.</extension><space/>Conversely, every Bayesian procedure is<space/><link><target>admissible decision rule</target><part>admissible</part></link>.<extension extension_name='ref'>Bernardo, Jos M., Smith, Adrian F.M.<space/><italics>Bayesian Theory.</italics><space/>John Wiley 1994. ISBN 0-471-92416-4.</extension></paragraph><heading level='2'>Personal probabilities and objective methods for constructing priors</heading><paragraph>Following the work on<space/><link><target>expected utility</target></link><space/><link><target>optimal decision</target><part>theory</part></link><space/>of<space/><link><target>Frank P. Ramsey</target><part>Ramsey</part></link><space/>and<space/><link><target>John von Neumann</target><part>von Neumann</part></link>, decision-theorists have accounted for<space/><link><target>optimal decision</target><part>rational behavior</part></link><space/>using a probability distribution for the<space/><link><target>Agent-based model</target><part>agent</part></link>. Johann Pfanzagl completed the<space/><italics><link><target>Theory of Games and Economic Behavior</target></link></italics><space/>by providing an axiomatization of subjective probability and utility, a task left uncompleted by von Neumann and<space/><link><target>Oskar Morgenstern</target></link>: their original theory supposed that all the agents had the same probability distribution, as a convenience.<extension extension_name='ref'>Pfanzagl (1967, 1968)</extension><space/>Pfanzagl's axiomatization was endorsed by Oskar Morgenstern: &quot;Von Neumann and I have anticipated&quot; the question whether probabilities &quot;might, perhaps more typically, be subjective and have stated specifically that in the latter case axioms could be found from which could derive the desired numerical utility together with a number for the probabilities (cf. p. 19 of The<space/><link><target>Theory of Games and Economic Behavior</target></link>). We did not carry this out; it was demonstrated by Pfanzagl ... with all the necessary rigor&quot;.<extension extension_name='ref'>Morgenstern (1976, page 65)</extension></paragraph><paragraph>Ramsey and<space/><link><target>Leonard Jimmie Savage</target><part>Savage</part></link><space/>noted that the individual agent's probability distribution could be objectively studied in experiments. The role of judgment and disagreement in science has been recognized since<space/><link><target>Aristotle</target></link><space/>and even more clearly with<space/><link><target>Francis Bacon</target></link>. The objectivity of science lies not in the psychology of individual scientists, but in the process of science and especially in statistical methods, as noted by<space/><link><target>Charles Sanders Peirce</target><part>C. S. Peirce</part></link>.<extension extension_name='ref'><template><target>cite journal</target><arg name="last">Stigler<space/></arg><arg name="first">Stephen M.<space/></arg><arg name="year">1978<space/></arg><arg name="authorlink">Stephen Stigler<space/></arg><arg name="title">Mathematical statistics in the early States<space/></arg><arg name="journal">Annals of Statistics<space/></arg><arg name="volume">6<space/></arg><arg name="issue">March<space/></arg><arg name="pages">239–265 esp. p. 248<space/></arg><arg name="publisher"><space/></arg><arg name="doi">10.1214/aos/1176344123<space/></arg><arg name="jstor">2958876<space/></arg><arg name="mr">483118<space/></arg><arg name="url">http://projecteuclid.org/euclid.aos/1176344123<space/></arg><arg name="accessdate"><space/></arg><arg name="ref">harv<space/></arg></template></extension><space/>Recall that the objective methods for falsifying propositions about personal probabilities have been used for a half century, as noted previously. Procedures for<space/><link><target>statistical hypothesis testing</target><part>testing hypotheses</part></link><space/>about probabilities (using finite samples) are due to<space/><link><target>Frank P. Ramsey</target><part>Ramsey</part></link><space/>(1931) and<space/><link><target>Bruno de Finetti</target><part>de Finetti</part></link><space/>(1931, 1937, 1964, 1970). Both<space/><link><target>Bruno de Finetti</target></link><space/>and<space/><link><target>Frank P. Ramsey</target></link><space/>acknowledge<template><target>Citation needed</target><arg name="date">September 2010</arg></template><space/>their debts to<space/><link><target>pragmatic philosophy</target></link>, particularly (for Ramsey) to<space/><link><target>Charles Sanders Peirce</target><part>Charles S. Peirce</part></link>.</paragraph><paragraph>The &quot;Ramsey test&quot; for evaluating probability distributions is implementable in theory, and has kept experimental psychologists occupied for a half century.<extension extension_name='ref'>Davidson et al. (1957)</extension>This work demonstrates that Bayesian-probability propositions can be<space/><link><target>Falsifiability</target><part>falsified</part></link>, and so meet an empirical criterion of<space/><link><target>Charles Sanders Peirce</target><part>Charles S. Peirce</part></link>, whose work inspired Ramsey. (This<space/><link><target>falsifiability</target></link>-criterion was popularized by<space/><link><target>Karl Popper</target></link>.<extension extension_name='ref'><link type='external' href='http://plato.stanford.edu/entries/popper/#ProDem'>&quot;Karl Popper&quot; in ''Stanford Encyclopedia of Philosophy''</link></extension><extension extension_name='ref'>Popper, Karl. (2002)<space/><link type='external' href='https://books.google.com/books?id=T76Zd20IYlgC&amp;amp;printsec=frontcover&amp;amp;dq=logic+of+scientific+discovery&amp;amp;source=bl&amp;amp;ots=eGfU8COmAA&amp;amp;sig=W8TTt29x5sG8aCGpYuWnonDFH8M&amp;amp;hl=en&amp;amp;ei=crC3TJKND46ssAPp06jkCA&amp;amp;sa=X&amp;amp;oi=book_result&amp;amp;ct=result&amp;amp;resnum=3&amp;amp;ved=0CCAQ6AEwAg#v=onepage&amp;amp;q=falsifiability&amp;amp;f=false'>''The Logic of Scientific Discovery''</link><space/>2nd Edition, Routledge ISBN 0-415-27843-0 (Reprint of 1959 translation of 1935 original) Page 57.</extension>)</paragraph><paragraph>Modern work on the experimental evaluation of personal probabilities uses the randomization,<space/><link><target>double blind</target><part>blinding</part></link>, and Boolean-decision procedures of the Peirce-Jastrow experiment.<extension extension_name='ref'>Peirce &amp; Jastrow (1885)</extension><space/>Since individuals act according to different probability judgments, these agents' probabilities are &quot;personal&quot; (but amenable to objective study).</paragraph><paragraph>Personal probabilities are problematic for science and for some applications where decision-makers lack the knowledge or time to specify an informed probability-distribution (on which they are prepared to act). To meet the needs of science and of human limitations, Bayesian statisticians have developed &quot;objective&quot; methods for specifying prior probabilities.</paragraph><paragraph>Indeed, some Bayesians have argued the prior state of knowledge defines<space/><italics>the</italics><space/>(unique) prior probability-distribution for &quot;regular&quot; statistical problems; cf.<space/><link><target>well-posed problem</target><trail>s</trail></link>. Finding the right method for constructing such &quot;objective&quot; priors (for appropriate classes of regular problems) has been the quest of statistical theorists from Laplace to<space/><link><target>John Maynard Keynes</target></link>,<space/><link><target>Harold Jeffreys</target></link>, and<space/><link><target>Edwin Thompson Jaynes</target></link>: These theorists and their successors have suggested several methods for constructing &quot;objective&quot; priors:</paragraph><list type='bullet'><listitem><link><target>principle of maximum entropy</target><part>Maximum entropy</part></link></listitem><listitem><link><target>Haar measure</target><part>Transformation group analysis</part></link></listitem><listitem><link><target>Jos-Miguel Bernardo</target><part>Reference analysis</part></link></listitem></list><paragraph>Each of these methods contributes useful priors for &quot;regular&quot; one-parameter problems, and each prior can handle some challenging<space/><link><target>statistical model</target><trail>s</trail></link><space/>(with &quot;irregularity&quot; or several parameters). Each of these methods has been useful in Bayesian practice. Indeed, methods for constructing &quot;objective&quot; (alternatively, &quot;default&quot; or &quot;ignorance&quot;) priors have been developed by avowed subjective (or &quot;personal&quot;) Bayesians like<space/><link><target>James Berger (statistician)</target><part>James Berger</part></link><space/>(<link><target>Duke University</target></link>) and<space/><link><target>Jos-Miguel Bernardo</target></link><space/>(<link><target>University of Valencia</target><part>Universitat de Valncia</part></link>), simply because such priors are needed for Bayesian practice, particularly in science.<extension extension_name='ref' name="refa">Bernardo, J. M. (2005).<space/><link type='external' href='http://www.uv.es/~bernardo/RefAna.pdf'>''Reference Analysis''</link>.<space/><italics>Handbook of Statistics</italics><space/>25 (D. K. Dey and<space/><link><target>C. R. Rao</target></link><space/>eds). Amsterdam: Elsevier, 1790</extension><space/>The quest for &quot;the universal method for constructing priors&quot; continues to attract statistical theorists.<extension extension_name='ref' name="refa"></extension></paragraph><paragraph>Thus, the Bayesian statistician needs either to use informed priors (using relevant expertise or previous data) or to choose among the competing methods for constructing &quot;objective&quot; priors.</paragraph><heading level='2'>See also</heading><list type='bullet'><listitem><link><target>Bertrand paradox (probability)</target><part>Bertrand paradox</part></link>&amp;nbsp; a paradox in classical probability, solved by<space/><link><target>Edwin Jaynes</target><part>E.T. Jaynes</part></link><space/>in the context of Bayesian probability</listitem><listitem><link><target>De Finetti's game</target></link>&amp;nbsp; a procedure for evaluating someone's subjective probability</listitem><listitem><link><target>QBism</target></link>&amp;nbsp; a controversial application of Bayesian probabilities to<space/><link><target>quantum mechanics</target></link></listitem><listitem><link><target>Uncertainty</target></link></listitem><listitem><italics><link><target>An Essay towards solving a Problem in the Doctrine of Chances</target></link></italics></listitem></list><heading level='2'>References</heading><paragraph><template><target>Reflist</target><arg>30em</arg></template></paragraph><heading level='2'>Bibliography</heading><list type='bullet'><listitem><template><target>Cite book</target><arg name="author">[[James Berger (statistician)|Berger, James O.]]</arg><arg name="title">Statistical Decision Theory and Bayesian Analysis</arg><arg name="edition">Second</arg><arg name="year">1985</arg><arg name="publisher">Springer-Verlag</arg><arg name="series">Springer Series in Statistics</arg><arg name="isbn">0-387-96098-8</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Bessière</arg><arg name="first">Pierre</arg><arg name="title">Bayesian Programming</arg><arg name="year">2013</arg><arg name="publisher">CRC Press</arg><arg name="isbn">9781439880326<space/></arg><arg name="author2">Mazer, E.<space/></arg><arg name="author3">Ahuacatzin, J-M<space/></arg><arg name="author4">Mekhnacha, K.</arg></template></listitem><listitem><template><target>Cite book</target><arg name="title">Bayesian Theory</arg><arg name="publisher">Wiley</arg><arg name="year">1994</arg><arg name="isbn">0-471-49464-X</arg><arg name="authorlink1">José-Miguel Bernardo</arg><arg name="last1">Bernardo</arg><arg name="first1">José&nbsp;M.</arg><arg name="authorlink2">Adrian Smith (statistician)</arg><arg name="last2">Smith</arg><arg name="first2">Adrian F.&nbsp;M.</arg></template></listitem><listitem><template><target>Cite book</target><arg name="last1">Bickel</arg><arg name="first1">Peter J.</arg><arg name="last2">Doksum</arg><arg name="first2">Kjell A.</arg><arg name="authorlink1">Peter J. Bickel</arg><arg name="title">Mathematical statistics, Volume&nbsp;1: Basic and selected topics</arg><arg name="edition">Second (updated printing 2007) of the Holden-Day&nbsp;1976</arg><arg name="mr">443141</arg><arg name="year">2001</arg><arg name="publisher">Pearson Prentice–Hall</arg><arg name="isbn">0-13-850363-X</arg><arg name="ref">harv</arg></template></listitem><listitem><template><target>Cite book</target><arg name="authorlink1">Donald Davidson (philosopher)</arg><arg name="first1">Donald<space/></arg><arg name="last1">Davidson</arg><arg name="authorlink2">Patrick Suppes</arg><arg name="first2">Patrick</arg><arg name="last2">Suppes</arg><arg name="authorlink3">Sidney Siegel</arg><arg name="first3">Sidney</arg><arg name="last3">Siegel</arg><arg name="title">Decision-Making: An Experimental Approach</arg><arg name="publisher">[[Stanford University Press]]</arg><arg name="year">1957</arg></template></listitem><listitem><link><target>Bruno de Finetti</target><part>de&amp;nbsp;Finetti, Bruno</part></link>. &quot;Probabilism: A Critical Essay on the Theory of Probability and on the Value of Science,&quot; (translation of 1931 article) in<space/><italics>Erkenntnis,</italics><space/>volume 31, September 1989.</listitem><listitem>de&amp;nbsp;Finetti, Bruno (1937) &quot;La Prvision: ses lois logiques, ses sources subjectives,&quot; Annales de l'Institut Henri Poincar,</listitem><listitem>de&amp;nbsp;Finetti, Bruno. &quot;Foresight: its Logical Laws, Its Subjective Sources,&quot; (translation of the<space/><link type='external' href='http://www.numdam.org/item?id=AIHP_1937__7_1_1_0'>1937 article</link><space/>in French) in H. E. Kyburg and H. E. Smokler (eds),<space/><italics>Studies in Subjective Probability,</italics><space/>New York: Wiley, 1964.</listitem><listitem>de&amp;nbsp;Finetti, Bruno (19745).<space/><italics>Theory of Probability. A Critical Introductory Treatment</italics>, (translation by A.Machi and<space/><link><target>AFM Smith</target></link><space/>of 1970 book) 2 volumes. Wiley ISBN 0-471-20141-3, ISBN 0-471-20142-1</listitem><listitem><link><target>Morris DeGroot</target><part>DeGroot, Morris</part></link><space/>(2004)<space/><italics>Optimal Statistical Decisions</italics>. Wiley Classics Library. (Originally published 1970.) ISBN 0-471-68029-X.</listitem><listitem><template><target>cite journal</target><arg name="doi">10.1086/288169</arg><arg name="title">Slightly More Realistic Personal Probability</arg><arg name="first">Ian</arg><arg name="last">Hacking</arg><arg name="authorlink">Ian Hacking<space/></arg><arg name="journal">Philosophy of Science<space/></arg><arg name="volume">34<space/></arg><arg name="issue">4</arg><arg name="date">December 1967<space/></arg><arg name="pages">311–325<space/></arg><arg name="jstor">186120</arg></template><space/>Partly reprinted in:<space/><link><target>Peter Grdenfors</target><part>Grdenfors, Peter</part></link><space/>and Sahlin, Nils-Eric. (1988)<space/><italics>Decision, Probability, and Utility: Selected Readings</italics>. 1988. Cambridge University Press. ISBN 0-521-33658-9</listitem><listitem>Hajek, A. and Hartmann, S. (2010): &quot;Bayesian Epistemology&quot;, in: Dancy, J., Sosa, E., Steup, M. (Eds.) (2001)<space/><italics>A Companion to Epistemology</italics>, Wiley. ISBN 1-4051-3900-5<space/><link type='external' href='http://stephanhartmann.org/HajekHartmann_BayesEpist.pdf'>Preprint</link></listitem><listitem><template><target>Cite book</target><arg name="last">Hald<space/></arg><arg name="first">Anders<space/></arg><arg name="authorlink">Anders Hald<space/></arg><arg name="title">A History of Mathematical Statistics from 1750 to 1930<space/></arg><arg name="year">1998<space/></arg><arg name="publisher">Wiley<space/></arg><arg name="location">New York<space/></arg><arg name="isbn">0-471-17912-4<space/></arg><arg name="page"><space/></arg><arg name="pages"><space/></arg><arg name="url"><space/></arg></template></listitem><listitem>Hartmann, S. and Sprenger, J. (2011) &quot;Bayesian Epistemology&quot;, in: Bernecker, S. and Pritchard, D. (Eds.) (2011)<space/><italics>Routledge Companion to Epistemology</italics>. Routledge. ISBN 978-0-415-96219-3 (<link type='external' href='http://stephanhartmann.org/HartmannSprenger_BayesEpis.pdf'>Preprint</link>)</listitem><listitem><template><target>springer</target><arg name="title">Bayesian approach to statistical problems</arg><arg name="id">p/b015390</arg></template></listitem><listitem><template><target>Cite book</target><arg name="title">Scientific Reasoning: the Bayesian Approach</arg><arg name="authorlink1">Colin Howson</arg><arg name="last1">Howson</arg><arg name="first1">C.</arg><arg name="last2">Urbach</arg><arg name="first2">P.</arg><arg name="publisher">[[Open Court Publishing Company]]</arg><arg name="year">2005</arg><arg name="edition">3rd<space/></arg><arg name="isbn">978-0-8126-9578-6</arg></template></listitem><listitem><link><target>Edwin Thompson Jaynes</target><part>Jaynes E.T.</part></link><space/>(2003)<space/><italics>Probability Theory: The Logic of Science</italics>, CUP. ISBN 978-0-521-59271-0 (<link type='external' href='http://www-biba.inrialpes.fr/Jaynes/prob.html'>Link to Fragmentary Edition of March 1996</link>).</listitem><listitem>McGrayne, SB. (2011).<space/><italics>The Theory That Would Not Die: How Bayes' Rule Cracked The Enigma Code, Hunted Down Russian Submarines, &amp; Emerged Triumphant from Two Centuries of Controversy.</italics><space/>New Haven: Yale University Press. ISBN 9780300169690;<space/><link type='external' href='http://www.worldcat.org/title/theory-that-would-not-die-how-bayes-rule-cracked-the-enigma-code-hunted-down-russian-submarines-emerged-triumphant-from-two-centuries-of-controversy/oclc/670481486'>OCLC 670481486</link></listitem><listitem><template><target>Cite book</target><arg name="author">[[Oskar Morgenstern|Morgenstern, Oskar]]</arg><arg name="year">1978</arg><arg name="publisher">New York University Press</arg><arg name="chapter">Some Reflections on [[Expected utility|Utility]]</arg><arg name="pages">65–70</arg><arg name="title">Selected Economic Writings of Oskar Morgenstern</arg><arg name="editor">Andrew Schotter</arg><arg name="isbn">978-0-8147-7771-8</arg></template></listitem><listitem><template><target>cite journal</target><arg name="author">[[Charles Sanders Peirce|Peirce, C.S.]] and [[Joseph Jastrow|Jastrow J.]]</arg><arg name="year">1885</arg><arg name="title">On Small Differences in Sensation</arg><arg name="journal">Memoirs of the National Academy of Sciences</arg><arg name="volume">3</arg><arg name="pages">73–83</arg><arg name="url">http://psychclassics.yorku.ca/Peirce/small-diffs.htm</arg></template></listitem><listitem><template><target>Cite book</target><arg name="author">Pfanzagl, J</arg><arg name="year">1967</arg><arg name="publisher">Princeton University Press</arg><arg name="chapter">Subjective Probability Derived from the Morgenstern-von Neumann Utility Theory</arg><arg name="pages">237–251</arg><arg name="title">Essays in Mathematical Economics In Honor of Oskar Morgenstern</arg><arg name="editor">[[Martin Shubik]]<space/></arg></template></listitem><listitem><template><target>Cite book</target><arg name="author">Pfanzagl, J. in cooperation with V.&nbsp;Baumann and H.&nbsp;Huber<space/></arg><arg name="year">1968<space/></arg><arg name="publisher">Wiley</arg><arg name="chapter">Events, Utility and Subjective Probability</arg><arg name="pages">195–220</arg><arg name="title">Theory of Measurement</arg></template></listitem><listitem><link><target>Frank P. Ramsey</target><part>Ramsey, Frank Plumpton</part></link><space/>(1931) &quot;Truth and Probability&quot; (<link type='external' href='http://cepa.newschool.edu/het//texts/ramsey/ramsess.pdf'>PDF</link>), Chapter VII in<space/><italics>The Foundations of Mathematics and other Logical Essays</italics>, Reprinted 2001, Routledge. ISBN 0-415-22546-9,</listitem><listitem><template><target>Cite book</target><arg name="author"><space/>Stigler, SM.
<space/></arg><arg name="authorlink"><space/>Stephen Stigler
<space/></arg><arg name="year"><space/>1990
<space/></arg><arg name="title"><space/>The History of Statistics: The Measurement of Uncertainty before 1900
<space/></arg><arg name="publisher"><space/>Belknap Press/Harvard University Press
<space/></arg><arg name="isbn"><space/>0-674-40341-X
</arg></template></listitem><listitem>Stigler, SM. (1999)<space/><italics>Statistics on the Table: The History of Statistical Concepts and Methods</italics>. Harvard University Press. ISBN 0-674-83601-4</listitem><listitem>Stone, JV (2013). Download chapter 1 of book<space/><link type='external' href='http://jim-stone.staff.shef.ac.uk/BookBayes2012/BayesRuleBookMain.html'>&quot;Bayes Rule: A Tutorial Introduction to Bayesian Analysis&quot;</link>, Sebtel Press, England.</listitem><listitem><template><target>cite book</target><arg name="author">Winkler, RL<space/></arg><arg name="title">Introduction to Bayesian Inference and Decision<space/></arg><arg name="publisher">Probabilistic<space/></arg><arg name="year">2003<space/></arg><arg name="isbn">0-9647938-4-9<space/></arg><arg name="edition">2nd<space/></arg></template><space/>Updated classic textbook. Bayesian theory clearly presented.</listitem></list><paragraph><template><target>DEFAULTSORT:Bayesian Probability</target></template><link><target>Category:Bayesian statistics</target><part>Probability</part></link><link><target>Category:Justification</target></link><link><target>Category:Probability interpretations</target></link><link><target>Category:Philosophy of mathematics</target></link><link><target>Category:Philosophy of science</target></link></paragraph></article>