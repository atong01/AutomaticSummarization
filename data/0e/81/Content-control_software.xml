<article title='Content-control_software'><paragraph><link><target>Image:Screenshot-whitehouse com.png</target><part>thumb</part><part>right</part><part>300px</part><part></part><part><link><target>DansGuardian</target></link><space/>blocking<space/><link><target>whitehouse.com</target></link>.</part></link></paragraph><paragraph><bold>Content-control software</bold><space/>is<space/><link><target>software</target></link><space/>designed to restrict or control the content a reader is authorised to access, especially when utilised to restrict material delivered over the<space/><link><target>Internet</target></link><space/>via the<space/><link><target>World Wide Web</target><part>Web</part></link>,<space/><link><target>e-mail</target></link>, or other means. Content-control software determines what content will be available or perhaps more often what content will be blocked.</paragraph><paragraph>Such restrictions can be applied at various levels: a government can attempt to apply them nationwide (see<space/><link><target>Internet censorship</target></link>), or they can, for example, be applied by an<space/><link><target>ISP</target></link><space/>to its clients, by an employer to its personnel, by a school to its students, by a library to its visitors, by a parent to a child's computer, or by an<space/><link><target>self-censorship</target><part>individual user to his or her own computer</part></link>.</paragraph><paragraph>The motive is often to prevent access to content which the computer's owner(s) or other authorities may consider objectionable. When imposed without the consent of the user, content control can be characterised as a form of internet censorship. Some content-control software includes time control functions that empowers parents to set the amount of time that child may spend accessing the Internet or playing games or other computer activities.</paragraph><paragraph>In some countries, such software is ubiquitous.<space/><link><target>Censorship in Cuba#Internet</target><part>In Cuba</part></link>, if a computer user at a government controlled Internet cafe types certain words, the word processor or browser is automatically closed, and a &quot;state security&quot; warning is given.<extension extension_name='ref' name="cubaonline"><template><target>cite web</target><arg name="url">http://www.rsf.org/IMG/pdf/rapport_gb_md_1.pdf</arg><arg name="title">Going online in Cuba: Internet under surveillance</arg><arg name="publisher">Reporters Without Borders</arg><arg name="year">2006</arg></template></extension></paragraph><heading level='2'>Terminology</heading><paragraph>The term<space/><italics>content control</italics><space/>is used on occasion by<space/><link><target>CNN</target></link>,<extension extension_name='ref'><template><target>cite news</target><arg name="url">http://edition.cnn.com/2005/WORLD/asiapcf/04/27/eyeonchina.internet/<space/></arg><arg name="title"><space/>Young, angry ... and wired - May 3, 2005<space/></arg><arg name="publisher">Edition.cnn.com<space/></arg><arg name="date">3 May 2005</arg><arg name="accessdate">25 October 2009</arg></template></extension><space/><italics><link><target>Playboy</target></link></italics><space/>magazine<extension extension_name='ref'><template><target>cite news</target><arg name="url">http://www.multichannel.com/policy/playboy-preaches-control/12883<space/></arg><arg name="title">Playboy Preaches Control<space/></arg><arg name="first">R. Thomas<space/></arg><arg name="last">Umstead<space/></arg><arg name="newspaper">Multichannel News<space/></arg><arg name="date">20 May 2006<space/></arg><arg name="accessdate">25 June 2013</arg></template></extension><space/>the<space/><italics><link><target>San Francisco Chronicle</target></link></italics><extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.sfgate.com/cgi-bin/article.cgi?file</arg><arg name="title">http://web.archive.org/web/20030708220938/http://www.sfgate.com/cgi-bin/article.cgi?file</arg><arg name="deadurl">yes<space/></arg><arg name="archiveurl">https://web.archive.org/20030708220938/http://www.sfgate.com:80/cgi-bin/article.cgi?file</arg><arg name="archivedate">8 July 2003<space/></arg></template></extension><space/>and the<space/><italics><link><target>New York Times</target></link></italics>;<extension extension_name='ref'><template><target>cite news</target><arg name="last">Bickerton<space/></arg><arg name="first">Derek<space/></arg><arg name="url">http://query.nytimes.com/gst/fullpage.html?res</arg><arg name="title">Digital Dreams - The<space/></arg><arg name="publisher">New York Times<space/></arg><arg name="date">30 November 1997<space/></arg><arg name="accessdate">25 October 2009</arg></template></extension><space/>however, several other terms, including<space/><italics>content filtering software</italics>,<space/><italics>secure web gateways</italics>,<space/><italics>censorware</italics>,<space/><italics>content security and control</italics>,<space/><italics>web filtering software</italics>,<space/><italics>content-censoring software</italics>, and<space/><italics>content-blocking software</italics>, are often used.<space/><italics>Nannyware</italics><space/>has also been used in both product marketing and by the media. Industry research company<space/><link><target>Gartner</target></link><space/>uses<space/><italics>secure web gateway</italics><space/>(SWG) to describe the market segment.<extension extension_name='ref' name="Gartner"><template><target>cite web</target><arg name="url">http://www.gartner.com/it-glossary/secure-web-gateway/</arg><arg name="title">IT Glossary: Secure Web Gateway</arg><arg name="publisher">[[Gartner]]</arg><arg name="accessdate">27 March 2012</arg></template></extension></paragraph><paragraph>Companies that make products that selectively block Web sites do not refer to these products as censorware, and prefer terms such as &quot;Internet filter&quot; or &quot;URL Filter&quot;; in the specialized case of software specifically designed to allow parents to monitor and restrict the access of their children, &quot;parental control software&quot; is also used. Some products log all sites that a user accesses and rates them based on content type for reporting to an &quot;accountability partner&quot; of the person's choosing, and the term<space/><link><target>accountability software</target></link><space/>is used. Internet filters, parental control software, and/or accountability software may also be combined into one product.</paragraph><paragraph>Those critical of such software, however, use the term &quot;censorware&quot; freely: consider the Censorware Project, for example.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://censorware.net/<space/></arg><arg name="title">Censorware Project<space/></arg><arg name="publisher">censorware.net<space/></arg><arg name="deadurl">yes<space/></arg><arg name="archiveurl">https://web.archive.org/20150620042654/http://www.censorware.net/<space/></arg><arg name="archivedate">20 June 2015<space/></arg></template></extension><space/>The use of the term<space/><italics>censorware</italics><space/>in editorials criticizing makers of such software is widespread and covers many different varieties and applications:<space/><link><target>Xeni Jardin</target></link><space/>used the term in a 9 March 2006 editorial in the New York Times when discussing the use of American-made filtering software to suppress content in China; in the same month a high school student used the term to discuss the deployment of such software in his school district.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://159.54.226.83/apps/pbcs.dll/article?AID</arg><arg name="title">http://159.54.226.83/apps/pbcs.dll/article?AID</arg><arg name="deadurl">yes<space/></arg><arg name="archiveurl">https://web.archive.org/20071019020114/http://159.54.226.83:80/apps/pbcs.dll/article?AID</arg><arg name="archivedate">19 October 2007<space/></arg></template></extension><extension extension_name='ref'><template><target>cite web</target><arg name="url">http://sethf.com/anticensorware/hearing_dc.php<space/></arg><arg name="title">DMCA 1201 Exemption Transcript, April 11 - Censorware<space/></arg><arg name="publisher">Sethf.com<space/></arg><arg name="date">11 April 2003<space/></arg><arg name="accessdate">25 October 2009</arg></template></extension></paragraph><paragraph>In general, outside of editorial pages as described above, traditional newspapers do not use the term censorware in their reporting, preferring instead to use less overtly controversial terms such as<space/><italics>content filter</italics>,<space/><italics>content control</italics>, or<space/><italics>web filtering</italics>; the New York Times and the<space/><italics><link><target>Wall Street Journal</target></link></italics><space/>both appear to follow this practice. On the other hand, Web-based newspapers such as<space/><link><target>CNET</target></link><space/>use the term in both editorial and journalistic contexts, for example &quot;Windows Live to Get Censorware.&quot;<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.techbeta.org/news/windows-live-to-get-censorware/<space/></arg><arg name="title">Windows Live to get censorware - ZDNet.co.uk<space/></arg><arg name="publisher">News.zdnet.co.uk<space/></arg><arg name="date">14 March 2006<space/></arg><arg name="accessdate">25 October 2009</arg></template></extension></paragraph><heading level='2'>Types of filtering</heading><paragraph>Filters can be implemented in many different ways: by software on a personal computer, via network infrastructure such as<space/><link><target>proxy server</target><trail>s</trail></link>,<space/><link><target>Domain Name System</target><part>DNS</part></link><space/>servers, or<space/><link><target>Firewall (computing)</target><part>firewall</part><trail>s</trail></link><space/>that provide Internet access.</paragraph><list type='def'><listitem><defkey>Browser based filters</defkey></listitem></list><list type='ident'><listitem><extension extension_name='ref'><template><target>cite web</target><arg name="url">https://addons.mozilla.org/en-US/firefox/search/?q</arg><arg name="title">Search Results for "content filtering"<space/></arg><arg name="work">Firefox Add-Ons<space/></arg><arg name="publisher">Mozilla<space/></arg><arg name="accessdate">25 June 2013</arg></template></extension><space/>Browser based content filtering solution is the most lightweight solution to do the content filtering, and is implemented via a third party<space/><link><target>browser extension</target></link>.</listitem></list><list type='def'><listitem><defkey>E-mail filters</defkey></listitem></list><list type='ident'><listitem>E-mail filters act on information contained in the mail body, in the mail headers such as sender and subject, and e-mail attachments to classify, accept, or reject messages.<space/><link><target>Bayesian spam filtering</target><part>Bayesian filters</part></link>, a type of statistical filter, are commonly used. Both client and server based filters are available.</listitem></list><list type='def'><listitem><defkey>Client-side filters</defkey></listitem></list><list type='ident'><listitem><extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.nap.edu/netsafekids/pro_fm_filter.html<space/></arg><arg name="title">Client-side filters<space/></arg><arg name="work">NetSafekids<space/></arg><arg name="publisher">National Academy of Sciences<space/></arg><arg name="year">2003<space/></arg><arg name="accessdate">24 June 2013</arg></template></extension><space/>This type of filter is installed as software on each computer where filtering is required.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://windows.microsoft.com/en-us/windows-vista/Protecting-your-kids-with-Family-Safety</arg><arg name="title">Protecting Your Kids with Family Safety</arg><arg name="date"></arg><arg name="accessdate">10 July 2012</arg><arg name="publisher">[[Microsoft]]</arg></template></extension><space/>This filter can typically be managed, disabled or uninstalled by anyone who has administrator-level privileges on the system.</listitem></list><list type='def'><listitem><defkey>Content-limited (or filtered) ISPs</defkey></listitem></list><list type='ident'><listitem>Content-limited (or filtered) ISPs are Internet service providers that offer access to only a set portion of Internet content on an opt-in or a mandatory basis. Anyone who subscribes to this type of service is subject to restrictions. The type of filters can be used to implement government,<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://pam2011.gatech.edu/papers/pam2011--Xu.pdf</arg><arg name="format">pdf</arg><arg name="title">Internet Censorship in China: Where Does the Filtering Occur?</arg><arg name="first">Xueyang</arg><arg name="last">Xu</arg><arg name="first2">Z. Morley</arg><arg name="last2">Mao</arg><arg name="first3">J. Alex</arg><arg name="last3">Halderman</arg><arg name="publisher">[[University of Michigan]]</arg><arg name="date">5 Jan 2011</arg></template></extension><space/>regulatory<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.telegraph.co.uk/technology/broadband/9242729/The-Pirate-Bay-cut-off-from-millions-of-Virgin-Media-customers.html<space/></arg><arg name="title">The Pirate Bay cut off from millions of Virgin Media customers<space/></arg><arg name="author"><space/>Christopher Williams<space/></arg><arg name="date">3 May 2012<space/></arg><arg name="accessdate">8 May 2012<space/></arg><arg name="work">The Telegraph</arg></template></extension><space/>or parental control over subscribers.</listitem></list><list type='def'><listitem><defkey>Network-based filtering</defkey></listitem></list><list type='ident'><listitem>This type of filter is implemented at the<space/><link><target>transport layer</target></link><space/>as a<space/><link><target>transparent proxy</target></link>, or at the<space/><link><target>application layer</target></link><space/>as a<space/><link><target>proxy server</target><part>web proxy</part></link>.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.websense.com/content/support/library/web/v75/wcg_deploy/WCG_Deploy.1.3.aspx</arg><arg name="title">Explicit and Transparent Proxy Deployments</arg><arg name="publisher">Websense</arg><arg name="accessdate">30 March 2012</arg><arg name="year">2010</arg></template></extension><space/>Filtering software may include<space/><link><target>data loss prevention software</target><part>data loss prevention</part></link><space/>functionality to filter outbound as well as inbound information. All users are subject to the access policy defined by the institution. The filtering can be customized, so a school district's high school library can have a different filtering profile than the district's junior high school library.</listitem></list><list type='def'><listitem><defkey>Search-engine filters</defkey></listitem></list><list type='ident'><listitem>Many search engines, such as Google and Alta Vista offer users the option of turning on a safety filter. When this safety filter is activated, it filters out the inappropriate links from all of the search results. If users know the actual URL of a website that features explicit or adult content, they have the ability to access that content without using a search engine. Engines like Lycos, Yahoo, and Bing offer child-oriented versions of their engines that permit only children friendly websites.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.nap.edu/netsafekids/pro_fm_filter.html<space/></arg><arg name="title">Filtering<space/></arg><arg name="work">NetSafekids<space/></arg><arg name="publisher">National Academy of Sciences<space/></arg><arg name="year">2003<space/></arg><arg name="accessdate">22 November 2010</arg></template></extension></listitem></list><heading level='2'>Reasons for filtering</heading><paragraph><template><target>main</target><arg>Internet censorship</arg></template><link><target>Internet service provider</target><trail>s</trail></link><space/>(ISPs) that block material containing<space/><link><target>pornography</target></link>, or controversial religious, political, or news-related content en route are often utilised by parents who do not permit their children to access content not conforming to<space/><link><target>indoctrination</target><part>their personal beliefs</part></link>. Content filtering software can, however, also be used to block<space/><link><target>malware</target></link><space/>and other content that is or contains hostile, intrusive, or annoying material including<space/><link><target>adware</target></link>,<space/><link><target>Spam (electronic)</target><part>spam</part></link>,<space/><link><target>computer virus</target><trail>es</trail></link>,<space/><link><target>computer worm</target><part>worms</part></link>,<space/><link><target>Trojan horse (computing)</target><part>trojan horses</part></link>, and<space/><link><target>spyware</target></link>.</paragraph><paragraph>Most content control software is marketed to organizations or parents. It is, however, also marketed on occasion to facilitate self-censorship, for example by people struggling with addictions to<space/><link><target>internet pornography</target><part>online pornography</part></link>, gambling, chat rooms, etc. Self-censorship software may also be utilised by some in order to avoid viewing content they consider immoral, inappropriate, or simply distracting. A number of<space/><link><target>accountability software</target></link><space/>products are marketed as<space/><italics>self-censorship</italics><space/>or<space/><italics>accountability software</italics>. These are often promoted by religious media and at<space/><link><target>place of worship</target><part>religious gatherings</part></link>.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.urbanministry.org/wiki/accountability-software<space/></arg><arg name="title">Accountability Software: Accountability and Monitoring Software Reviews<space/></arg><arg name="work">TechMission, Safe Families<space/></arg><arg name="publisher">UrbanMinistry.org<space/></arg><arg name="date"><space/></arg><arg name="accessdate">25 October 2009</arg></template></extension></paragraph><paragraph><template><target>citation needed span</target><arg name="text">Opinions as to when this software is moral (and sometimes legal) to use vary widely with individual people being strongly in favor of ''and'' against the same software used in different scenarios.</arg><arg name="date">September 2013</arg></template></paragraph><heading level='2'>Criticism</heading><heading level='3'>Filtering errors</heading><heading level='4'>Overblocking</heading><paragraph>Utilising a filter that is overly zealous at filtering content, or mislabels content not intended to be censored can result in over blocking, or over-censoring. Over blocking can filter out material that should be acceptable under the filtering policy in effect, for example health related information may unintentionally be filtered along with porn-related material because of the<space/><link><target>Scunthorpe problem</target></link>. Filter administrators may prefer to err on the side of caution by accepting over blocking to prevent any risk of access to sites that they determine to be undesirable. Content-control software was mentioned as blocking access to Beaver College before its name change to<space/><link><target>Arcadia University</target></link>.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://slashdot.org/article.pl?sid</arg><arg name="title">Web Censors Prompt College To Consider Name Change<space/></arg><arg name="publisher">Slashdot<space/></arg><arg name="date">2 March 2000<space/></arg><arg name="accessdate">22 November 2010</arg></template></extension><space/>Another example was the filtering of<space/><link><target>Horniman Museum</target></link>.<extension extension_name='ref'><template><target>cite news</target><arg name="url">http://www.theregister.co.uk/2004/10/08/horniman_museum_filtered/<space/></arg><arg name="title">Porn filters have a field day on Horniman Museum<space/></arg><arg name="author">Lester Haines<space/></arg><arg name="date">8 October 2004<space/></arg><arg name="newspaper">The Register</arg></template></extension><space/>As well, over-blocking may encourage users to bypass the filter entirely.</paragraph><heading level='4'>Underblocking</heading><paragraph>Whenever new information is uploaded to the Internet, filters can under block, or under-censor, content if the parties responsible for maintaining the filters do not update them quickly and accurately, and a blacklisting rather than a whitelisting filtering policy is in place.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.stat.berkeley.edu/~stark/Preprints/filter07.pdf<space/></arg><arg name="title">The Effectiveness of Internet Content Filters<space/></arg><arg name="first">Philip B.<space/></arg><arg name="last">Stark<space/></arg><arg name="publisher">[[University of California, Berkeley]]<space/></arg><arg name="date">10 November 2007<space/></arg><arg name="accessdate">22 November 2010<space/></arg></template></extension></paragraph><heading level='3'>Morality and opinion</heading><paragraph>Many<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.arnnet.com.au/article/340550/microsoft_google_yahoo_speak_isp_filter_consultation/?fp</arg><arg name="title">Microsoft, Google and Yahoo! speak out in ISP filter consultation
<space/></arg><arg name="first">Spandas<space/></arg><arg name="last">Lui<space/></arg><arg name="date">23 March 2010<space/></arg><arg name="publisher">arnnet.com<space/></arg><arg name="accessdate">22 November 2010</arg></template></extension><space/>would disapprove of government filtering viewpoints on moral or political issues, agreeing that this could become support for<space/><link><target>propaganda</target></link>. Many<extension extension_name='ref'><template><target>cite news</target><arg name="url">http://news.bbc.co.uk/2/hi/technology/8517829.stm<space/></arg><arg name="work">BBC News<space/></arg><arg name="title">Google and Yahoo raise doubts over planned net filters<space/></arg><arg name="date">16 February 2010<space/></arg><arg name="accessdate">30 April 2010</arg></template></extension><space/>would also find it unacceptable that an ISP, whether by law or by the ISP's own choice, should deploy such software without allowing the users to disable the filtering for their own connections. In the United States, the<space/><link><target>First Amendment to the United States Constitution</target><part>First Amendment</part></link><space/>has been cited in calls to criminalise forced internet censorship. (See<space/><link><target>Content-control software#Legal actions</target><part>section below</part></link>)</paragraph><paragraph>Without adequate governmental supervision, content-filtering software could enable private companies to censor as they please. (See<space/><link><target>#Religious or political censorship</target><part>Religious or political censorship</part></link>, below). Government utilisation or encouragement of content-control software is a component of<space/><link><target>Internet Censorship</target></link><space/>(not to be confused with<space/><link><target>PRISM</target><part>Internet Surveillance</part></link>, in which content is monitored and not necessarily restricted). The governments of countries such as<space/><link><target>Internet Censorship in China</target><part>the People's Republic of China</part></link>, and<space/><link><target>Cuba</target></link><space/>are current examples of countries in which this ethically controversial activity is alleged to have taken place.</paragraph><heading level='3'>Legal actions</heading><paragraph>In 1998, a United States federal district court in Virginia ruled that the imposition of mandatory filtering in a public library violates the First Amendment of the U.S. Bill of Rights.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.tomwbell.com/NetLaw/Ch04/Loudoun.html<space/></arg><arg name="title">Mainstream Loudon v. Board of Trustees of the Loudon County Library, 24 F. Supp. 2d 552 (E.D. Va. 1998)<space/></arg><arg name="publisher">Tomwbell.com<space/></arg><arg name="date"><space/></arg><arg name="accessdate">25 October 2009</arg></template></extension></paragraph><paragraph>In 1996 the US Congress passed the<space/><link><target>Communications Decency Act</target></link>, banning indecency on the Internet. Civil liberties groups challenged the law under the<space/><link><target>First Amendment to the United States Constitution</target><part>First Amendment</part></link><space/>and in 1997 the<space/><link><target>Supreme Court of the United States</target><part>Supreme Court</part></link><space/>ruled in their favor.<extension extension_name='ref'><template><target>cite news</target><arg name="url">https://supreme.justia.com/cases/federal/us/521/844/case.html<space/></arg><arg name="title">Reno v. American Civil Liberties Union - 521 U.S. 844 (1997)<space/></arg><arg name="work">U.S. Reports<space/></arg><arg name="date">26 June 1997<space/></arg><arg name="publisher">Justia.com</arg></template></extension><space/>Part of the civil liberties argument, especially from groups like the<space/><link><target>Electronic Frontier Foundation</target></link>, was that parents who wanted to block sites could use their own content-filtering software, making government involvement unnecessary.<template><target>Citation needed</target><arg name="date">February 2007</arg></template></paragraph><paragraph>In the late 1990s, groups such as the Censorware Project began reverse-engineering the content-control software and decrypting the blacklists to determine what kind of sites the software blocked. This led to legal action alleging violation of the &quot;Cyber Patrol&quot;<space/><link><target>EULA</target><part>license agreement</part></link>.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://w2.eff.org/legal/cases/Microsystems_v_Scandinavia_Online/?f</arg><arg name="title">Microsystems v Scandinavia Online, Verified Complaint<space/></arg><arg name="work">Civil No. 00CV10488, United States District Court, District of Massachusetts<space/></arg><arg name="author">Attorneys for Microsystems Software, Inc. and Mattel, Inc.<space/></arg><arg name="publisher">Electronic Frontier Foundation<space/></arg><arg name="date">15 March 2000<space/></arg><arg name="accessdate">25 October 2009</arg></template></extension><space/>They discovered that such tools routinely blocked unobjectionable sites while also failing to block intended targets. (See<space/><link><target>#Over-zealous filtering</target><part>Over-zealous filtering</part></link>, below).</paragraph><paragraph>Some content-control software companies responded by claiming that their filtering criteria were backed by intensive manual checking. The companies' opponents argued, on the other hand, that performing the necessary checking would require resources greater than the companies possessed and that therefore their claims were not valid.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www7.nationalacademies.org/itas/whitepaper_1.html<space/></arg><arg name="title">Electronic Frontier Foundation White Paper 1 for NRC project on Tools and Strategies for Protecting Kids from Pornography and Their Applicability to Other Inappropriate Internet Content<space/></arg><arg name="author">Seth Finkelstein, Consulting Programmer; Lee Tien, Senior Staff Attorney, EFF<space/></arg><arg name="publisher">National Academy of Sciences<space/></arg><arg name="archiveurl"><space/>http://web.archive.org/web/20060419190143/http://www7.nationalacademies.org/itas/whitepaper_1.html<space/></arg><arg name="archivedate">19 April 2006</arg></template></extension></paragraph><paragraph>The<space/><link><target>Motion Picture Association</target></link><space/>successfully obtained a UK ruling enforcing ISPs to use content-control software to prevent<space/><link><target>copyright infringement</target></link><space/>by their subscribers.<extension extension_name='ref'><template><target>cite news</target><arg name="title">Sky, Virgin Media Asked to Block Piracy Site Newzbin2</arg><arg name="url">http://www.bbc.co.uk/news/technology-15653434<space/></arg><arg name="publisher">[[BBC News]]<space/></arg><arg name="date">9 November 2011<space/></arg><arg name="accessdate">26 March 2012<space/></arg></template></extension></paragraph><heading level='3'>Religious, anti-religious, and political censorship</heading><paragraph>Many types of content-control software have been shown to block sites based on the religious and political leanings of the company owners. Examples include blocking several religious sites<extension extension_name='ref'><template><target>cite web</target><arg name="author">Kelly Wilson<space/></arg><arg name="url">http://hometown.aol.com/Mjolnir13/test.htm<space/></arg><arg name="title">Hometown Has Been Shutdown - People Connection Blog: AIM Community Network<space/></arg><arg name="publisher">Hometown.aol.com<space/></arg><arg name="date">2008-11-06<space/></arg><arg name="accessdate">2009-10-25</arg></template></extension><extension extension_name='ref'><template><target>cite web</target><arg name="url">http://members.tripod.com/~Trifold/NOTICE.html<space/></arg><arg name="title">Notice!!<space/></arg><arg name="publisher">Members.tripod.com<space/></arg><arg name="date"><space/></arg><arg name="accessdate">2009-10-25</arg></template></extension><space/>(including the Web site of the Vatican), many political sites, and sites about gay/lesbians.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.glaad.org/media/archive_detail.php?id</arg><arg name="title">http://www.glaad.org/media/archive_detail.php?id</arg><arg name="deadurl">yes<space/></arg><arg name="archiveurl">https://web.archive.org/20140502015519/http://www.glaad.org/media/archive_detail.php?id</arg><arg name="archivedate">2 May 2014<space/></arg></template></extension><space/><italics>X-Stop</italics><space/>was shown to block sites such as the<space/><link><target>Quaker Oats Company</target><part>Quaker</part></link><space/>web site, the<space/><link><target>National Journal of Sexual Orientation Law</target></link>, the<space/><link><target>Heritage Foundation</target></link>, and parts of<space/><link><target>The Ethical Spectacle</target></link>.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.spectacle.org/cs/burt.html<space/></arg><arg name="title">The Mind of a Censor<space/></arg><arg name="publisher">Spectacle.org<space/></arg><arg name="date"><space/></arg><arg name="accessdate">2009-10-25</arg></template></extension><space/>CYBERsitter blocks out sites like<space/><link><target>National Organization for Women</target></link>.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.spectacle.org/alert/peace.html<space/></arg><arg name="title">CYBERsitter: Where do we not want you to go today?<space/></arg><arg name="publisher">Spectacle.org<space/></arg><arg name="date"><space/></arg><arg name="accessdate">2009-10-25</arg></template></extension><space/>Nancy Willard, an academic researcher and attorney, pointed out that many U.S. public schools and libraries use the same filtering software that many Christian organizations use.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.csriu.org/onlinedocs/documents/religious2.html<space/></arg><arg name="title">See: Filtering Software: The Religious Connection<space/></arg><arg name="publisher">Csriu.org<space/></arg><arg name="date"><space/></arg><arg name="accessdate">2009-10-25</arg></template></extension><space/>Cyber Patrol, a product developed by The Anti-Defamation League and Mattel's The Learning Company,<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.adl.org/presrele/mise_00/3081-00.asp<space/></arg><arg name="title">See: ADL and The Learning Company Develop Educational Software<space/></arg><arg name="publisher">adl.org<space/></arg><arg name="date"><space/></arg><arg name="accessdate">2011-08-26</arg></template></extension><space/>has been found to block not only political sites it deems to be engaging in 'hate speech' but also human rights web sites, such as Amnesty International's web page about Israel and gay-rights web sites, such as glaad.org.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.peacefire.org/censorware/Cyber_Patrol/<space/></arg><arg name="title">See: Cyber Patrol Examined<space/></arg><arg name="publisher">peacefire.org<space/></arg><arg name="date"><space/></arg><arg name="accessdate">2011-08-26</arg></template></extension></paragraph><heading level='2'>Content labeling</heading><paragraph>Content labeling may be considered another form of content-control software. In 1994, the<space/><link><target>Internet Content Rating Association</target></link><space/>(ICRA) &amp;mdash; now part of the<space/><link><target>Family Online Safety Institute</target></link><space/>&amp;mdash; developed a content rating system for online content providers. Using an online questionnaire a webmaster describes the nature of his web content. A small file is generated that contains a condensed, computer readable digest of this description that can then be used by content filtering software to block or allow that site.</paragraph><paragraph>ICRA labels come in a variety of formats.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.fosi.org/icra/#tech<space/></arg><arg name="title">ICRA: Technical standards used<space/></arg><arg name="accessdate">2008-07-04<space/></arg><arg name="work"><space/></arg><arg name="publisher">FOSI<space/></arg><arg name="date"><space/></arg></template></extension><space/>These include the World Wide Web Consortium's<space/><link><target>Resource Description Framework</target></link><space/>(RDF) as well as<space/><link><target>Platform for Internet Content Selection</target></link><space/>(PICS) labels used by<space/><link><target>Microsoft</target></link>'s<space/><link><target>Internet Explorer</target></link><space/>Content Advisor.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.microsoft.com/windows/ie/ie6/using/howto/security/contentadv/config.mspx<space/></arg><arg name="title">Browse the Web with Internet Explorer 6 and Content Advisor<space/></arg><arg name="accessdate"><space/></arg><arg name="work"><space/></arg><arg name="publisher">Microsoft<space/></arg><arg name="date">March 26, 2003<space/></arg></template></extension></paragraph><paragraph>ICRA labels are an example of self-labeling. Similarly, in 2006 the<space/><link><target>Association of Sites Advocating Child Protection (ASACP)</target></link><space/>initiated the<space/><link type='external' href='http://rtalabel.org'>Restricted to Adults</link><space/>self-labeling initiative. ASACP members were concerned that various forms of legislation being proposed in the<space/><link><target>United States</target></link><space/>were going to have the effect of forcing adult companies to label their content.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.asacp.org/page.php?content</arg><arg name="title">ASACP Participates in Financial Coalition Against Child Pornography<space/></arg><arg name="accessdate">2008-07-04<space/></arg><arg name="work"><space/></arg><arg name="publisher"><space/></arg><arg name="date">November 20, 2007<space/></arg></template></extension><space/>The RTA label, unlike ICRA labels, does not require a webmaster to fill out a questionnaire or sign up to use. Like ICRA the RTA label is free. Both labels are recognized by a<space/><link><target>List of Content Control Software</target><part>wide variety of content-control software</part></link>.</paragraph><paragraph>The<space/><link><target>Voluntary Content Rating</target></link><space/>(VCR) system was devised by<space/><link><target>Solid Oak Software</target></link><space/>for their<space/><link><target>CYBERsitter</target></link><space/>filtering software, as an alternative to the PICS system, which some critics deemed too complex. It employs<space/><link><target>HTML</target></link><space/><link><target>meta element</target><part>metadata</part></link><space/>tags embedded within web page documents to specify the type of content contained in the document. Only two levels are specified,<space/><italics>mature</italics><space/>and<space/><italics>adult</italics>, making the specification extremely simple.</paragraph><heading level='2'>Use in public libraries</heading><heading level='3'>United States</heading><paragraph>The use of Internet filters or content-control software varies widely in public libraries in the United States, since Internet use policies are established by the local library board. Many libraries adopted Internet filters after Congress conditioned the receipt of universal service discounts on the use of Internet filters through the<space/><link><target>Children's Internet Protection Act</target></link><space/>(CIPA). Other libraries do not install content control software, believing that acceptable use policies and educational efforts address the issue of children accessing<space/><link><target>age-inappropriate</target></link><space/>content while preserving adult users' right to freely access information. Some libraries use Internet filters on computers used by children only. Some libraries that employ content-control software allow the software to be deactivated on a case-by-case basis on application to a librarian; libraries that are subject to CIPA are required to have a policy that allows adults to request that the filter be disabled without having to explain the reason for their request.</paragraph><paragraph>Many legal scholars believe that a number of legal cases, in particular<space/><italics><link><target>Reno v. American Civil Liberties Union</target></link></italics>, established that the use of content-control software in libraries is a violation of the First Amendment.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.spectacle.org/cs/library.bak<space/></arg><arg name="title">Purchase of blocking software by public libraries is unconstitutional<space/></arg><arg name="accessdate"><space/></arg><arg name="last">Wallace<space/></arg><arg name="first">Jonathan D.<space/></arg><arg name="coauthors"><space/></arg><arg name="date">November 9, 1997<space/></arg><arg name="work"><space/></arg><arg name="publisher"></arg></template></extension><space/>The Children's Internet Protection Act [CIPA] and the June 2003 case<space/><italics><link><target>United States v. American Library Association</target></link></italics><space/>found CIPA constitutional as a condition placed on the receipt of federal funding, stating that First Amendment concerns were dispelled by the law's provision that allowed adult library users to have the filtering software disabled, without having to explain the reasons for their request. The plurality decision left open a future &quot;as-applied&quot; Constitutional challenge, however. In November 2006, a lawsuit was filed against the North Central Regional Library District (NCRL) in Washington State for its policy of refusing to disable restrictions upon requests of adult patrons, but CIPA was not challenged in that matter.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.aclu-wa.org/detail.cfm?id</arg><arg name="title">ACLU Suit Seeks Access to Information on Internet for Library Patrons<space/></arg><arg name="accessdate"><space/></arg><arg name="work"><space/></arg><arg name="publisher">ACLU of Washington<space/></arg><arg name="date">November 16, 2006<space/></arg></template></extension><space/>In May 2010, the Washington State Supreme Court provided an opinion after it was asked to certify a question referred by the United States District Court for the Eastern District of Washington: Whether a public library, consistent with Article I, 5 of the Washington Constitution, may filter Internet access for all patrons without disabling Web sites containing constitutionally-protected speech upon the request of an adult library patron. The Washington State Supreme Court ruled that NCRLs internet filtering policy did not violate Article I, Section 5 of the Washington State Constitution. The Court said: It appears to us that NCRLs filtering policy is reasonable and accords with its mission and these policies and is viewpoint neutral. It appears that no article I, section 5 content-based violation exists in this case. NCRLs essential mission is to promote reading and lifelong learning. As NCRL maintains, it is reasonable to impose restrictions on Internet access in order to maintain an environment that is conducive to study and contemplative thought. The case now returns to federal court.</paragraph><paragraph>In March 2007, Virginia passed a law similar to CIPA that requires public libraries receiving state funds to use content-control software. Like CIPA, the law requires libraries to disable filters for an adult library user when requested to do so by the user.<extension extension_name='ref'><template><target>cite news</target><arg name="first">Michael<space/></arg><arg name="last">Sluss<space/></arg><arg name="authorlink"><space/></arg><arg name="coauthors"><space/></arg><arg name="title">Kaine signs library bill: The legislation requires public libraries to block obscene material with Internet filters<space/></arg><arg name="url">http://www.roanoke.com/politics/wb/wb/xp-109919<space/></arg><arg name="work"><space/></arg><arg name="publisher">The Roanoke Times<space/></arg><arg name="date">March 23, 2007<space/></arg><arg name="accessdate"><space/></arg></template></extension></paragraph><heading level='3'>Australia</heading><paragraph>The Australian Internet Safety Advisory Body has information about &quot;practical advice on Internet safety, parental control and filters for the protection of children, students and families&quot; that also includes public libraries.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.pcw.vic.edu.au/Our%20School/Parents%20Guide%20to%20Internet%20Safety.pdf<space/></arg><arg name="title">NetAlert: Parents Guide to Internet Safety<space/></arg><arg name="publisher">Australian Communications and Media Authority<space/></arg><arg name="date">2 August 2007<space/></arg><arg name="accessdate">24 June 2013</arg></template></extension></paragraph><paragraph>NetAlert, the software made available free of charge by the Australian government, was allegedly cracked by a 16-year-old student, Tom Wood, less than a week after its release in August 2007. Wood supposedly bypassed the $84 million filter in about half an hour to highlight problems with the government's approach to Internet content filtering.<extension extension_name='ref'><template><target>cite news</target><arg name="url">http://www.smh.com.au/news/National/Teenager-cracks-govts-84m-porn-filter/2007/08/25/1187462562907.html<space/></arg><arg name="title">Teenager cracks govt's $84m porn filter<space/></arg><arg name="agency">Australian Associated Press (AAP)<space/></arg><arg name="work">Sydney Morning Herald<space/></arg><arg name="publisher">Fairfax Digital<space/></arg><arg name="date">25 August 2007<space/></arg><arg name="accessdate">24 June 2013</arg></template></extension></paragraph><paragraph>The Australian Government has introduced legislation that requires ISP's to &quot;restrict access to age restricted content (commercial MA15+ content and R18+ content) either hosted in Australia or provided from Australia&quot; that was due to commence from 20 January 2008, known as<space/><link><target>Cleanfeed (content blocking system)</target><part>Cleanfeed</part></link>.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.acma.gov.au/webwr/_assets/main/lib310563/ras_declaration_2007.pdf<space/></arg><arg name="title">Restricted Access Systems Declaration 2007<space/></arg><arg name="publisher">Australian Communications and Media Authority (ACMA)<space/></arg><arg name="year">2007<space/></arg><arg name="accessdate">24 June 2013</arg></template></extension></paragraph><paragraph>Cleanfeed is a proposed mandatory ISP level content filtration system. It was proposed by the<space/><link><target>Kim Beazley</target><part>Beazley</part></link><space/>led<space/><link><target>Australian Labor Party</target></link><space/>opposition in a 2006 press release, with the intention of protecting children who were vulnerable due to claimed parental computer illiteracy. It was announced on 31 December 2007 as a policy to be implemented by the<space/><link><target>Kevin Rudd</target><part>Rudd</part></link><space/>ALP government, and initial tests in<space/><link><target>Tasmania</target></link><space/>have produced a 2008 report. Cleanfeed is funded in the current budget, and is moving towards an Expression of Interest for live testing with ISPs in 2008. Public opposition and criticism have emerged, led by the<space/><link><target>Electronic Frontiers Australia</target><part>EFA</part></link><space/>and gaining irregular mainstream media attention, with a majority of Australians reportedly &quot;strongly against&quot; its implementation.<extension extension_name='ref' name="nocleanfeed.com"><template><target>cite web</target><arg name="url">http://nocleanfeed.com/learn.html<space/></arg><arg name="title">Learn - No Clean Feed - Stop Internet Censorship in Australia<space/></arg><arg name="publisher">Electronic Frontiers Australia<space/></arg><arg name="date"><space/></arg><arg name="accessdate">25 October 2009</arg></template></extension><space/>Criticisms include its expense, inaccuracy (it will be impossible to ensure only illegal sites are blocked) and the fact that it will be compulsory, which can be seen as an intrusion on free speech rights.<extension extension_name='ref' name="nocleanfeed.com"></extension><space/>Another major criticism point has been that although the filter is claimed to stop certain materials, the underground rings dealing in such materials will not be affected. The filter might also provide a false sense of security for parents, who might supervise children less while using the Internet, achieving the exact opposite effect.<template><target>or</target><arg name="date">June 2013</arg></template><space/>Cleanfeed is a responsibility of<space/><link><target>Stephen Conroy</target><part>Senator Conroy's</part></link><space/>portfolio.</paragraph><heading level='3'>Denmark</heading><paragraph>In Denmark it is stated policy that it will &quot;prevent inappropriate Internet sites from being accessed from children's libraries across Denmark.&quot;<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.prnewswire.com/cgi-bin/stories.pl?ACCT</arg><arg name="title">Danish Ministry of Culture Chooses SonicWALL CMS 2100 Content Filter to Keep Children's Libraries Free of Unacceptable Material<space/></arg><arg name="publisher">Prnewswire.com<space/></arg><arg name="date"><space/></arg><arg name="accessdate">2009-10-25</arg></template></extension><space/>&quot;'It is important that every library in the country has the opportunity to protect children against pornographic material when they are using library computers. It is a main priority for me as Culture Minister to make sure children can surf the net safely at libraries,' states Brian Mikkelsen in a press-release of the Danish Ministry of Culture.&quot;<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.saferinternet.org/ww/en/pub/insafe/news/articles/0606/dk.htm<space/></arg><arg name="title">Danish Minister of Culture offers Internet filters to libraries<space/></arg><arg name="publisher">Saferinternet.org<space/></arg><arg name="date"><space/></arg><arg name="accessdate">2009-10-25</arg></template></extension></paragraph><heading level='3'>United Kingdom</heading><paragraph>#section:Web blocking in the United Kingdom</paragraph><heading level='2'>Bypassing filters</heading><paragraph><template><target>Main</target><arg>Internet censorship circumvention</arg></template></paragraph><paragraph>Content filtering in general can &quot;be bypassed entirely by tech-savvy individuals&quot;. Blocking content on circumvention advice &quot;[will not]...guarantee that users won't eventually be able to find a way around the filter.&quot;<extension extension_name='ref' name="techsoup"><template><target>cite web</target><arg name="url">http://www.cityvision.edu/wiki/understanding-content-filtering-faq-nonprofits<space/></arg><arg name="title">Understanding Content Filtering: An FAQ for Nonprofits<space/></arg><arg name="last">Satterfield<space/></arg><arg name="first">Brian<space/></arg><arg name="date">4 June 2007<space/></arg><arg name="publisher">Techsoup.org<space/></arg><arg name="accessdate">24 June 2013</arg></template></extension></paragraph><paragraph>Some software may be bypassed successfully by using alternative protocols such as<space/><link><target>File Transfer Protocol</target><part>FTP</part></link><space/>or<space/><link><target>telnet</target></link><space/>or<space/><link><target>HTTPS</target></link>, conducting searches in a different language, using a<space/><link><target>proxy server</target></link><space/>or a circumventor such as<space/><link><target>Psiphon</target></link>. Also cached web pages returned by Google or other searches could bypass some controls as well. Web syndication services may provide alternate paths for content. Some of the more poorly designed programs can be shut down by killing their processes: for example, in<space/><link><target>Microsoft Windows</target></link><space/>through the Windows<space/><link><target>Task Manager</target></link>, or in<space/><link><target>Mac OS X</target></link><space/>using Force Quit or<space/><link><target>Activity Monitor</target></link>. Numerous workarounds and counters to workarounds from content-control software creators exist.<link><target>Google</target></link><space/>services are often blocked by filters, but these may most often be bypassed by using<space/><italics>https://</italics><space/>in place of<space/><italics>http://</italics><space/>since content filtering software is not able to interpret content under secure connections (in this case SSL).</paragraph><paragraph>Many content filters have an option which allows authorized people to bypass the content filter. This is especially useful in environments where the computer is being supervised and the content filter is aggressively blocking Web sites that need to be accessed.<template><target>Citation needed</target><arg name="date">March 2009</arg></template></paragraph><paragraph>An encrypted<space/><link><target>VPN</target></link><space/>can be used as means of bypassing content control software, especially if the content control software is installed on an Internet gateway or firewall.</paragraph><paragraph>Sometimes, an antivirus software with web protection may stop the content-control filter.<template><target>citation needed</target><arg name="date">June 2013</arg></template></paragraph><heading level='2'>Products and services</heading><paragraph><template><target>See also</target><arg>List of content-control software</arg><arg>Category:Content-control software</arg></template>Some ISPs offer<space/><link><target>parental control</target></link><space/>options. Some offer security software which includes parental controls.<space/><link><target>Mac OS X v10.4</target></link><space/>offers parental controls for several applications (<link><target>Mail (OS X)</target><part>Mail</part></link>,<space/><link><target>Macintosh Finder</target><part>Finder</part></link>,<space/><link><target>iChat</target></link>,<space/><link><target>Safari (web browser)</target><part>Safari</part></link><space/>&amp;<space/><link><target>Dictionary (software)</target><part>Dictionary</part></link>). Microsoft's<space/><link><target>Windows Vista</target></link><space/>operating system also includes content-control software.</paragraph><paragraph>Content filtering technology exists in two major forms:<space/><link><target>Application-level gateway</target><part>application gateway</part></link><space/>or<space/><link><target>Deep packet inspection</target><part>packet inspection</part></link>. For HTTP access the application gateway is called a web-proxy or just a proxy. Such web-proxies can inspect both the initial request and the returned web page using arbitrarily complex rules and will not return any part of the page to the requester until a decision is made. In addition they can make substitutions in whole or for any part of the returned result. Packet inspection filters do not initially interfere with the connection to the server but inspect the data in the connection as it goes past, at some point the filter may decide that the connection is to be filtered and it will then disconnect it by injecting a TCP-Reset or similar faked packet. The two techniques can be used together with the packet filter monitoring a link until it sees an HTTP connection starting to an IP address that has content that needs filtering. The packet filter then redirects the connection to the<space/><link><target>Proxy server#Intercepting proxy server</target><part>web-proxy</part></link><space/>which can perform detailed filtering on the website without having to pass through all unfiltered connections. This combination is<space/><link><target>Cleanfeed (content blocking system)</target><part>quite popular</part></link><space/>because it can significantly reduce the cost of the system.</paragraph><paragraph>Gateway-based content control software may be more difficult to bypass than desktop software as the user does not have physical access to the filtering device. However, many of the techniques in the<space/><link><target>Content-control software#Bypassing filters</target><part>Bypassing filters</part></link><space/>section still work.</paragraph><heading level='2'>See also</heading><list type='bullet'><listitem><link><target>Adultism</target></link></listitem><listitem><link><target>Ad filtering</target></link></listitem><listitem><link><target>David Burt (filtering advocate)</target><part>David Burt</part></link>, a former librarian and advocate for content-control software</listitem><listitem><link><target>Comparison of content-control software and providers</target></link></listitem><listitem><link><target>Computer and network surveillance</target></link></listitem><listitem><link><target>Deep content inspection</target></link></listitem><listitem><link><target>Egress filtering</target></link>, control of outbound network traffic<space/></listitem><listitem><link><target>Financial Coalition Against Child Pornography</target></link></listitem><listitem><link><target>Internet censorship</target></link><list type='bullet'><listitem><link><target>Internet censorship circumvention</target></link></listitem></list></listitem><listitem><link><target>Internet safety</target></link></listitem><listitem><link><target>List of parental control software</target></link></listitem><listitem><link><target>Opposition to pornography</target></link></listitem><listitem><link><target>Parental controls</target></link></listitem><listitem><link><target>Peacefire</target></link>, a U.S.-based website dedicated to &quot;preserving First Amendment rights for Internet users, particularly those younger than 18&quot;</listitem><listitem><link><target>Russian State Duma Bill 89417-6</target></link><space/>- a proposed bill that would mandate content control software</listitem><listitem><link><target>Wordfilter</target></link>, generic name for scripts typically used on Internet forums or chat rooms that automatically scans users' posts or comments as they are submitted and automatically changes or censors particular words or phrases</listitem></list><heading level='2'>References</heading><paragraph><template><target>Reflist</target><arg>30em</arg></template><template><target>Wiktionary</target><arg>censorware</arg></template><template><target>Censorship</target></template></paragraph><paragraph><template><target>DEFAULTSORT:Content-Control Software</target></template><link><target>Category:Content-control software</target><part></part></link><link><target>Category:Web browsers</target></link><link><target>Category:Internet censorship</target></link><link><target>Category:Digital rights management</target></link></paragraph></article>