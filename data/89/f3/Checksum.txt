{{Refimprove|date=August 2012}}
[[File:Checksum.svg|thumb|330px|right|Effect of a typical checksum function (the Unix <tt>[[cksum]]</tt> utility)]]

A '''checksum''' or '''hash sum''' is a small-size datum from a block of [[digital data]] for the purpose of [[error detection|detecting errors]] which may have been introduced during its [[telecommunication|transmission]] or [[computer storage|storage]].  It is usually applied to an installation file after it is received from the download server.  By themselves checksums are often used to verify data integrity, but should not be relied upon to also verify data [[authentication|authenticity]]. 

The actual [[algorithm|procedure]] which yields the checksum, given a data input is called a '''checksum function''' or '''[[checksum algorithm]]'''. Depending on its design goals, a good checksum algorithm will usually output a significantly different value, even for small changes made to the input. 
This is especially true of [[cryptographic hash function]]s, which may be used to detect many data corruption errors and verify overall [[data integrity]]; if the computed checksum for the current data input matches the stored value of a previously computed checksum, there is a very high probability the data has not been accidentally altered or corrupted.

Checksum functions are related to [[hash function]]s, [[fingerprint (computing)|fingerprint]]s, [[randomization function]]s, and [[cryptographic hash function]]s.  However, each of those concepts has different applications and therefore different design goals. Checksums are used as cryptographic primitives in larger authentication algorithms. For cryptographic systems with these two specific design goals, see [[HMAC]].

[[Check digit]]s and [[parity bit]]s are special cases of checksums, appropriate for small blocks of data (such as [[Social Security number]]s, [[bank account]] numbers, [[Word (data type)|computer word]]s, single [[byte]]s, etc.).  Some [[error-correcting code]]s are based on special checksums which not only detect common errors but also allow the original data to be recovered in certain cases.

==Checksum algorithms==
===Parity byte or parity word===
The simplest checksum algorithm is the so-called [[longitudinal redundancy check|longitudinal parity check]], which breaks the data into "words" with a fixed number ''n'' of bits, and then computes the [[exclusive or]] of all those words.  The result is appended to the message as an extra word.To check the integrity of a message, the receiver computes the exclusive or (XOR) of all its words, including the checksum; if the result is not a word with ''n'' zeros, the receiver knows a transmission error occurred.

With this checksum, any transmission error which flips a single bit of the message, or an odd number of bits, will be detected as an incorrect checksum.  However, an error which affects two bits will not be detected if those bits lie at the same position in two distinct words.  Also swapping of two or more words will not be detected. If the affected bits are independently chosen at random, the probability of a two-bit error being undetected is 1/''n''.

===Modular sum===

A variant of the previous algorithm is to add all the "words" as unsigned binary numbers, discarding any overflow bits, and append the [[two's complement]] of the total as the checksum.  To validate a message, the receiver adds all the words in the same manner, including the checksum; if the result is not a word full of zeros, an error must have occurred.  This variant too detects any single-bit error, but the promodular sum is used in [[J1708|SAE J1708]].<ref>{{cite web|url=http://www.kvaser.com/zh/about-can/related-protocols-and-standards/50.html |title=SAE J1708 |publisher=Kvaser.com |archiveurl=http://web.archive.org/web/20131211152639/http://www.kvaser.com/zh/about-can/related-protocols-and-standards/50.html |archivedate={{date|2013-12-11}} }}</ref>

===Position-dependent checksums===

The simple checksums described above fail to detect some common errors which affect many bits at once, such as changing the order of data words, or inserting or deleting words with all bits set to zero.  The checksum algorithms most used in practice, such as [[Fletcher's checksum]], [[Adler-32]], and [[cyclic redundancy check]]s (CRCs), address these weaknesses by considering not only the value of each word but also its position in the sequence. This feature generally increases the [[Analysis of algorithms|cost]] of computing the checksum.

===General considerations===
A single-bit transmission error then corresponds to a displacement from a valid corner (the correct message and checksum) to one of the ''m'' adjacent corners.  An error which affects ''k'' bits moves the message to a corner which is ''k'' steps removed from its correct corner.  The goal of a good checksum algorithm is to spread the valid corners as far from each other as possible, so as to increase the likelihood "typical" transmission errors will end up in an invalid corner.

==See also==

General topic
* [[Algorithm]]
* [[Data degradation|Bit rot]]
* [[Check digit]]
* [[Damm algorithm]]
* [[File verification]]
* [[Fletcher's checksum]]
* [[Frame check sequence]]
* [[cksum]]
* [[md5sum]]
* [[sha1sum]]
* [[Parchive]]
* [[Sum (Unix)|sum]]
* [[SYSV checksum]]
* [[BSD checksum]]

Error correction
* [[Hamming code]]
* [[IPv4 header checksum]]

Hash functions
* [[List of hash functions]]
* [[Luhn algorithm]]
* [[Parity bit]]
* [[Rolling checksum]]
* [[Verhoeff algorithm]]
* [[ZFS]]&nbsp;â€” a file system which performs automatic file integrity checking using checksums

==References==
{{reflist}}

==External links==
{{wikibooks
 |1= Algorithm Implementation
 |2= Checksums
}}
*[http://www.netrino.com/Embedded-Systems/How-To/Additive-Checksums Additive Checksums (C)] theory from Barr Group
*[http://hashingapp.github.io Hashing] - Standalone hashing application for Windows that let's you hash multiple files
* [http://corz.org/windows/software/checksum checksum], a fast file, folder and drive hashing application for [[Microsoft Windows|Windows]], which computes MD5, SHA-1 and BLAKE2 hashes.
* [http://compressme.net/ CHK Checksum Utility] - an advanced checksum tool
* [http://filechecksumutility.sourceforge.net/ File Checksum Utility] - Calculate MD5, SHA1, SHA256 and SHA512 Hashes
* [http://support.microsoft.com/kb/841290 MD5 and SHA-1 tool] from Microsoft.com 
* [http://www.jonelo.de/java/jacksum/index.html Jacksum], is a [[Java (software platform)|Java]]-based application that supports a large number of algorithms for computing and verifying checksums, CRCs and message digests 
* [http://rhash.anz.ru/ RHash], a [[C (programming language)|C]]-based application which supports ''recursion'' and many other unique features 
* [http://code.google.com/p/jdigest/ jdigest], a [[Java (software platform)|Java]]-based tool from Google which works [[MD5]] and [[Secure Hash Algorithm|SHA]] sums for Windows via right-clicking
* [http://www.richherrick.com/software/hash/index.html Hash Generator and Validation Tool (Hash)], a command-prompt utility which will generate/validate several types of hash values for multiple files and directory trees.

[[Category:Checksum algorithms|*]]