<article title='Rendering_%28computer_graphics%29'><paragraph><template><target>About</target><arg></arg><arg>3-dimensional rendering</arg><arg>3D rendering</arg><arg>rendering of HTML</arg><arg>web browser engine</arg></template><link><target>File:Render Types.png</target><part>thumb</part><part>A variety of rendering techniques applied to a single 3D scene</part></link><link><target>Image:Glasses 800 edit.png</target><part>thumb</part><part>An image created by using<space/><link><target>POV-Ray</target></link><space/>3.6</part></link></paragraph><preblock><preline><bold>Rendering</bold><space/>is the process of generating an image from a<space/><link><target>2D model</target><part>2D</part></link><space/>or<space/><link><target>3D model</target></link><space/>(or models in what collectively could be called a<space/><italics>scene</italics><space/>file), by means of computer programs. Also, the results of such a model can be called a rendering. A scene file contains objects in a strictly defined language or data structure; it would contain geometry, viewpoint,<space/><link><target>texture mapping</target><part>texture</part></link>,<space/><link><target>lighting</target></link>, and<space/><link><target>shading</target></link><space/>information as a description of the virtual scene. The data contained in the scene file is then passed to a rendering program to be processed and output to a<space/><link><target>digital image</target></link><space/>or<space/><link><target>raster graphics</target></link><space/>image file. The term &quot;rendering&quot; may be by analogy with an &quot;artist's rendering&quot; of a scene. Though the technical details of rendering methods vary, the general challenges to overcome in producing a 2D image from a 3D representation stored in a scene file are outlined as the<space/><link><target>graphics pipeline</target></link><space/>along a rendering device, such as a<space/><link><target>Graphics processing unit</target><part>GPU</part></link>. A GPU is a purpose-built device able to assist a<space/><link><target>Central processing unit</target><part>CPU</part></link><space/>in performing complex rendering calculations. If a scene is to look relatively realistic and predictable under virtual lighting, the rendering software should solve the<space/><link><target>rendering equation</target></link>. The rendering equation doesn't account for all lighting phenomena, but is a general lighting model for computer-generated imagery. 'Rendering' is also used to describe the process of calculating effects in a video editing program to produce final video output.</preline></preblock><paragraph>Rendering is one of the major sub-topics of<space/><link><target>3D computer graphics</target></link>, and in practice is always connected to the others. In the<space/><link><target>graphics pipeline</target></link>, it is the last major step, giving the final appearance to the models and animation. With the increasing sophistication of computer graphics since the 1970s, it has become a more distinct subject.</paragraph><paragraph>Rendering has uses in<space/><link><target>Architectural rendering</target><part>architecture</part></link>,<space/><link><target>video game</target><trail>s</trail></link>,<space/><link><target>simulation</target><part>simulators</part></link>,<space/><link><target>film</target><part>movie</part></link><space/>or TV<space/><link><target>visual effects</target></link>, and design visualization, each employing a different balance of features and techniques. As a product, a wide variety of renderers are available. Some are integrated into larger modeling and animation packages, some are stand-alone, some are free open-source projects. On the inside, a renderer is a carefully engineered program, based on a selective mixture of disciplines related to:<space/><link><target>optics</target><part>light physics</part></link>,<space/><link><target>visual system</target><part>visual perception</part></link>,<space/><link><target>mathematics</target></link><space/>and<space/><link><target>software engineering</target><part>software development</part></link>.</paragraph><paragraph>In the case of 3D graphics, rendering may be done slowly, as in<space/><link><target>pre-rendered</target><part>pre-rendering</part></link>, or in real time. Pre-rendering is a computationally intensive process that is typically used for movie creation, while<space/><link><target>Real-time computer graphics</target><part>real-time</part></link><space/>rendering is often done for 3D video games which rely on the use of graphics cards with 3D hardware accelerators.</paragraph><heading level='2'>Usage</heading><paragraph>When the pre-image (a<space/><link><target>wireframe model</target><part>wireframe</part></link><space/>sketch usually) is complete, rendering is used, which adds in<space/><link><target>bitmap textures</target></link><space/>or<space/><link><target>procedural textures</target></link>, lights,<space/><link><target>bump mapping</target></link><space/>and relative position to other objects. The result is a completed image the consumer or intended viewer sees.</paragraph><paragraph>For movie animations, several images (frames) must be rendered, and stitched together in a program capable of making an animation of this sort. Most 3D image editing programs can do this.</paragraph><heading level='2'>Features</heading><paragraph>A rendered image can be understood in terms of a number of visible features. Rendering research and development has been largely motivated by finding ways to simulate these efficiently. Some relate directly to particular algorithms and techniques, while others are produced together.</paragraph><list type='bullet'><listitem><link><target>shading</target></link><template><target>snd</target></template><space/>how the color and brightness of a surface varies with lighting</listitem><listitem><link><target>texture mapping</target><part>texture-mapping</part></link><template><target>snd</target></template><space/>a method of applying detail to surfaces</listitem><listitem><link><target>bump mapping</target><part>bump-mapping</part></link><template><target>snd</target></template><space/>a method of simulating small-scale bumpiness on surfaces</listitem><listitem><link><target>distance fog</target><part>fogging/participating medium</part></link><template><target>snd</target></template><space/>how light dims when passing through non-clear atmosphere or air</listitem><listitem><link><target>shadow</target><trail>s</trail></link><template><target>snd</target></template><space/>the effect of obstructing light</listitem><listitem><link><target>soft shadows</target></link><template><target>snd</target></template><space/>varying darkness caused by partially obscured light sources</listitem><listitem><link><target>Reflection (computer graphics)</target><part>reflection</part></link><template><target>snd</target></template><space/>mirror-like or highly glossy reflection</listitem><listitem><link><target>transparency (optics)</target></link>,<space/><link><target>transparency (graphic)</target></link><space/>or<space/><link><target>Opacity (optics)</target><part>opacity</part></link><template><target>snd</target></template><space/>sharp transmission of light through solid objects</listitem><listitem><link><target>translucency</target></link><template><target>snd</target></template><space/>highly scattered transmission of light through solid objects</listitem><listitem><link><target>refraction</target></link><template><target>snd</target></template><space/>bending of light associated with transparency</listitem><listitem><link><target>diffraction</target></link><template><target>snd</target></template><space/>bending, spreading and interference of light passing by an object or aperture that disrupts the ray</listitem><listitem><link><target>global illumination</target><part>indirect illumination</part></link><template><target>snd</target></template><space/>surfaces illuminated by light reflected off other surfaces, rather than directly from a light source (also known as global illumination)</listitem><listitem><link><target>Caustic (optics)</target><part>caustics</part></link><space/>(a form of indirect illumination)<template><target>snd</target></template><space/>reflection of light off a shiny object, or focusing of light through a transparent object, to produce bright highlights on another object</listitem><listitem><link><target>depth of field</target></link><template><target>snd</target></template><space/>objects appear blurry or out of focus when too far in front of or behind the object in focus</listitem><listitem><link><target>motion blur</target></link><template><target>snd</target></template><space/>objects appear blurry due to high-speed motion, or the motion of the camera</listitem><listitem><link><target>non-photorealistic rendering</target></link><template><target>snd</target></template><space/>rendering of scenes in an artistic style, intended to look like a painting or drawing</listitem></list><heading level='2'>Techniques</heading><paragraph>Many rendering algorithms have been researched, and software used for rendering may employ a number of different techniques to obtain a final image.</paragraph><paragraph><link><target>Vectorization (image tracing)</target><part>Tracing</part></link><space/>every<space/><link><target>photon</target><part>particle of light</part></link><space/>in a scene is nearly always completely impractical and would take a stupendous amount of time. Even tracing a portion large enough to produce an image takes an inordinate amount of time if the sampling is not intelligently restricted.</paragraph><paragraph>Therefore, a few loose families of more-efficient light transport modelling techniques have emerged:</paragraph><list type='bullet'><listitem><link><target>rasterization</target></link>, including<space/><link><target>scanline rendering</target></link>, geometrically projects objects in the scene to an image plane, without advanced optical effects;</listitem><listitem><link><target>ray casting</target></link><space/>considers the scene as observed from a specific point of view, calculating the observed image based only on geometry and very basic optical laws of reflection intensity, and perhaps using<space/><link><target>Monte Carlo method</target><part>Monte Carlo</part></link><space/>techniques to reduce artifacts;</listitem><listitem><link><target>Ray tracing (graphics)</target><part>ray tracing</part></link><space/>is similar to ray casting, but employs more advanced optical simulation, and usually uses Monte Carlo techniques to obtain more realistic results at a speed that is often orders of magnitude slower.</listitem></list><paragraph>The fourth type of light transport technique,<space/><link><target>Radiosity (computer graphics)</target><part>radiosity</part></link><space/>is not usually implemented as a rendering technique, but instead calculates the passage of light as it leaves the light source and illuminates surfaces. These surfaces are usually rendered to the display using one of the other three techniques.</paragraph><paragraph>Most advanced software combines two or more of the techniques to obtain good-enough results at reasonable cost.</paragraph><paragraph>Another distinction is between<space/><link><target>Image and object order rendering</target><part>image order</part></link><space/>algorithms, which iterate over pixels of the image plane, and<space/><link><target>Image and object order rendering</target><part>object order</part></link><space/>algorithms, which iterate over objects in the scene. Generally object order is more efficient, as there are usually fewer objects in a scene than pixels.</paragraph><heading level='3'><template><target>Anchor</target><arg>Rasterisation</arg></template>Scanline rendering and rasterisation</heading><paragraph><template><target>main</target><arg>Rasterisation</arg></template><link><target>File:Latest Rendering of the E-ELT.jpg</target><part>thumb</part><part>Rendering of the<space/><link><target>European Extremely Large Telescope</target></link>.</part></link></paragraph><paragraph>A high-level representation of an image necessarily contains elements in a different domain from pixels. These elements are referred to as primitives. In a schematic drawing, for instance, line segments and curves might be primitives. In a graphical user interface, windows and buttons might be the primitives. In rendering of 3D models, triangles and polygons in space might be primitives.</paragraph><paragraph>If a pixel-by-pixel (image order) approach to rendering is impractical or too slow for some task, then a primitive-by-primitive (object order) approach to rendering may prove useful. Here, one loops through each of the primitives, determines which pixels in the image it affects, and modifies those pixels accordingly. This is called<space/><bold>rasterization</bold>, and is the rendering method used by all current<space/><link><target>graphics card</target><trail>s</trail></link>.</paragraph><paragraph>Rasterization is frequently faster than pixel-by-pixel rendering. First, large areas of the image may be empty of primitives; rasterization will ignore these areas, but pixel-by-pixel rendering must pass through them. Second, rasterization can improve<space/><link><target>cache coherency</target></link><space/>and reduce redundant work by taking advantage of the fact that the pixels occupied by a single primitive tend to be contiguous in the image. For these reasons, rasterization is usually the approach of choice when<space/><link><target>interactivity</target><part>interactive</part></link><space/>rendering is required; however, the pixel-by-pixel approach can often produce higher-quality images and is more versatile because it does not depend on as many assumptions about the image as rasterization.</paragraph><paragraph>The older form of rasterization is characterized by rendering an entire face (primitive) as a single color. Alternatively, rasterization can be done in a more complicated manner by first rendering the vertices of a face and then rendering the pixels of that face as a blending of the vertex colors. This version of rasterization has overtaken the old method as it allows the graphics to flow without complicated textures (a rasterized image when used face by face tends to have a very block-like effect if not covered in complex textures; the faces are not smooth because there is no gradual color change from one primitive to the next). This newer method of rasterization utilizes the graphics card's more taxing shading functions and still achieves better performance because the simpler textures stored in memory use less space. Sometimes designers will use one rasterization method on some faces and the other method on others based on the angle at which that face meets other joined faces, thus increasing speed and not hurting the overall effect.</paragraph><heading level='3'>Ray casting</heading><paragraph><template><target>Main</target><arg>Ray casting</arg></template><template><target>Unreferenced section</target><arg name="date">May 2010</arg></template>In<space/><bold>ray casting</bold><space/>the geometry which has been modeled is parsed pixel by pixel, line by line, from the point of view outward, as if casting rays out from the point of view. Where an object is intersected, the color value at the point may be evaluated using several methods. In the simplest, the color value of the object at the point of intersection becomes the value of that pixel. The color may be determined from a<space/><link><target>texture mapping</target><part>texture-map</part></link>. A more sophisticated method is to modify the colour value by an illumination factor, but without calculating the relationship to a simulated light source. To reduce artifacts, a number of rays in slightly different directions may be averaged.</paragraph><paragraph>Rough simulations of optical properties may be additionally employed: a simple calculation of the ray from the object to the point of view is made. Another calculation is made of the angle of incidence of light rays from the light source(s), and from these as well as the specified intensities of the light sources, the value of the pixel is calculated. Another simulation uses illumination plotted from a radiosity algorithm, or a combination of these two.</paragraph><paragraph>Raycasting is primarily used for realtime simulations, such as those used in 3D computer games and cartoon animations, where detail is not important, or where it is more efficient to manually fake the details in order to obtain better performance in the computational stage. This is usually the case when a large number of frames need to be animated. The resulting surfaces have a characteristic 'flat' appearance when no additional tricks are used, as if objects in the scene were all painted with matte finish.</paragraph><heading level='3'>Ray tracing</heading><paragraph><link><target>Image:SpiralSphereAndJuliaDetail1.jpg</target><part>thumb</part><part>250px</part><part>''Spiral Sphere and Julia, Detail'', a computer-generated image created by visual artist Robert W. McGregor using only<space/><link><target>POV-Ray</target></link><space/>3.6 and its built-in scene description language.</part></link><template><target>Main</target><arg>Ray tracing (graphics)</arg></template><bold>Ray tracing</bold><space/>aims to simulate the natural flow of light, interpreted as particles. Often, ray tracing methods are utilized to approximate the solution to the<space/><link><target>rendering equation</target></link><space/>by applying<space/><link><target>Monte Carlo methods</target></link><space/>to it. Some of the most used methods are<space/><link><target>path tracing</target></link>,<space/><link><target>path tracing#Bidirectional path tracing</target><part>bidirectional path tracing</part></link>, or<space/><link><target>Metropolis light transport</target></link>, but also semi realistic methods are in use, like<space/><link><target>Whitted Style Ray Tracing</target></link>, or hybrids. While most implementations let light propagate on straight lines, applications exist to simulate relativistic spacetime effects.<extension extension_name='ref'><template><target>cite paper</target><arg name="id"><space/>{{citeseerx|10.1.1.56.830}}<space/></arg><arg name="title"><space/>Relativistic Ray-Tracing: Simulating the Visual Appearance of Rapidly Moving Objects<space/></arg></template></extension></paragraph><paragraph>In a final, production quality rendering of a ray traced work, multiple rays are generally shot for each pixel, and traced not just to the first object of intersection, but rather, through a number of sequential 'bounces', using the known laws of optics such as &quot;angle of incidence equals angle of reflection&quot; and more advanced laws that deal with refraction and surface roughness.</paragraph><paragraph>Once the ray either encounters a light source, or more probably once a set limiting number of bounces has been evaluated, then the surface illumination at that final point is evaluated using techniques described above, and the changes along the way through the various bounces evaluated to estimate a value observed at the point of view. This is all repeated for each sample, for each pixel.</paragraph><paragraph>In<space/><link><target>distribution ray tracing</target></link>, at each point of intersection, multiple rays may be spawned. In<space/><link><target>path tracing</target></link>, however, only a single ray or none is fired at each intersection, utilizing the statistical nature of<space/><link><target>Monte Carlo</target></link><space/>experiments.</paragraph><paragraph>As a brute-force method, ray tracing has been too slow to consider for real-time, and until recently too slow even to consider for short films of any degree of quality, although it has been used for special effects sequences, and in advertising, where a short portion of high quality (perhaps even<space/><link><target>photorealism</target><part>photorealistic</part></link>) footage is required.</paragraph><paragraph>However, efforts at optimizing to reduce the number of calculations needed in portions of a work where detail is not high or does not depend on ray tracing features have led to a realistic possibility of wider use of ray tracing. There is now some hardware accelerated ray tracing equipment, at least in prototype phase, and some game demos which show use of real-time software or hardware ray tracing.</paragraph><heading level='2'>Radiosity</heading><paragraph><template><target>Main</target><arg>Radiosity (computer graphics)</arg></template><bold>Radiosity</bold><space/>is a method which attempts to simulate the way in which directly illuminated surfaces act as indirect light sources that illuminate other surfaces. This produces more realistic shading and seems to better capture the '<link><target>Shading#Ambient lighting</target><part>ambience</part></link>' of an indoor scene. A classic example is the way that shadows 'hug' the corners of rooms.</paragraph><paragraph>The optical basis of the simulation is that some diffused light from a given point on a given surface is reflected in a large spectrum of directions and illuminates the area around it.</paragraph><paragraph>The simulation technique may vary in complexity. Many renderings have a very rough estimate of radiosity, simply illuminating an entire scene very slightly with a factor known as ambiance. However, when advanced radiosity estimation is coupled with a high quality ray tracing algorithim, images may exhibit convincing realism, particularly for indoor scenes.</paragraph><paragraph>In advanced radiosity simulation, recursive, finite-element algorithms 'bounce' light back and forth between surfaces in the model, until some recursion limit is reached. The colouring of one surface in this way influences the colouring of a neighbouring surface, and vice versa. The resulting values of illumination throughout the model (sometimes including for empty spaces) are stored and used as additional inputs when performing calculations in a ray-casting or ray-tracing model.</paragraph><paragraph>Due to the iterative/recursive nature of the technique, complex objects are particularly slow to emulate. Prior to the standardization of rapid radiosity calculation, some graphic artists used a technique referred to loosely as<space/><link><target>false radiosity</target></link><space/>by darkening areas of texture maps corresponding to corners, joints and recesses, and applying them via self-illumination or diffuse mapping for scanline rendering. Even now, advanced radiosity calculations may be reserved for calculating the ambiance of the room, from the light reflecting off walls, floor and ceiling, without examining the contribution that complex objects make to the radiosityor complex objects may be replaced in the radiosity calculation with simpler objects of similar size and texture.</paragraph><paragraph>Radiosity calculations are viewpoint independent which increases the computations involved, but makes them useful for all viewpoints. If there is little rearrangement of radiosity objects in the scene, the same radiosity data may be reused for a number of frames, making radiosity an effective way to improve on the flatness of ray casting, without seriously impacting the overall rendering time-per-frame.</paragraph><paragraph>Because of this, radiosity is a prime component of leading real-time rendering methods, and has been used from beginning-to-end to create a large number of well-known recent feature-length animated 3D-cartoon films.<template><target>Unicode</target><arg></arg></template></paragraph><heading level='2'>Sampling and filtering</heading><paragraph>One problem that any rendering system must deal with, no matter which approach it takes, is the<space/><bold>sampling problem</bold>. Essentially, the rendering process tries to depict a<space/><link><target>continuous function</target></link><space/>from image space to colors by using a finite number of pixels. As a consequence of the<space/><link><target>NyquistShannon sampling theorem</target></link><space/>(or Kotelnikov theorem), any spatial waveform that can be displayed must consist of at least two pixels, which is proportional to<space/><link><target>image resolution</target></link>. In simpler terms, this expresses the idea that an image cannot display details, peaks or troughs in color or intensity, that are smaller than one pixel.</paragraph><paragraph>If a naive rendering algorithm is used without any filtering, high frequencies in the image function will cause ugly<space/><link><target>aliasing</target></link><space/>to be present in the final image. Aliasing typically manifests itself as<space/><link><target>jaggies</target></link>, or jagged edges on objects where the pixel grid is visible. In order to remove aliasing, all rendering algorithms (if they are to produce good-looking images) must use some kind of<space/><link><target>low-pass filter</target></link><space/>on the image function to remove high frequencies, a process called<space/><link><target>Spatial anti-aliasing</target><part>antialiasing</part></link>.</paragraph><heading level='2'>Optimization</heading><heading level='3'>Optimizations used by an artist when a scene is being developed</heading><paragraph>Due to the large number of calculations, a work in progress is usually only rendered in detail appropriate to the portion of the work being developed at a given time, so in the initial stages of modeling, wireframe and ray casting may be used, even where the target output is ray tracing with radiosity. It is also common to render only parts of the scene at high detail, and to remove objects that are not important to what is currently being developed.</paragraph><heading level='3'>Common optimizations for real time rendering</heading><paragraph>For real-time, it is appropriate to simplify one or more common approximations, and tune to the exact parameters of the scenery in question, which is also tuned to the agreed parameters to get the most 'bang for the buck'.</paragraph><heading level='2'>Academic core</heading><paragraph><template><target>Main</target><arg>Unbiased rendering</arg></template></paragraph><paragraph>The implementation of a realistic renderer always has some basic element of physical simulation or emulation &amp;mdash; some computation which resembles or abstracts a real physical process.</paragraph><paragraph>The term &quot;<italics>physically based</italics>&quot; indicates the use of physical models and approximations that are more general and widely accepted outside rendering. A particular set of related techniques have gradually become established in the rendering community.</paragraph><paragraph>The basic concepts are moderately straightforward, but intractable to calculate; and a single elegant algorithm or approach has been elusive for more general purpose renderers. In order to meet demands of robustness, accuracy and practicality, an implementation will be a complex combination of different techniques.</paragraph><paragraph>Rendering research is concerned with both the adaptation of scientific models and their efficient application.</paragraph><heading level='3'>The rendering equation</heading><paragraph><template><target>Main</target><arg>Rendering equation</arg></template></paragraph><paragraph>This is the key academic/theoretical concept in rendering. It serves as the most abstract formal expression of the non-perceptual aspect of rendering. All more complete algorithms can be seen as solutions to particular formulations of this equation.</paragraph><list type='ident'><listitem><extension extension_name='math'>L_o(x, \vec w) = L_e(x, \vec w) + \int_\Omega f_r(x, \vec w', \vec w) L_i(x, \vec w') (\vec w' \cdot \vec n) \mathrm{d}\vec w'</extension></listitem></list><paragraph>Meaning: at a particular position and direction, the outgoing light (L<xhtml:sub>o</xhtml:sub>) is the sum of the emitted light (L<xhtml:sub>e</xhtml:sub>) and the reflected light. The reflected light being the sum of the incoming light (L<xhtml:sub>i</xhtml:sub>) from all directions, multiplied by the surface reflection and incoming angle. By connecting outward light to inward light, via an interaction point, this equation stands for the whole 'light transport' &amp;mdash; all the movement of light in a scene.</paragraph><heading level='3'>The bidirectional reflectance distribution function</heading><paragraph>The<space/><bold><link><target>bidirectional reflectance distribution function</target></link></bold><space/>(BRDF) expresses a simple model of light interaction with a surface as follows:</paragraph><list type='ident'><listitem><extension extension_name='math'>f_r(x, \vec w', \vec w) = \frac{\mathrm{d}L_r(x, \vec w)}{L_i(x, \vec w')(\vec w' \cdot \vec n) \mathrm{d}\vec w'}</extension></listitem></list><paragraph>Light interaction is often approximated by the even simpler models: diffuse reflection and specular reflection, although both can ALSO be BRDFs.</paragraph><heading level='3'>Geometric optics</heading><paragraph>Rendering is practically exclusively concerned with the particle aspect of light physics &amp;mdash; known as<space/><link><target>geometric optics</target></link>. Treating light, at its basic level, as particles bouncing around is a simplification, but appropriate: the wave aspects of light are negligible in most scenes, and are significantly more difficult to simulate. Notable wave aspect phenomena include diffraction (as seen in the colours of<space/><link><target>Compact disc</target><part>CDs</part></link><space/>and<space/><link><target>DVD</target><trail>s</trail></link>) and polarisation (as seen in<space/><link><target>Liquid crystal display</target><part>LCDs</part></link>). Both types of effect, if needed, are made by appearance-oriented adjustment of the reflection model.</paragraph><heading level='3'>Visual perception</heading><paragraph>Though it receives less attention, an understanding of human visual perception is valuable to rendering. This is mainly because image displays and human perception have restricted ranges. A renderer can simulate an almost infinite range of light brightness and color, but current displays &amp;mdash; movie screen, computer monitor, etc. &amp;mdash; cannot handle so much, and something must be discarded or compressed. Human perception also has limits, and so does not need to be given large-range images to create realism. This can help solve the problem of fitting images into displays, and, furthermore, suggest what short-cuts could be used in the rendering simulation, since certain subtleties won't be noticeable. This related subject is<space/><link><target>tone mapping</target></link><space/>result.</paragraph><paragraph>Mathematics used in rendering includes:<space/><link><target>linear algebra</target></link>,<space/><link><target>calculus</target></link>,<space/><link><target>numerical analysis</target><part>numerical mathematics</part></link>,<space/><link><target>digital signal processing</target><part>signal processing</part></link>, and<space/><link><target>Monte Carlo methods</target></link>.</paragraph><paragraph>Rendering for movies often takes place on a network of tightly connected computers known as a<space/><link><target>render farm</target></link>.</paragraph><paragraph>The current<template><target>when</target><arg name="date">February 2014</arg></template><space/>state of the art in 3-D image description for movie creation is the<space/><link><target>mental ray</target></link><space/><link><target>scene description language</target></link><space/>designed at<space/><link><target>mental images</target></link><space/>and<space/><link><target>RenderMan Shading Language</target></link><space/>designed at<space/><link><target>Pixar</target></link>.<extension extension_name='ref'><link type='external' href='http://portal.acm.org/citation.cfm?id=1185817&amp;amp;jmp=abstract&amp;amp;coll=GUIDE&amp;amp;dl=GUIDE'>A brief introduction to RenderMan</link></extension><space/>(compare with simpler 3D fileformats such as<space/><link><target>VRML</target></link><space/>or<space/><link><target>application programming interface</target><part>APIs</part></link><space/>such as<space/><link><target>OpenGL</target></link><space/>and<space/><link><target>DirectX</target></link><space/>tailored for 3D hardware accelerators).</paragraph><paragraph>Other renderers (including proprietary ones) can and are sometimes used, but most other renderers tend to miss one or more of the often needed features like good texture filtering, texture caching, programmable shaders, highend geometry types like hair, subdivision or nurbs surfaces with tesselation on demand, geometry caching, raytracing with geometry caching, high quality shadow mapping, speed or patent-free implementations. Other highly sought features these days may include<space/><link><target>Interactive Photorealistic Rendering</target><part>IPR</part></link><space/>and hardware rendering/shading.</paragraph><heading level='2'>Chronology of important published ideas</heading><paragraph><link><target>File:ESTCube orbiidil 2.jpg</target><part>thumb</part><part>Rendering of an<space/><link><target>ESTCube-1</target></link><space/>satellite</part></link></paragraph><paragraph><template><target>Div col</target><arg></arg><arg>25em</arg></template></paragraph><list type='bullet'><listitem>1968<space/><italics><link><target>Ray casting</target></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink"><space/>Arthur Appel<space/></arg><arg name="last"><space/>Appel<space/></arg><arg name="first"><space/>A.<space/></arg><arg name="year"><space/>1968<space/></arg><arg name="url"><space/>http://graphics.stanford.edu/courses/Appel.pdf<space/></arg><arg name="title"><space/>Some techniques for shading machine renderings of solids<space/></arg><arg name="booktitle"><space/>Proceedings of the Spring Joint Computer Conference<space/></arg><arg name="volume"><space/>32<space/></arg><arg name="pages"><space/>37–49<space/></arg></template></extension></listitem><listitem>1970<space/><italics><link><target>Scanline rendering</target></link></italics><extension extension_name='ref'><template><target>cite journal</target><arg name="authorlink"><space/>W. Jack Bouknight<space/></arg><arg name="last"><space/>Bouknight<space/></arg><arg name="first"><space/>W. J.<space/></arg><arg name="year"><space/>1970<space/></arg><arg name="title"><space/>A procedure for generation of three-dimensional half-tone computer graphics presentations<space/></arg><arg name="journal"><space/>Communications of the ACM<space/></arg><arg name="volume"><space/>13<space/></arg><arg name="issue"><space/>9<space/></arg><arg name="pages"><space/>527–536<space/></arg><arg name="doi"><space/>10.1145/362736.362739<space/></arg></template></extension></listitem><listitem>1971<space/><italics><link><target>Gouraud shading</target></link></italics><extension extension_name='ref'><template><target>cite journal</target><arg name="authorlink"><space/>Henri Gouraud (computer scientist)<space/></arg><arg name="last"><space/>Gouraud<space/></arg><arg name="first"><space/>H.<space/></arg><arg name="year"><space/>1971<space/></arg><arg name="url"><space/>http://www.cs.uiowa.edu/~cwyman/classes/spring05-22C251/papers/ContinuousShadingOfCurvedSurfaces.pdf<space/></arg><arg name="title"><space/>Continuous shading of curved surfaces<space/></arg><arg name="journal"><space/>IEEE Transactions on Computers<space/></arg><arg name="volume"><space/>20<space/></arg><arg name="issue"><space/>6<space/></arg><arg name="pages"><space/>623–629<space/></arg><arg name="doi">10.1109/t-c.1971.223313</arg></template></extension></listitem><listitem>1973<space/><italics><link><target>Phong shading</target></link></italics><extension extension_name='ref' name="phong">University of Utah School of Computing, http://www.cs.utah.edu/school/history/#phong-ref</extension><extension extension_name='ref'><template><target>cite journal</target><arg name="authorlink"><space/>Bui Tuong Phong<space/></arg><arg name="last"><space/>Phong<space/></arg><arg name="first"><space/>B-T<space/></arg><arg name="year"><space/>1975<space/></arg><arg name="url"><space/>http://jesper.kalliope.org/blog/library/p311-phong.pdf<space/></arg><arg name="title"><space/>Illumination for computer generated pictures<space/></arg><arg name="journal"><space/>Communications of the ACM<space/></arg><arg name="volume"><space/>18<space/></arg><arg name="issue"><space/>6<space/></arg><arg name="pages"><space/>311–316<space/></arg><arg name="doi">10.1145/360825.360839</arg></template></extension></listitem><listitem>1973<space/><italics><link><target>Phong reflection model</target><part>Phong reflection</part></link></italics><extension extension_name='ref' name="phong"></extension></listitem><listitem>1973<space/><italics><link><target>Diffuse reflection</target></link></italics><extension extension_name='ref'>Bui Tuong Phong,<space/><link type='external' href='http://www.cs.northwestern.edu/~ago820/cs395/Papers/Phong_1975.pdf'>Illumination for computer generated pictures</link>, Communications of ACM 18 (1975), no. 6, 311317.</extension></listitem><listitem>1973<space/><italics><link><target>Specular highlight</target></link></italics><extension extension_name='ref' name="phong"></extension></listitem><listitem>1973<space/><italics><link><target>Specular reflection</target></link></italics><extension extension_name='ref' name="phong"></extension></listitem><listitem>1974<space/><italics><link><target>Sprite (computer graphics)</target><part>Sprites</part></link></italics><extension extension_name='ref' name="vintage3d">http://vintage3d.org/history.php</extension></listitem><listitem>1974<space/><italics><link><target>Scrolling</target></link></italics><extension extension_name='ref' name="vintage3d"></extension></listitem><listitem>1974<space/><italics><link><target>Texture mapping</target></link></italics><extension extension_name='ref' name="Catmull thesis"><template><target>cite thesis</target><arg name="authorlink"><space/>Edwin Catmull<space/></arg><arg name="last"><space/>Catmull<space/></arg><arg name="first"><space/>E.<space/></arg><arg name="year"><space/>1974<space/></arg><arg name="url"><space/>http://www.pixartouchbook.com/storage/catmull_thesis.pdf<space/></arg><arg name="title"><space/>A subdivision algorithm for computer display of curved surfaces<space/></arg><arg name="degree"><space/>PhD<space/></arg><arg name="publisher"><space/>University of Utah<space/></arg></template></extension></listitem><listitem>1974<space/><italics><link><target>Z-buffering</target></link></italics><extension extension_name='ref' name="Catmull thesis"></extension></listitem><listitem>1976<space/><italics><link><target>Environment mapping</target></link></italics><extension extension_name='ref'><template><target>cite journal</target><arg name="authorlink1"><space/>James F. Blinn<space/></arg><arg name="last1"><space/>Blinn<space/></arg><arg name="first1"><space/>J.F.<space/></arg><arg name="authorlink2"><space/>M. E. Newell<space/></arg><arg name="last2"><space/>Newell<space/></arg><arg name="first2"><space/>M.E.<space/></arg><arg name="year"><space/>1976<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.87.8903}}<space/></arg><arg name="title"><space/>Texture and reflection in computer generated images<space/></arg><arg name="journal"><space/>Communications of the ACM<space/></arg><arg name="volume"><space/>19<space/></arg><arg name="pages"><space/>542–546<space/></arg><arg name="doi">10.1145/360349.360353</arg></template></extension></listitem><listitem>1977<space/><italics><link><target>Side-scrolling video game</target><part>Side-scrolling</part></link></italics><extension extension_name='ref'>http://www.arcade-museum.com/game_detail.php?game_id=12797</extension></listitem><listitem>1977<space/><italics><link><target>Shadow volume</target><trail>s</trail></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink"><space/>Franklin C. Crow<space/></arg><arg name="last"><space/>Crow<space/></arg><arg name="first"><space/>F.C.<space/></arg><arg name="year"><space/>1977<space/></arg><arg name="url"><space/>http://design.osu.edu/carlson/history/PDFs/crow-shadows.pdf<space/></arg><arg name="title"><space/>Shadow algorithms for computer graphics<space/></arg><arg name="booktitle"><space/>Computer Graphics (Proceedings of SIGGRAPH 1977)<space/></arg><arg name="volume"><space/>11<space/></arg><arg name="issue"><space/>2<space/></arg><arg name="pages"><space/>242–248<space/></arg></template></extension></listitem><listitem>1978<space/><italics>Shadow buffer</italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink"><space/>Lance Williams<space/></arg><arg name="last"><space/>Williams<space/></arg><arg name="first"><space/>L.<space/></arg><arg name="year"><space/>1978<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.134.8225}}<space/></arg><arg name="title"><space/>Casting curved shadows on curved surfaces<space/></arg><arg name="booktitle"><space/>Computer Graphics (Proceedings of SIGGRAPH 1978)<space/></arg><arg name="volume"><space/>12<space/></arg><arg name="issue"><space/>3<space/></arg><arg name="pages"><space/>270–274<space/></arg></template></extension></listitem><listitem>1978<space/><italics><link><target>Bump mapping</target></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink"><space/>James F. Blinn<space/></arg><arg name="last"><space/>Blinn<space/></arg><arg name="first"><space/>J.F.<space/></arg><arg name="year"><space/>1978<space/></arg><arg name="url"><space/>http://research.microsoft.com/pubs/73939/p286-blinn.pdf<space/></arg><arg name="title"><space/>Simulation of wrinkled surfaces<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1978)<space/></arg><arg name="volume"><space/>12<space/></arg><arg name="issue"><space/>3<space/></arg><arg name="pages"><space/>286–292<space/></arg></template></extension></listitem><listitem>1979<space/><italics><link><target>Tile engine</target><part>Tile map</part></link></italics><extension extension_name='ref'>http://books.google.co.uk/books?id=oK3D4i5ldKgC&amp;pg=PA173</extension></listitem><listitem>1980<space/><italics><link><target>BSP trees</target></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink1"><space/>Henry Fuchs<space/></arg><arg name="last1"><space/>Fuchs<space/></arg><arg name="first1"><space/>H.<space/></arg><arg name="authorlink2"><space/>Zvi M. Kedem<space/></arg><arg name="last2"><space/>Kedem<space/></arg><arg name="first2"><space/>Z.M.<space/></arg><arg name="authorlink3"><space/>Bruce F. Naylor<space/></arg><arg name="last3"><space/>Naylor<space/></arg><arg name="first3"><space/>B.F.<space/></arg><arg name="year"><space/>1980<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.112.4406}}<space/></arg><arg name="title"><space/>On visible surface generation by a priori tree structures<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1980)<space/></arg><arg name="volume"><space/>14<space/></arg><arg name="issue"><space/>3<space/></arg><arg name="pages"><space/>124–133<space/></arg></template></extension></listitem><listitem>1980<space/><italics><link><target>Ray tracing (graphics)</target><part>Ray tracing</part></link></italics><extension extension_name='ref'><template><target>cite journal</target><arg name="authorlink"><space/>Turner Whitted<space/></arg><arg name="last"><space/>Whitted<space/></arg><arg name="first"><space/>T.<space/></arg><arg name="year"><space/>1980<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.114.7629}}<space/></arg><arg name="title"><space/>An improved illumination model for shaded display<space/></arg><arg name="journal"><space/>Communications of the ACM<space/></arg><arg name="volume"><space/>23<space/></arg><arg name="issue"><space/>6<space/></arg><arg name="pages"><space/>343–349<space/></arg><arg name="doi">10.1145/358876.358882</arg></template></extension></listitem><listitem>1981<space/><italics><link><target>Parallax scrolling</target></link></italics><extension extension_name='ref'>http://books.google.co.uk/books?id=lB4PAwAAQBAJ&amp;pg=PA181</extension></listitem><listitem>1981<space/><italics><link><target>2.5D#Scaling along the Z axis</target><part>Sprite zooming</part></link></italics><extension extension_name='ref'>http://www.system16.com/hardware.php?id=690</extension></listitem><listitem>1981<space/><italics>Cook shader</italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink1"><space/>Robert L. Cook<space/></arg><arg name="last1"><space/>Cook<space/></arg><arg name="first1"><space/>R.L.<space/></arg><arg name="authorlink2"><space/>Kenneth E. Torrance<space/></arg><arg name="last2"><space/>Torrance<space/></arg><arg name="first2"><space/>K.E.<space/></arg><arg name="year"><space/>1981<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.88.7796}}<space/></arg><arg name="title"><space/>A reflectance model for computer graphics<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1981)<space/></arg><arg name="volume"><space/>15<space/></arg><arg name="issue"><space/>3<space/></arg><arg name="pages"><space/>307–316<space/></arg></template></extension></listitem><listitem>1983<space/><italics><link><target>Mipmap</target><part>MIP maps</part></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink"><space/>Lance Williams<space/></arg><arg name="last"><space/>Williams<space/></arg><arg name="first"><space/>L.<space/></arg><arg name="year"><space/>1983<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.163.6298}}<space/></arg><arg name="title"><space/>Pyramidal parametrics<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1983)<space/></arg><arg name="volume"><space/>17<space/></arg><arg name="issue"><space/>3<space/></arg><arg name="pages"><space/>1–11<space/></arg></template></extension></listitem><listitem>1984<space/><italics><link><target>Octree</target></link><space/>ray tracing</italics><extension extension_name='ref'><template><target>cite journal</target><arg name="authorlink"><space/>Andrew Glassner<space/></arg><arg name="last"><space/>Glassner<space/></arg><arg name="first"><space/>A.S.<space/></arg><arg name="year"><space/>1984<space/></arg><arg name="title"><space/>Space subdivision for fast ray tracing<space/></arg><arg name="journal"><space/>IEEE Computer Graphics & Applications<space/></arg><arg name="volume"><space/>4<space/></arg><arg name="issue"><space/>10<space/></arg><arg name="pages"><space/>15–22<space/></arg><arg name="doi">10.1109/mcg.1984.6429331</arg></template></extension></listitem><listitem>1984<space/><italics><link><target>Alpha compositing</target></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink1"><space/></arg><arg name="last1"><space/>Porter<space/></arg><arg name="first1"><space/>T.<space/></arg><arg name="authorlink2"><space/>Tom Duff<space/></arg><arg name="last2"><space/>Duff<space/></arg><arg name="first2"><space/>T.<space/></arg><arg name="year"><space/>1984<space/></arg><arg name="url"><space/>http://keithp.com/~keithp/porterduff/p253-porter.pdf<space/></arg><arg name="title"><space/>Compositing digital images<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1984)<space/></arg><arg name="volume"><space/>18<space/></arg><arg name="issue"><space/>3<space/></arg><arg name="pages"><space/>253–259<space/></arg></template></extension></listitem><listitem>1984<space/><italics><link><target>Distributed ray tracing</target></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink1"><space/>Robert L. Cook<space/></arg><arg name="last1"><space/>Cook<space/></arg><arg name="first1"><space/>R.L.<space/></arg><arg name="authorlink2"><space/></arg><arg name="last2"><space/>Porter<space/></arg><arg name="first2"><space/>T.<space/></arg><arg name="authorlink3"><space/>Loren Carpenter<space/></arg><arg name="last3"><space/>Carpenter<space/></arg><arg name="first3"><space/>L.<space/></arg><arg name="year"><space/>1984<space/></arg><arg name="url"><space/>http://www.cs.rutgers.edu/~nealen/teaching/cs428_fall09/readings/cook84.pdf<space/></arg><arg name="title"><space/>Distributed ray tracing<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1984)<space/></arg><arg name="volume"><space/>18<space/></arg><arg name="issue"><space/>3<space/></arg><arg name="pages"><space/>137–145<space/></arg></template></extension></listitem><listitem>1984<space/><italics><link><target>Radiosity (computer graphics)</target><part>Radiosity</part></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink"><space/>Cindy M. Goral<space/></arg><arg name="last1"><space/>Goral<space/></arg><arg name="first1"><space/>C.<space/></arg><arg name="authorlink2"><space/>Kenneth E. Torrance<space/></arg><arg name="last2"><space/>Torrance<space/></arg><arg name="first2"><space/>K.E.<space/></arg><arg name="authorlink3"><space/>Donald P. Greenberg<space/></arg><arg name="last3"><space/>Greenberg<space/></arg><arg name="first3"><space/>D.P.<space/></arg><arg name="authorlink4"><space/>Bennett Battaile<space/></arg><arg name="last4"><space/>Battaile<space/></arg><arg name="first4"><space/>B.<space/></arg><arg name="year"><space/>1984<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.112.356}}<space/></arg><arg name="title"><space/>Modeling the interaction of light between diffuse surfaces<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1984)<space/></arg><arg name="volume"><space/>18<space/></arg><arg name="issue"><space/>3<space/></arg><arg name="pages"><space/>213–222<space/></arg></template></extension></listitem><listitem>1985<space/><italics><link><target>Parallax scrolling#Raster method</target><part>Row/column scrolling</part></link></italics><extension extension_name='ref'>http://cgfm2.emuviews.com/txt/s16tech.txt</extension></listitem><listitem>1985<space/><italics><link><target>Hemicube (computer graphics)</target><part>Hemicube</part></link><space/>radiosity</italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink1"><space/>Michael F. Cohen<space/></arg><arg name="last1"><space/>Cohen<space/></arg><arg name="first1"><space/>M.F.<space/></arg><arg name="authorlink2"><space/>Donald P. Greenberg<space/></arg><arg name="last2"><space/>Greenberg<space/></arg><arg name="first2"><space/>D.P.<space/></arg><arg name="year"><space/>1985<space/></arg><arg name="url"><space/>http://www.arnetminer.org/dev.do?m</arg><arg name="title"><space/>The hemi-cube: a radiosity solution for complex environments<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1985)<space/></arg><arg name="volume"><space/>19<space/></arg><arg name="issue"><space/>3<space/></arg><arg name="pages"><space/>31–40<space/></arg><arg name="doi"><space/>10.1145/325165.325171</arg></template></extension></listitem><listitem>1986<space/><italics>Light source tracing</italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink"><space/>James Arvo<space/></arg><arg name="last"><space/>Arvo<space/></arg><arg name="first"><space/>J.<space/></arg><arg name="year"><space/>1986<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.31.581}}<space/></arg><arg name="title"><space/>Backward ray tracing<space/></arg><arg name="conference"><space/>SIGGRAPH 1986 Developments in Ray Tracing course notes<space/></arg></template></extension></listitem><listitem>1986<space/><italics><link><target>Rendering equation</target></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink"><space/>Jim Kajiya<space/></arg><arg name="last"><space/>Kajiya<space/></arg><arg name="first"><space/>J.<space/></arg><arg name="year"><space/>1986<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.63.1402}}<space/></arg><arg name="title"><space/>The rendering equation<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1986)<space/></arg><arg name="volume"><space/>20<space/></arg><arg name="issue"><space/>4<space/></arg><arg name="pages"><space/>143–150<space/></arg></template></extension></listitem><listitem>1987<space/><italics><link><target>Reyes rendering</target></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink1"><space/>Robert L. Cook<space/></arg><arg name="last1"><space/>Cook<space/></arg><arg name="first1"><space/>R.L.<space/></arg><arg name="authorlink2"><space/>Loren Carpenter<space/></arg><arg name="last2"><space/>Carpenter<space/></arg><arg name="first2"><space/>L.<space/></arg><arg name="authorlink3"><space/>Edwin Catmull<space/></arg><arg name="last3"><space/>Catmull<space/></arg><arg name="first3"><space/>E.<space/></arg><arg name="year"><space/>1987<space/></arg><arg name="url"><space/>http://graphics.pixar.com/library/Reyes/paper.pdf<space/></arg><arg name="title"><space/>The Reyes image rendering architecture<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1987)<space/></arg><arg name="volume"><space/>21<space/></arg><arg name="issue"><space/>4<space/></arg><arg name="pages"><space/>95–102<space/></arg></template></extension></listitem><listitem>1988<space/><italics><link><target>Depth perception</target><part>Depth cue</part></link></italics><extension extension_name='ref' name="s21">http://mamedev.org/source/src/mame/drivers/namcos21.c.html</extension></listitem><listitem>1988<space/><italics><link><target>Distance fog</target></link></italics><extension extension_name='ref' name="s21"></extension></listitem><listitem>1988<space/><italics><link><target>Tiled rendering</target></link></italics><extension extension_name='ref' name="s21"></extension></listitem><listitem>1991<space/><italics><link><target>Xiaolin Wu's line algorithm</target><part>Xiaolin Wu line anti-aliasing</part></link></italics><extension extension_name='ref'><template><target>cite journal</target><arg name="author">Wu, Xiaolin<space/></arg><arg name="url"><space/>http://portal.acm.org/citation.cfm?id</arg><arg name="title"><space/>An efficient antialiasing technique<space/></arg><arg name="journal">[[Computer Graphics]]<space/></arg><arg name="date">July 1991<space/></arg><arg name="volume">25<space/></arg><arg name="issue">4<space/></arg><arg name="pages">143–152<space/></arg><arg name="doi"><space/>10.1145/127719.122734<space/></arg><arg name="isbn">0-89791-436-8<space/></arg></template></extension><extension extension_name='ref'><template><target>cite book</target><arg name="author"><space/>Wu, Xiaolin<space/></arg><arg name="year"><space/>1991<space/></arg><arg name="chapter"><space/>Fast Anti-Aliased Circle Generation<space/></arg><arg name="editor"><space/>James Arvo (Ed.)<space/></arg><arg name="title"><space/>Graphics Gems II<space/></arg><arg name="pages"><space/>446–450<space/></arg><arg name="location"><space/>San Francisco<space/></arg><arg name="publisher"><space/>Morgan Kaufmann<space/></arg><arg name="isbn"><space/>0-12-064480-0<space/></arg></template></extension></listitem><listitem>1991<space/><italics>Hierarchical radiosity</italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink1"><space/>Pat Hanrahan<space/></arg><arg name="last1"><space/>Hanrahan<space/></arg><arg name="first1"><space/>P.<space/></arg><arg name="authorlink2"><space/>David Salzman<space/></arg><arg name="last2"><space/>Salzman<space/></arg><arg name="first2"><space/>D.<space/></arg><arg name="authorlink3"><space/>Larry Aupperle<space/></arg><arg name="last3"><space/>Aupperle<space/></arg><arg name="first3"><space/>L.<space/></arg><arg name="year"><space/>1991<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.93.5694}}<space/></arg><arg name="title"><space/>A rapid hierarchical radiosity algorithm<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1991)<space/></arg><arg name="volume"><space/>25<space/></arg><arg name="issue"><space/>4<space/></arg><arg name="pages"><space/>197–206<space/></arg></template></extension></listitem><listitem>1993<space/><italics><link><target>Texture filtering</target></link></italics><extension extension_name='ref'>http://ign.com/articles/2009/04/21/ign-presents-the-history-of-sega?page=8</extension></listitem><listitem>1993<space/><italics><link><target>Texture mapping#Perspective correctness</target><part>Perspective correction</part></link></italics><extension extension_name='ref'>http://www.system16.com/hardware.php?id=713</extension></listitem><listitem>1993<space/><italics><link><target>Transform, clipping, and lighting</target></link></italics><extension extension_name='ref' name="magic">http://www.system16.com/hardware.php?id=832</extension></listitem><listitem>1993<space/><italics><link><target>Shading#Directional lighting</target><part>Directional lighting</part></link></italics><extension extension_name='ref' name="magic"></extension></listitem><listitem>1993<space/><italics><link><target>Trilinear interpolation</target></link></italics><extension extension_name='ref' name="magic"></extension></listitem><listitem>1993<space/><italics><link><target>Z-buffering#Z-culling</target><part>Z-culling</part></link></italics><extension extension_name='ref' name="magic"></extension></listitem><listitem>1993<space/><italics><link><target>OrenNayar reflectance model</target><part>OrenNayar reflectance</part></link></italics><extension extension_name='ref' name="oren-nayar">M. Oren and S.K. Nayar, &quot;<link type='external' href='http://www1.cs.columbia.edu/CAVE/publications/pdfs/Oren_SIGGRAPH94.pdf'>Generalization of Lambert's Reflectance Model</link>&quot;. SIGGRAPH. pp.239-246, Jul, 1994</extension></listitem><listitem>1993<space/><italics><link><target>Tone mapping</target></link></italics><extension extension_name='ref'><template><target>cite journal</target><arg name="authorlink1"><space/>Jack Tumblin<space/></arg><arg name="last1"><space/>Tumblin<space/></arg><arg name="first1"><space/>J.<space/></arg><arg name="authorlink2"><space/>Holly Rushmeier<space/></arg><arg name="last2"><space/>Rushmeier<space/></arg><arg name="first2"><space/>H.E.<space/></arg><arg name="year"><space/>1993<space/></arg><arg name="url"><space/>http://smartech.gatech.edu/bitstream/handle/1853/3686/92-31.pdf?sequence</arg><arg name="title"><space/>Tone reproduction for realistic computer generated images<space/></arg><arg name="journal"><space/>IEEE Computer Graphics & Applications<space/></arg><arg name="volume"><space/>13<space/></arg><arg name="issue"><space/>6<space/></arg><arg name="pages"><space/>42–48<space/></arg><arg name="doi">10.1109/38.252554</arg></template></extension></listitem><listitem>1993<space/><italics><link><target>Subsurface scattering</target></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink1"><space/>Pat Hanrahan<space/></arg><arg name="last1"><space/>Hanrahan<space/></arg><arg name="first1"><space/>P.<space/></arg><arg name="authorlink2"><space/>Wolfgang Krueger<space/></arg><arg name="last2"><space/>Krueger<space/></arg><arg name="first2"><space/>W.<space/></arg><arg name="year"><space/>1993<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.57.9761}}<space/></arg><arg name="title"><space/>Reflection from layered surfaces due to subsurface scattering<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1993)<space/></arg><arg name="volume"><space/>27<space/></arg><arg name="pages"><space/>165–174<space/></arg></template></extension></listitem><listitem>1994<space/><italics><link><target>Heightmap</target></link></italics><extension extension_name='ref'>http://www.extentofthejam.com/pseudo/</extension></listitem><listitem>1995<space/><italics><link><target>Hidden surface determination</target></link></italics><extension extension_name='ref'>http://www.hotchips.org/wp-content/uploads/hc_archives/hc07/3_Tue/HC7.S5/HC7.5.1.pdf</extension></listitem><listitem>1995<space/><italics><link><target>Photon mapping</target></link></italics><extension extension_name='ref'><template><target>cite journal</target><arg name="authorlink1"><space/>Henrik Wann Jensen<space/></arg><arg name="last1"><space/>Jensen<space/></arg><arg name="first1"><space/>H.W.<space/></arg><arg name="authorlink2"><space/>Niels Jørgen Christensen<space/></arg><arg name="last2"><space/>Christensen<space/></arg><arg name="first2"><space/>N.J.<space/></arg><arg name="year"><space/>1995<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.97.2724}}<space/></arg><arg name="title"><space/>Photon maps in bidirectional monte carlo ray tracing of complex objects<space/></arg><arg name="journal"><space/>Computers & Graphics<space/></arg><arg name="volume"><space/>19<space/></arg><arg name="issue"><space/>2<space/></arg><arg name="pages"><space/>215–224<space/></arg><arg name="doi">10.1016/0097-8493(94)00145-o</arg></template></extension></listitem><listitem>1996<space/><italics><link><target>Multisample anti-aliasing</target></link></italics><extension extension_name='ref'>http://www.system16.com/hardware.php?id=717</extension></listitem><listitem>1997<space/><italics><link><target>Metropolis light transport</target></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink1"><space/>Eric Veach<space/></arg><arg name="last1"><space/>Veach<space/></arg><arg name="first1"><space/>E.<space/></arg><arg name="authorlink2"><space/>Leonidas J. Guibas<space/></arg><arg name="last2"><space/>Guibas<space/></arg><arg name="first2"><space/>L.<space/></arg><arg name="year"><space/>1997<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.88.944}}<space/></arg><arg name="title"><space/>Metropolis light transport<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1997)<space/></arg><arg name="volume"><space/>16<space/></arg><arg name="pages"><space/>65–76<space/></arg></template></extension></listitem><listitem>1997<space/><italics>Instant Radiosity</italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink"><space/>Alex Keller<space/></arg><arg name="last"><space/>Keller<space/></arg><arg name="first"><space/>A.<space/></arg><arg name="year"><space/>1997<space/></arg><arg name="id"><space/>{{citeseerx|10.1.1.15.240}}<space/></arg><arg name="title"><space/>Instant Radiosity<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 1997)<space/></arg><arg name="volume"><space/>24<space/></arg><arg name="pages"><space/>49–56<space/></arg></template></extension></listitem><listitem>1998<space/><italics><link><target>Hidden surface removal</target></link></italics><extension extension_name='ref'>http://web.archive.org/web/20070811102018/http://www3.sharkyextreme.com/hardware/reviews/video/neon250/2.shtml</extension></listitem><listitem>2002<space/><italics><link><target>Precomputed Radiance Transfer</target></link></italics><extension extension_name='ref'><template><target>cite conference</target><arg name="authorlink1"><space/>Peter Pike Sloan<space/></arg><arg name="last1"><space/>Sloan<space/></arg><arg name="first1"><space/>P.<space/></arg><arg name="authorlink2"><space/>Jan Kautz<space/></arg><arg name="last2"><space/>Kautz<space/></arg><arg name="first2"><space/>J.<space/></arg><arg name="authorlink3"><space/>John Snyder (computer scientist)<space/></arg><arg name="last3"><space/>Snyder<space/></arg><arg name="first3"><space/>J.<space/></arg><arg name="year"><space/>2002<space/></arg><arg name="url"><space/>http://www.mpi-inf.mpg.de/~jnkautz/projects/prt/prtSIG02.pdf<space/></arg><arg name="title"><space/>Precomputed Radiance Transfer for Real-Time Rendering in Dynamic, Low Frequency Lighting Environments<space/></arg><arg name="conference"><space/>Computer Graphics (Proceedings of SIGGRAPH 2002)<space/></arg><arg name="volume"><space/>29<space/></arg><arg name="pages"><space/>527–536<space/></arg></template></extension></listitem></list><paragraph><template><target>Div col end</target></template></paragraph><heading level='2'>See also</heading><paragraph><template><target>Portal</target><arg>Computer graphics</arg></template><template><target>Div col</target><arg></arg><arg>25em</arg></template></paragraph><list type='bullet'><listitem><link><target>2D computer graphics</target></link></listitem><listitem><link><target>3D computer graphics</target></link></listitem><listitem><link><target>3D rendering</target></link></listitem><listitem><link><target>Architectural rendering</target></link></listitem><listitem><link><target>Global illumination</target></link></listitem><listitem><link><target>Graphics pipeline</target></link></listitem><listitem><link><target>High dynamic range rendering</target></link></listitem><listitem><link><target>Image-based modeling and rendering</target></link></listitem><listitem><link><target>Non-photorealistic rendering</target></link></listitem><listitem><link><target>Painter's algorithm</target></link></listitem><listitem><link><target>Pre-rendered</target></link></listitem><listitem><link><target>Raster image processor</target></link></listitem><listitem><link><target>Radiosity (computer graphics)</target><part>Radiosity</part></link></listitem><listitem><link><target>Ray tracing (graphics)</target><part>Ray tracing</part></link></listitem><listitem><link><target>Real-time computer graphics</target></link></listitem><listitem><link><target>Reyes rendering</target><part>Reyes</part></link></listitem><listitem><link><target>Scanline rendering</target><part>Scanline rendering/Scanline algorithm</part></link></listitem><listitem><link><target>Software rendering</target></link></listitem><listitem><link><target>Sprite (computer graphics)</target></link></listitem><listitem><link><target>Unbiased rendering</target></link></listitem><listitem><link><target>Vector graphics</target></link></listitem><listitem><link><target>VirtualGL</target></link></listitem><listitem><link><target>Virtual model</target></link></listitem><listitem><link><target>Virtual studio</target></link></listitem><listitem><link><target>Volume rendering</target></link></listitem><listitem><link><target>Z-buffering</target><part>Z-buffer algorithms</part></link></listitem></list><paragraph><template><target>Div col end</target></template></paragraph><heading level='2'>References</heading><paragraph><template><target>Reflist</target><arg>30em</arg></template></paragraph><heading level='2'>Further reading</heading><paragraph><template><target>Refbegin</target></template></paragraph><list type='bullet'><listitem><template><target>cite book</target><arg name="last">Pharr</arg><arg name="first">Matt</arg><arg name="title">Physically based rendering from theory to implementation</arg><arg name="year">2004</arg><arg name="publisher">Elsevier/Morgan Kaufmann</arg><arg name="location">Amsterdam</arg><arg name="isbn">0-12-553180-X</arg><arg name="edition"></arg><arg name="first2">Greg</arg><arg name="last2">Humphreys</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Shirley</arg><arg name="first">Peter</arg><arg name="title">Realistic ray tracing</arg><arg name="year">2003</arg><arg name="publisher">AK Peters</arg><arg name="location">Natick, Mass.</arg><arg name="isbn">1-56881-198-5</arg><arg name="edition">2</arg><arg name="first2">R. Keith</arg><arg name="last2">Morley</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Dutré</arg><arg name="first">Philip</arg><arg name="title">Advanced global illumination</arg><arg name="year">2003</arg><arg name="publisher">A K Peters</arg><arg name="location">Natick, Mass.</arg><arg name="isbn">1-56881-177-2</arg><arg name="edition">[Online-Ausg.]</arg><arg name="first2">Philippe</arg><arg name="last2">Bekaert</arg><arg name="first3">Kavita</arg><arg name="last3">Bala</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Akenine-Möller</arg><arg name="first">Tomas</arg><arg name="title">Real-time rendering</arg><arg name="year">2004</arg><arg name="publisher">AK Peters</arg><arg name="location">Natick, Mass.</arg><arg name="isbn">1-56881-182-9</arg><arg name="edition">2</arg><arg name="first2">Eric</arg><arg name="last2">Haines</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Strothotte</arg><arg name="first">Thomas</arg><arg name="title">Non-photorealistic computer graphics modeling, rendering, and animation</arg><arg name="year">2002</arg><arg name="publisher">Morgan Kaufmann</arg><arg name="location">San Francisco, CA</arg><arg name="isbn">1-55860-787-0</arg><arg name="edition">2</arg><arg name="first2">Stefan</arg><arg name="last2">Schlechtweg</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Gooch</arg><arg name="first">Bruce</arg><arg name="title">Non-photorealistic rendering</arg><arg name="year">2001</arg><arg name="publisher">A K Peters</arg><arg name="location">Natick, Mass.</arg><arg name="isbn">1-56881-133-0</arg><arg name="first2">Amy</arg><arg name="last2">Gooch</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Jensen</arg><arg name="first">Henrik Wann</arg><arg name="title">Realistic image synthesis using photon mapping</arg><arg name="year">2001</arg><arg name="publisher">AK Peters</arg><arg name="location">Natick, Mass.</arg><arg name="isbn">1-56881-147-0</arg><arg name="edition">[Nachdr.]</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Blinn</arg><arg name="first">Jim</arg><arg name="title">Jim Blinn's corner : a trip down the graphics pipeline</arg><arg name="year">1996</arg><arg name="publisher">Morgan Kaufmann Publishers</arg><arg name="location">San Francisco, Calif.</arg><arg name="isbn">1-55860-387-5</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Glassner</arg><arg name="first">Andrew S.</arg><arg name="title">Principles of digital image synthesis</arg><arg name="year">2004</arg><arg name="publisher">Kaufmann</arg><arg name="location">San Francisco, Calif.</arg><arg name="isbn">1-55860-276-3</arg><arg name="edition">2</arg><arg name="authorlink">Andrew Glassner</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Cohen</arg><arg name="first">Michael F.</arg><arg name="title">Radiosity and realistic image synthesis</arg><arg name="year">1998</arg><arg name="publisher">Academic Press Professional</arg><arg name="location">Boston, Mass. [u.a.]</arg><arg name="isbn">0-12-178270-0</arg><arg name="edition">3</arg><arg name="first2">John R.</arg><arg name="last2">Wallace</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Foley</arg><arg name="first">James D.</arg><arg name="title">Computer graphics : principles and practice</arg><arg name="year">1990</arg><arg name="publisher">Addison-Wesley</arg><arg name="location">Reading, Mass.</arg><arg name="isbn">0-201-12110-7</arg><arg name="edition">2</arg><arg name="author2">Van Dam<space/></arg><arg name="author3">Feiner<space/></arg><arg name="author4"><space/>Hughes<space/></arg></template></listitem><listitem><template><target>cite book</target><arg name="first"></arg><arg name="title">An introduction to ray tracing</arg><arg name="year">1989</arg><arg name="publisher">Acad. Press</arg><arg name="location">London [u.a.]</arg><arg name="isbn">0-12-286160-4</arg><arg name="edition">3</arg><arg name="editor">Andrew S. Glassner</arg></template></listitem><listitem><template><target>cite journal</target><arg name="url">http://radsite.lbl.gov/radiance/papers/sg94.1/<space/></arg><arg name="title">The RADIANCE Lighting Simulation and Rendering System<space/></arg><arg name="last">Ward<space/></arg><arg name="first">Gregory J.<space/></arg><arg name="work">SIGGRAPH 94<space/></arg><arg name="date">July 1994<space/></arg><arg name="pages">459–72</arg></template></listitem></list><paragraph><template><target>Refend</target></template></paragraph><heading level='2'>External links</heading><paragraph><template><target>Wiktionary</target><arg>renderer</arg></template></paragraph><list type='bullet'><listitem><link type='external' href='http://www.gpurendering.com'>GPU Rendering Magazine</link><space/>Online CGI magazine about advantages of GPU rendering</listitem><listitem><link type='external' href='http://www.siggraph.org/'>SIGGRAPH</link><space/>The ACMs special interest group in graphics &amp;mdash; the largest academic and professional association and conference.</listitem><listitem>http://www.cs.brown.edu/~tor/ List of links to (recent) siggraph papers (and some others) on the web.</listitem></list><preblock><preline></preline></preblock><paragraph><template><target>Visualization</target></template></paragraph><paragraph><template><target>DEFAULTSORT:Rendering (Computer Graphics)</target></template><link><target>Category:3D rendering</target></link></paragraph></article>