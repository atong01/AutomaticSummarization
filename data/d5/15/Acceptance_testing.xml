<article title='Acceptance_testing'><paragraph><template><target>Use mdy dates</target><arg name="date">September 2012</arg></template></paragraph><paragraph><link><target>File:US Navy 090407-N-4669J-042 Sailors assigned to the air department of the aircraft carrier USS George H.W. Bush (CVN 77) test the ship's catapult systems during acceptance trials.jpg</target><part>thumb</part><part>right</part><part>300px</part><part>Acceptance testing of an<space/><link><target>aircraft catapult</target></link></part></link></paragraph><paragraph><link><target>File:James Webb Primary Mirror.jpg</target><part>thumb</part><part>right</part><part>300px</part><part>Six of the primary mirrors of the<space/><link><target>James Webb Space Telescope</target></link><space/>being prepared for acceptance testing</part></link></paragraph><paragraph>In<space/><link><target>engineering</target></link><space/>and its various<space/><link><target>fields of engineering</target><part>subdisciplines</part></link>,<space/><bold>acceptance testing</bold><space/>is a test conducted to determine if the requirements of a<space/><link><target>specification</target></link><space/>or<space/><link><target>contract</target></link><space/>are met. It may involve<space/><link><target>chemical test</target><trail>s</trail></link>,<space/><link><target>physical test</target><trail>s</trail></link>, or<space/><link><target>Performance test (assessment)</target><part>performance test</part><trail>s</trail></link>.</paragraph><paragraph>In<space/><link><target>systems engineering</target></link><space/>it may involve<space/><link><target>black-box testing</target></link><space/>performed on a<space/><link><target>system</target></link><space/>(for example: a piece of<space/><link><target>software system</target><part>software</part></link>, lots of manufactured mechanical parts, or batches of chemical products) prior to its delivery.<extension extension_name='ref'><template><target>cite book</target><arg name="last">Black<space/></arg><arg name="first">Rex<space/></arg><arg name="date">August 2009<space/></arg><arg name="title"><space/>Managing the Testing Process: Practical Tools and Techniques for Managing Hardware and Software Testing<space/></arg><arg name="publisher">Hoboken, NJ: Wiley<space/></arg><arg name="isbn">0-470-40415-9</arg></template></extension></paragraph><paragraph>In<space/><link><target>software testing</target></link><space/>the<space/><link><target>International Software Testing Qualifications Board</target><part>ISTQB</part></link><space/>defines<space/><italics>acceptance</italics><space/>as: formal testing with respect to user needs, requirements, and business processes conducted to determine whether or not a system satisfies the acceptance criteria and to enable the user, customers or other authorized entity to determine whether or not to accept the system.<extension extension_name='ref' name="ISTQB Glossary"><template><target>cite book</target><arg name="publisher">[[International Software Testing Qualifications Board|ISTQB]]</arg><arg name="date">2010</arg><arg name="accessdate">2012-11-22</arg><arg name="title">Standard glossary of terms used in Software Testing, Version 2.1</arg></template></extension><space/>Acceptance testing is also known as<space/><link><target>user acceptance testing</target></link><space/>(UAT), end-user testing,<space/><link><target>operational acceptance testing</target></link><space/>(OAT) or field (acceptance) testing.</paragraph><paragraph>A<space/><link><target>smoke testing (software)</target><part>smoke test</part></link><space/>may be used as an acceptance test prior to introducing a build of software to the main testing process.<template><target>citation needed (lead)</target><arg name="date">September 2015</arg></template></paragraph><heading level='2'>Overview</heading><paragraph>Testing is a set of activities conducted to facilitate discovery and/or evaluation of properties of one or more items under test.<extension extension_name='ref' name="ISO 29119 Part-1"><preblock><preline><template><target>cite book</target><arg name="publisher">[[International Organization for Standardization|ISO]]</arg><arg name="date">2013</arg><arg name="accessdate">2014-10-14</arg><arg name="title">ISO/IEC/IEEE 29119-1-2013 Software and Systems Engineering - Software Testing - Part 1- Concepts and Definitions</arg><arg name="url">http://www.iso.org/iso/home/store/catalogue_tc/catalogue_detail.htm?csnumber</arg></template></preline></preblock></extension><space/>Each individual test, known as a test case, exercises a set of predefined test activities, developed to drive the execution of the test item to meet test objectives; including correct implementation, error identification, quality verification and other valued detail.<extension extension_name='ref' name="ISO 29119 Part-1"></extension><space/>The test environment is usually designed to be identical, or as close as possible, to the anticipated production environment. It includes all facilities, hardware, software, firmware, procedures and/or documentation intended for or used to perform the testing of software.<extension extension_name='ref' name="ISO 29119 Part-1"></extension></paragraph><paragraph>UAT and OAT test cases are ideally derived in collaboration with business customers, business analysts, testers, and developers. It's essential that these tests include both business logic tests as well as operational environment conditions. The business customers (product owners) are the primary<space/><link><target>project stakeholder</target><part>stakeholders</part></link><space/>of these tests. As the test conditions successfully achieve their acceptance criteria, the stakeholders are reassured the development is progressing in the right direction.<extension extension_name='ref' name="ISO 29119 Part-4"><preblock><preline><template><target>cite book</target><arg name="publisher">[[International Organization for Standardization|ISO]]</arg><arg name="date">2013</arg><arg name="accessdate">2014-10-14</arg><arg name="title">ISO/IEC/IEEE DIS 29119-4 Software and Systems Engineering - Software Testing - Part 4- Test Techniques</arg><arg name="url">http://www.iso.org/iso/home/store/catalogue_tc/catalogue_detail.htm?csnumber</arg></template></preline></preblock></extension></paragraph><list type='bullet'><listitem>User acceptance test (UAT) criteria (in<space/><link><target>agile software development</target></link>) are usually created by business customers and expressed in a<space/><link><target>Domain specific language</target><part>business domain language</part></link>. These are high-level tests to verify the completeness of a<space/><link><target>user story</target></link><space/>or stories 'played' during any sprint/iteration.<space/></listitem><listitem>Operational acceptance test (OAT) criteria (regardless if using agile, iterative or sequential development) are defined in terms of functional and non-functional requirements; covering key quality attributes of<space/><link><target>software testing</target><part>functional stability</part></link>,<space/><link><target>portability testing</target><part>portability</part></link><space/>and<space/><link><target>reliability theory</target><part>reliability</part></link>.</listitem></list><heading level='2'>Process</heading><paragraph>The acceptance test suite may need to be performed multiple times, as all of the test cases may not be executed within a single test iteration.<extension extension_name='ref' name="ISO 29119 Part-2"><preblock><preline><template><target>cite book</target><arg name="publisher">[[International Organization for Standardization|ISO]]</arg><arg name="date">2013</arg><arg name="accessdate">2014-05-21</arg><arg name="title">ISO/IEC/IEEE 29119-2-2013 Software and Systems Engineering - Software Testing - Part 2- Test Processes</arg><arg name="url">http://www.iso.org/iso/home/store/catalogue_tc/catalogue_detail.htm?csnumber</arg></template></preline></preblock></extension></paragraph><paragraph>The acceptance test suite is run using predefined acceptance test procedures to direct the testers which data to use, the step-by-step processes to follow and the expected result following execution. The actual results are retained for comparison with the expected results.<extension extension_name='ref' name="ISO 29119 Part-2"></extension><space/>If the actual results match the expected results for each test case, the test case is said to pass. If the quantity of non-passing test cases does not breach the project's predetermined threshold, the test suite is said to pass. If it does, the system may either be rejected or accepted on conditions previously agreed between the sponsor and the manufacturer.</paragraph><paragraph>The anticipated result of a successful test execution:</paragraph><list type='bullet'><listitem>test cases are executed, using predetermined data</listitem><listitem>actual results are recorded</listitem><listitem>actual and expected results are compared, and</listitem><listitem>test results are determined.</listitem></list><paragraph>The objective is to provide confidence that the developed product meets both the functional and non-functional requirements. The purpose of conducting acceptance testing is that once completed, and provided the acceptance criteria are met, it is expected the sponsors will sign-off on the product development/enhancement as satisfying the defined requirements (previously agreed between business and product provider/developer).</paragraph><heading level='2'>User acceptance testing</heading><paragraph>User acceptance testing (UAT) consists of a process of verifying that a solution works for the user.<extension extension_name='ref'><template><target>cite book</target><arg name="last"><space/>Cimperman</arg><arg name="first"><space/>Rob</arg><arg name="title"><space/>UAT Defined: A Guide to Practical User Acceptance Testing</arg><arg name="year"><space/>2006</arg><arg name="publisher"><space/>Pearson Education</arg><arg name="isbn"><space/>9780132702621</arg><arg name="pages">Chapter 2</arg></template></extension><space/>It is not<space/><link><target>system testing</target></link><space/>(ensuring software does not crash and meets documented requirements), but rather ensures that the solution will work for the user i.e. test the user accepts the solution (software vendors often refer to this as &quot;Beta testing&quot;).</paragraph><paragraph>This testing should be undertaken by a<space/><link><target>subject-matter expert</target></link><space/>(SME), preferably the owner or client of the solution under test, and provide a summary of the findings for confirmation to proceed after trial or review. In<space/><link><target>Software development process</target><part>software development</part></link>, UAT as one of the final stages of a project often occurs before a client or customer accepts the new system. Users of the system perform tests in line with what would occur in real-life scenarios.<extension extension_name='ref'><template><target>cite book</target><arg name="last"><space/>Goethem</arg><arg name="first"><space/>Brian Hambling, Pauline van</arg><arg name="title"><space/>User acceptance testing : a step-by-step guide</arg><arg name="year"><space/>2013</arg><arg name="publisher"><space/>BCS Learning & Development Limited</arg><arg name="isbn"><space/>9781780171678</arg></template></extension></paragraph><paragraph>It is important that the materials given to the tester be similar to the materials that the end user will have. Provide testers with real-life scenarios such as the three most common tasks or the three most difficult tasks you expect an average user will undertake.<template><target>Citation needed</target><arg name="date">March 2015</arg></template><space/>Instructions on how to complete the tasks must not be provided.<template><target>Citation needed</target><arg name="date">March 2015</arg></template></paragraph><paragraph>The UAT acts as a final verification of the required business functionality and proper functioning of the system, emulating real-world usage conditions on behalf of the paying client or a specific large customer. If the software works as required and without issues during normal use, one can reasonably extrapolate the same level of stability in production.<extension extension_name='ref'><template><target>cite book</target><arg name="last">Pusuluri</arg><arg name="first">Nageshwar Rao</arg><arg name="title">Software Testing Concepts And Tools</arg><arg name="year">2006</arg><arg name="publisher">Dreamtech Press</arg><arg name="isbn">9788177227123</arg><arg name="page">62</arg></template></extension></paragraph><paragraph>User tests, usually performed by clients or by end-users, do not normally focus on identifying simple problems such as spelling errors or cosmetic problems, nor on<space/><link><target>Software bug</target><part>showstopper</part></link><space/>defects, such as<space/><link><target>crash (computing)</target><part>software crashes</part></link>; testers and developers previously identify and fix these issues during earlier<space/><link><target>unit testing</target></link>,<space/><link><target>integration testing</target></link>, and<space/><link><target>system testing</target></link><space/>phases.</paragraph><paragraph>UAT should be executed against test scenarios.<template><target>Citation needed</target><arg name="date">December 2014</arg></template><space/>Test scenarios usually differ from System or Functional test cases in the sense that they represent a &quot;player&quot; or &quot;user&quot; journey. The broad nature of the test scenario ensures that the focus is on the journey and not on technical or system-specific key presses, staying away from &quot;click-by-click&quot; test steps to allow for a variance in users' steps through systems. Test scenarios can be broken down into logical &quot;days&quot;, which are usually where the actor (player/customer/operator) system (backoffice, front end) changes.<template><target>Citation needed</target><arg name="date">December 2014</arg></template></paragraph><paragraph>In the industrial sector, a common UAT is a factory acceptance test (FAT). This test takes place before installation of the concerned equipment. Most of the time testers not only check if the equipment meets the pre-set specification, but also if the equipment is fully functional. A FAT usually includes a check of completeness, a verification against contractual requirements, a proof of functionality (either by simulation or a conventional function test) and a final inspection.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.tuv.com/en/corporate/business_customers/materials_testing_and_inspection/supply_chain_services/factory_acceptance_test/factory_acceptance_test.jsp<space/></arg><arg name="title">Factory Acceptance Test (FAT)<space/></arg><arg name="publisher">Tuv.com<space/></arg><arg name="date"><space/></arg><arg name="accessdate">September 18, 2012</arg></template></extension><extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.inspection-for-industry.com/factory-acceptance-test.html<space/></arg><arg name="title">Factory Acceptance Test<space/></arg><arg name="publisher">Inspection-for-industry.com<space/></arg><arg name="accessdate">September 18, 2012</arg></template></extension></paragraph><paragraph>The results of these tests give confidence to the client(s) as to how the system will perform in production. There may also be legal or contractual requirements for acceptance of the system.</paragraph><heading level='2'>Operational acceptance testing</heading><paragraph><link><target>Operational Acceptance Testing</target></link><space/>(OAT) is used to conduct operational readiness (pre-release) of a product, service or system as part of a<space/><link><target>quality management system</target></link>. OAT is a common type of non-functional<space/><link><target>software testing</target></link>, used mainly in<space/><link><target>software development</target></link><space/>and<space/><link><target>software maintenance</target></link><space/>projects. This type of testing focuses on the<space/><link><target>operational readiness</target></link><space/>of the system to be supported, and/or to become part of the production environment.<space/></paragraph><heading level='2'>Acceptance testing in extreme programming</heading><paragraph>Acceptance testing is a term used in<space/><link><target>agile software development</target></link><space/>methodologies, particularly<space/><link><target>extreme programming</target></link>, referring to the functional testing of a<space/><link><target>user story</target></link><space/>by the software development team during the implementation phase.<extension extension_name='ref'><template><target>cite web</target><arg name="title">Introduction to Acceptance/Customer Tests as Requirements Artifacts</arg><arg name="url">http://www.agilemodeling.com/artifacts/acceptanceTests.htm</arg><arg name="work">agilemodeling.com</arg><arg name="publisher">Agile Modeling</arg><arg name="accessdate">9 December 2013</arg></template></extension></paragraph><paragraph>The customer specifies scenarios to test when a user story has been correctly implemented. A story can have one or many acceptance tests, whatever it takes to ensure the functionality works. Acceptance tests are<space/><link><target>Black-box testing</target><part>black-box system tests</part></link>. Each acceptance test represents some expected result from the system. Customers are responsible for verifying the correctness of the acceptance tests and reviewing test scores to decide which failed tests are of highest priority. Acceptance tests are also used as regression tests prior to a production release. A user story is not considered complete until it has passed its acceptance tests. This means that new acceptance tests must be created for each iteration or the development team will report zero progress.<extension extension_name='ref'><template><target>cite web</target><arg name="author">Don Wells<space/></arg><arg name="url">http://www.extremeprogramming.org/rules/functionaltests.html<space/></arg><arg name="title">Acceptance Tests<space/></arg><arg name="publisher">Extremeprogramming.org<space/></arg><arg name="date"><space/></arg><arg name="accessdate">September 20, 2011</arg></template></extension></paragraph><paragraph><template><target>Expand section</target><arg name="date">May 2008</arg></template></paragraph><heading level='2'>Types of acceptance testing</heading><paragraph><template><target>unreferenced section</target><arg name="date">March 2015</arg></template>Typical types of acceptance testing include the following</paragraph><list type='def'><listitem><defkey>User acceptance testing</defkey><defval></defval></listitem></list><list type='ident'><listitem>This may include factory acceptance testing, i.e. the testing done by factory users before the product or system is moved to its destination site, after which site acceptance testing may be performed by the users at the site.</listitem></list><list type='def'><listitem><defkey><link><target>Operational acceptance testing</target></link></defkey><defval>Also known as operational readiness testing, this refers to the checking done to a system to ensure that processes and procedures are in place to allow the system to be used and maintained. This may include checks done to back-up facilities, procedures for disaster recovery, training for end users, maintenance procedures, and security procedures.</defval></listitem><listitem><defkey>Contract and regulation acceptance testing</defkey></listitem></list><list type='ident'><listitem>In contract acceptance testing, a system is tested against acceptance criteria as documented in a contract, before the system is accepted. In regulation acceptance testing, a system is tested to ensure it meets governmental, legal and safety standards.</listitem></list><list type='def'><listitem><defkey>Alpha and beta testing</defkey></listitem></list><list type='ident'><listitem>Alpha testing takes place at developers' sites, and involves testing of the operational system by internal staff, before it is released to external customers. Beta testing takes place at customers' sites, and involves testing by a group of customers who use the system at their own locations and provide feedback, before the system is released to other customers. The latter is often called field testing.</listitem></list><heading level='2'>List of acceptance-testing frameworks</heading><paragraph><template><target>unreferenced section</target><arg name="date">March 2015</arg></template></paragraph><list type='bullet'><listitem><link><target>Concordion</target></link>,<space/><link><target>Specification_by_example</target><part>Specification by Example (SbE)</part></link><space/>framework<list type='bullet'><listitem>Concordion.NET, acceptance testing in .NET</listitem></list></listitem><listitem><link><target>Cucumber (software)</target><part>Cucumber</part></link>, a<space/><link><target>behavior-driven development</target></link><space/>(BDD) acceptance test framework<list type='bullet'><listitem>Capybara, Acceptance test framework for Ruby web applications</listitem><listitem>Behat, BDD acceptance framework for PHP</listitem><listitem>Lettuce, BDD acceptance framework for Python</listitem></list></listitem><listitem><link><target>Fabasoft app.test</target></link><space/>for automated acceptance tests</listitem><listitem><link><target>Framework for Integrated Test</target></link><space/>(Fit)<list type='bullet'><listitem><link><target>FitNesse</target></link>, a<space/><link><target>Fork (software development)</target><part>fork</part></link><space/>of Fit</listitem></list></listitem><listitem><link><target>iMacros</target></link></listitem><listitem><link><target>ItsNat</target></link><space/>Java Ajax web framework with built-in, server based, functional web testing capabilities.</listitem><listitem><link><target>Mocha (JavaScript framework)</target><part>Mocha</part></link>, a popular web acceptance test framework based on Javascript and Node.js</listitem><listitem><link><target>Ranorex</target></link></listitem><listitem><link><target>Robot Framework</target></link></listitem><listitem><link><target>Selenium (software)</target><part>Selenium</part></link></listitem><listitem><link><target>Specification by example</target></link><space/>(Specs2)</listitem><listitem><link><target>Watir</target></link></listitem></list><heading level='2'>See also</heading><paragraph><template><target>Portal</target><arg>Software Testing</arg></template></paragraph><list type='bullet'><listitem><link><target>Acceptance sampling</target></link></listitem><listitem><link><target>Black-box testing</target></link></listitem><listitem><link><target>Conference room pilot</target></link></listitem><listitem><link><target>Development stage</target></link></listitem><listitem><link><target>Dynamic testing</target></link></listitem><listitem><link><target>Grey box testing</target></link></listitem><listitem><link><target>Software testing</target></link></listitem><listitem><link><target>System testing</target></link></listitem><listitem><link><target>Test-driven development</target></link></listitem><listitem><link><target>Unit testing</target></link></listitem><listitem><link><target>White box testing</target></link></listitem></list><heading level='2'>References</heading><paragraph><template><target>Reflist</target></template></paragraph><heading level='2'>Further reading</heading><list type='bullet'><listitem><template><target>Cite book</target><arg name="title">User Acceptance Testing: A Step by Step Guide<space/></arg><arg name="publisher">BCS Learning and Development Ltd<space/></arg><arg name="last1"><space/>Hambling<space/></arg><arg name="first1"><space/>Brian<space/></arg><arg name="last2"><space/>van Goethem<space/></arg><arg name="first2"><space/>Pauline<space/></arg><arg name="year">2013<space/></arg><arg name="location">Swindon<space/></arg><arg name="isbn">978-1-78017-167-8<space/></arg></template></listitem></list><heading level='2'>External links</heading><list type='bullet'><listitem><link type='external' href='http://testingguidance.codeplex.com'>Acceptance Test Engineering Guide</link><space/>by<space/><link type='external' href='http://msdn.com/practices'>Microsoft patterns &amp; practices</link></listitem><listitem>Article<space/><link type='external' href='http://www.methodsandtools.com/archive/archive.php?id=23'>Using Customer Tests to Drive Development</link><space/>from<space/><link type='external' href='http://www.methodsandtools.com/'>Methods &amp; Tools</link></listitem><listitem>Article<space/><link type='external' href='http://www.methodsandtools.com/archive/archive.php?id=72'>Acceptance TDD Explained</link><space/>from<space/><link type='external' href='http://www.methodsandtools.com/'>Methods &amp; Tools</link></listitem><listitem>Article<space/><link type='external' href='http://www.softwaretestinghelp.com/successful-user-acceptance-testing/'>User Acceptance Testing Challenges</link><space/>from<space/><link type='external' href='http://www.softwaretestinghelp.com/'>Software Testing Help</link></listitem></list><paragraph><template><target>DEFAULTSORT:Acceptance Testing</target></template></paragraph><paragraph><link><target>Category:Software testing</target></link><link><target>Category:Hardware testing</target></link></paragraph></article>