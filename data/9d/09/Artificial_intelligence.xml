<article title='Artificial_intelligence'><paragraph><template><target>Redirect</target><arg>AI</arg><arg>other uses</arg><arg>Ai (disambiguation){{!}}Ai</arg><arg>and</arg><arg>Artificial intelligence (disambiguation)</arg></template><template><target>pp-pc1</target></template></paragraph><preblock><preline><bold>Artificial intelligence</bold><space/>(<bold>AI</bold>) is the<space/><link><target>intelligence</target></link><space/>exhibited by machines or software. It is also the name of the academic<space/><link><target>field of study</target></link><space/>which studies how to create computers and computer<space/><link><target>software</target></link><space/>that are capable of intelligent behavior. Major AI researchers and textbooks define this field as &quot;the study and design of intelligent agents&quot;,<extension extension_name='ref' name="Definition of AI"></extension><space/>in which an<space/><link><target>intelligent agent</target></link><space/>is a system that perceives its environment and takes actions that maximize its chances of success.<extension extension_name='ref' name="Intelligent agents"></extension><space/><link><target>John McCarthy (computer scientist)</target><part>John McCarthy</part></link>, who coined the term in 1955,<extension extension_name='ref' name="Coining of the term AI"></extension><space/>defines it as &quot;the science and engineering of making intelligent machines&quot;.<extension extension_name='ref' name="McCarthy's definition of AI"></extension></preline></preblock><preblock><preline>AI research is highly technical and specialized, and is deeply divided into subfields that often fail to communicate with each other.<extension extension_name='ref' name="Fragmentation of AI"></extension><space/>Some of the division is due to social and cultural factors: subfields have grown up around particular institutions and the work of individual researchers. AI research is also divided by several technical issues. Some subfields focus on the solution of specific<space/><link><target>#Goals</target><part>problems</part></link>. Others focus on one of several possible<space/><link><target>#Approaches</target><part>approaches</part></link><space/>or on the use of a particular<space/><link><target>#Tools</target><part>tool</part></link><space/>or towards the accomplishment of particular<space/><link><target>#Applications</target><part>applications</part></link>.</preline></preblock><paragraph>The central problems (or goals) of AI research include<space/><link><target>reasoning</target></link>,<space/><link><target>knowledge</target></link>,<space/><link><target>Automated planning and scheduling</target><part>planning</part></link>,<space/><link><target>learning</target></link>,<space/><link><target>natural language processing</target></link><space/>(communication),<space/><link><target>perception</target></link><space/>and the ability to move and manipulate objects.<extension extension_name='ref' name="Problems of AI"></extension><space/><link><target>artificial general intelligence</target><part>General intelligence</part></link><space/>is still among the field's long-term goals.<extension extension_name='ref' name="General intelligence"></extension><space/>Currently popular approaches include<space/><link><target>#Statistical</target><part>statistical methods</part></link>,<space/><link><target>#Sub-symbolic</target><part>computational intelligence</part></link><space/>and<space/><link><target>#Symbolic</target><part>traditional symbolic AI</part></link>. There are a large number of tools used in AI, including versions of<space/><link><target>#Search and optimization</target><part>search and mathematical optimization</part></link>,<space/><link><target>#Logic</target><part>logic</part></link>,<space/><link><target>#Probabilistic methods for uncertain reasoning</target><part>methods based on probability and economics</part></link>, and many others. The AI field is interdisciplinary, in which a number of sciences and professions converge, including<space/><link><target>computer science</target></link>,<space/><link><target>mathematics</target></link>,<space/><link><target>psychology</target></link>,<space/><link><target>linguistics</target></link>,<space/><link><target>philosophy</target></link><space/>and<space/><link><target>neuroscience</target></link>, as well as other specialized fields such as<space/><link><target>artificial psychology</target></link>.</paragraph><preblock><preline>The field was founded on the claim that a central property of humans,<space/><link><target>human intelligence</target></link>the<space/><link><target>sapience</target></link><space/>of<space/><italics><link><target>Homo sapiens</target></link></italics>&quot;can be so precisely described that a machine can be made to simulate it.&quot;<extension extension_name='ref'>See the<space/><link><target>Dartmouth conference</target><part>Dartmouth proposal</part></link>, under<space/><link><target>#Philosophy</target><part>Philosophy</part></link>, below.</extension><space/>This raises philosophical issues about the nature of the<space/><link><target>mind</target></link><space/>and the ethics of creating artificial beings endowed with human-like intelligence, issues which have been addressed by<space/><link><target>History of AI#AI in myth, fiction and speculation</target><part>myth</part></link>,<space/><link><target>artificial intelligence in fiction</target><part>fiction</part></link><space/>and<space/><link><target>philosophy of AI</target><part>philosophy</part></link><space/>since antiquity.<extension extension_name='ref' name="McCorduck's thesis"></extension><space/>Artificial intelligence has been the subject of tremendous optimism<extension extension_name='ref'>The optimism referred to includes the predictions of early AI researchers (see<space/><link><target>History of AI#The optimism</target><part>optimism in the history of AI</part></link>) as well as the ideas of modern<space/><link><target>transhumanism</target><part>transhumanists</part></link><space/>such as<space/><link><target>Ray Kurzweil</target></link>.</extension><space/>but has also suffered stunning<space/><link><target>AI winter</target><part>setbacks</part></link>.<extension extension_name='ref'>The &quot;setbacks&quot; referred to include the<space/><link><target>AI winter#Machine translation and the ALPAC report of 1966</target><part>ALPAC report</part></link><space/>of 1966, the abandonment of<space/><link><target>perceptrons</target></link><space/>in 1970,<space/><link><target>AI winter#The Lighthill report</target><part>the Lighthill Report</part></link><space/>of 1973 and the<space/><link><target>AI winter#The collapse of the Lisp machine market in 1987</target><part>collapse of the Lisp machine market</part></link><space/>in 1987.</extension><space/>Today it has become an essential part of the technology industry, providing the heavy lifting for many of the most challenging problems in computer science.<extension extension_name='ref' name="AI widely used"></extension></preline></preblock><heading level='2'>History</heading><preblock><preline><template><target>Main</target><arg>History of artificial intelligence</arg><arg>Timeline of artificial intelligence</arg></template></preline></preblock><preblock><preline>Thinking machines and artificial beings appear in<space/><link><target>Greek myth</target><trail>s</trail></link>, such as<space/><link><target>Talos</target></link><space/>of<space/><link><target>Crete</target></link>, the bronze robot of<space/><link><target>Hephaestus</target></link>, and<space/><link><target>Pygmalion (mythology)</target><part>Pygmalion's</part></link><space/><link><target>Galatea (mythology)</target><part>Galatea</part></link>.<extension extension_name='ref' name="AI in myth"></extension><space/>Human likenesses believed to have intelligence were built in every major civilization: animated<space/><link><target>cult image</target><trail>s</trail></link><space/>were worshiped in<space/><link><target>Egypt</target></link><space/>and<space/><link><target>Greece</target></link><extension extension_name='ref' name="Cult images as artificial intelligence"></extension><space/>and humanoid<space/><link><target>automaton</target><trail>s</trail></link><space/>were built by<space/><link><target>King Mu of Zhou#Automaton</target><part>Yan Shi</part></link>,<space/><link><target>Hero of Alexandria</target></link><space/>and<space/><link><target>Al-Jazari</target></link>.<extension extension_name='ref' name="Humanoid automata"></extension><space/>It was also widely believed that artificial beings had been created by<space/><link><target>Jbir ibn Hayyn</target></link>,<space/><link><target>Judah Loew</target></link><space/>and<space/><link><target>Paracelsus</target></link>.<extension extension_name='ref' name="Artificial beings"></extension><space/>By the 19th and 20th centuries, artificial beings had become a common feature in fiction, as in<space/><link><target>Mary Shelley</target></link>'s<space/><italics><link><target>Frankenstein</target></link></italics><space/>or<space/><link><target>Karel apek</target></link>'s<space/><italics><link><target>R.U.R. (Rossum's Universal Robots)</target></link></italics>.<extension extension_name='ref' name="AI in early science fiction"></extension><space/><link><target>Pamela McCorduck</target></link><space/>argues that all of these are some examples of an ancient urge, as she describes it, &quot;to forge the gods&quot;.<extension extension_name='ref' name="McCorduck's thesis"></extension><space/>Stories of these creatures and their fates discuss many of the same hopes, fears and<space/><link><target>ethics of artificial intelligence</target><part>ethical concerns</part></link><space/>that are presented by artificial intelligence.</preline></preblock><preblock><preline>Mechanical or<space/><link><target>formal reasoning</target><part>&quot;formal&quot; reasoning</part></link><space/>has been developed by philosophers and mathematicians since antiquity. The study of logic led directly to the invention of the<space/><link><target>computer</target><part>programmable digital electronic computer</part></link>, based on the work of mathematician<space/><link><target>Alan Turing</target></link><space/>and others. Turing's<space/><link><target>theory of computation</target></link><space/>suggested that a machine, by shuffling symbols as simple as &quot;0&quot; and &quot;1&quot;, could simulate any conceivable act of mathematical deduction.<extension extension_name='ref'>This insight, that digital computers can simulate any process of formal reasoning, is known as the<space/><link><target>ChurchTuring thesis</target></link>.</extension><extension extension_name='ref' name="Formal reasoning"></extension><space/>This, along with concurrent discoveries in<space/><link><target>neurology</target></link>,<space/><link><target>information theory</target></link><space/>and<space/><link><target>cybernetic</target><trail>s</trail></link>, inspired a small group of researchers to begin to seriously consider the possibility of building an electronic brain.<extension extension_name='ref' name="AI's immediate precursors"></extension></preline></preblock><preblock><preline>The field of AI research was founded at<space/><link><target>Dartmouth Conferences</target><part>a conference</part></link><space/>on the campus of<space/><link><target>Dartmouth College</target></link><space/>in the summer of 1956.<extension extension_name='ref' name="Dartmouth conference"></extension><space/>The attendees, including<space/><link><target>John McCarthy (computer scientist)</target><part>John McCarthy</part></link>,<space/><link><target>Marvin Minsky</target></link>,<space/><link><target>Allen Newell</target></link>,<space/><link><target>Arthur Samuel</target></link>, and<space/><link><target>Herbert A. Simon</target><part>Herbert Simon</part></link>, became the leaders of AI research for many decades.<extension extension_name='ref' name="Hegemony of the Dartmouth conference attendees"></extension><space/>They and their students wrote programs that were, to most people, simply astonishing:<extension extension_name='ref'>Russell and Norvig write &quot;it was astonishing whenever a computer did anything kind of smartish.&quot;<space/><template><target>Harvnb</target><arg>Russell</arg><arg>Norvig</arg><arg>2003</arg><arg name="p">18</arg></template></extension><space/>computers were winning at checkers, solving word problems in algebra, proving logical theorems and speaking English.<extension extension_name='ref' name="Golden years of AI"></extension><space/>By the middle of the 1960s, research in the U.S. was heavily funded by the<space/><link><target>DARPA</target><part>Department of Defense</part></link><extension extension_name='ref' name="AI funding in the 60s"></extension><space/>and laboratories had been established around the world.<extension extension_name='ref' name="AI in England"></extension><space/>AI's founders were profoundly optimistic about the future of the new field:<space/><link><target>Herbert A. Simon</target><part>Herbert Simon</part></link><space/>predicted that &quot;machines will be capable, within twenty years, of doing any work a man can do&quot; and<space/><link><target>Marvin Minsky</target></link><space/>agreed, writing that &quot;within a generation&amp;nbsp;... the problem of creating 'artificial intelligence' will substantially be solved&quot;.<extension extension_name='ref' name="Optimism of early AI"></extension></preline></preblock><preblock><preline>They had failed to recognize the difficulty of some of the problems they faced.<extension extension_name='ref'>See<space/><template><target>See section</target><arg>History of artificial intelligence</arg><arg>The problems</arg></template></extension><space/>In 1974, in response to the criticism of<space/><link><target>Sir James Lighthill</target></link><template><target>sfn</target><arg>Lighthill</arg><arg>1973</arg></template><space/>and ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off all undirected exploratory research in AI. The next few years would later be called an &quot;<link><target>AI winter</target></link>&quot;,<extension extension_name='ref' name="First AI winter"></extension><space/>a period when funding for AI projects was hard to find.</preline></preblock><preblock><preline>In the early 1980s, AI research was revived by the commercial success of<space/><link><target>expert system</target><trail>s</trail></link>,<extension extension_name='ref' name="Expert systems"></extension><space/>a form of AI program that simulated the knowledge and analytical skills of one or more human experts. By 1985 the market for AI had reached over a billion dollars. At the same time, Japan's<space/><link><target>fifth generation computer</target></link><space/>project inspired the U.S and British governments to restore funding for academic research in the field.<extension extension_name='ref' name="AI in the 80s"></extension><space/>However, beginning with the collapse of the<space/><link><target>Lisp Machine</target></link><space/>market in 1987, AI once again fell into disrepute, and a second, longer lasting<space/><link><target>AI winter</target></link><space/>began.<extension extension_name='ref' name="Second AI winter"></extension></preline></preblock><preblock><preline></preline></preblock><paragraph>In the 1990s and early 21st century, AI achieved its greatest successes, albeit somewhat behind the scenes. Artificial intelligence is used for logistics,<space/><link><target>data mining</target></link>,<space/><link><target>medical diagnosis</target></link><space/>and many other areas throughout the technology industry.<extension extension_name='ref' name="AI widely used"></extension>The success was due to several factors: the increasing computational power of computers (see<space/><link><target>Moore's law</target></link>), a greater emphasis on solving specific subproblems, the creation of new ties between AI and other fields working on similar problems, and a new commitment by researchers to solid mathematical methods and rigorous scientific standards.<extension extension_name='ref' name="Formal methods in AI"></extension></paragraph><preblock><preline>On 11 May 1997,<space/><link><target>IBM Deep Blue</target><part>Deep Blue</part></link><space/>became the first computer chess-playing system to beat a reigning world chess champion,<space/><link><target>Garry Kasparov</target></link>.<extension extension_name='ref'><template><target>Harvnb</target><arg>McCorduck</arg><arg>2004</arg><arg name="pp">480–483</arg></template></extension><space/>In February 2011, in a<space/><italics><link><target>Jeopardy!</target></link></italics><space/><link><target>quiz show</target></link><space/>exhibition match,<space/><link><target>IBM</target></link>'s<space/><link><target>question answering system</target></link>,<space/><link><target>Watson (artificial intelligence software)</target><part>Watson</part></link>, defeated the two greatest Jeopardy champions,<space/><link><target>Brad Rutter</target></link><space/>and<space/><link><target>Ken Jennings</target></link>, by a significant margin.<template><target>sfn</target><arg>Markoff</arg><arg>2011</arg></template><space/>The<space/><link><target>Kinect</target></link>, which provides a 3D bodymotion interface for the<space/><link><target>Xbox 360</target></link><space/>and the Xbox One, uses algorithms that emerged from lengthy AI research<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.i-programmer.info/news/105-artificial-intelligence/2176-kinects-ai-breakthrough-explained.html</arg><arg name="title">Kinect's AI breakthrough explained</arg><arg name="author">Administrator</arg><arg name="work">i-programmer.info</arg></template></extension><space/>as do<space/><link><target>intelligent personal assistant</target><trail>s</trail></link><space/>in<space/><link><target>smartphone</target><trail>s</trail></link>.<extension extension_name='ref'>http://readwrite.com/2013/01/15/virtual-personal-assistants-the-future-of-your-smartphone-infographic</extension></preline></preblock><heading level='2'>Research</heading><heading level='3'>Goals</heading><preblock><preline>The general problem of simulating (or creating) intelligence has been broken down into a number of specific sub-problems. These consist of particular traits or capabilities that researchers would like an intelligent system to display. The traits described below have received the most attention.<extension extension_name='ref' name="Problems of AI"></extension></preline></preblock><heading level='4'>Deduction, reasoning, problem solving</heading><preblock><preline></preline></preblock><paragraph>Early AI researchers developed algorithms that imitated the step-by-step reasoning that humans use when they solve puzzles or make logical deductions.<extension extension_name='ref' name="Reasoning"></extension><space/>By the late 1980s and 1990s, AI research had also developed highly successful methods for dealing with<space/><link><target>uncertainty</target><part>uncertain</part></link><space/>or incomplete information, employing concepts from<space/><link><target>probability</target></link><space/>and economics.<extension extension_name='ref' name="Uncertain reasoning"></extension></paragraph><preblock><preline>For difficult problems, most of these algorithms can require enormous computational resources most experience a &quot;<link><target>combinatorial explosion</target></link>&quot;: the amount of memory or computer time required becomes astronomical when the problem goes beyond a certain size. The search for more efficient problem-solving algorithms is a high priority for AI research.<extension extension_name='ref' name="Intractability"></extension></preline></preblock><paragraph>Human beings solve most of their problems using fast, intuitive judgements rather than the conscious, step-by-step deduction that early AI research was able to model.<extension extension_name='ref' name="Psychological evidence of sub-symbolic reasoning"></extension><space/>AI has made some progress at imitating this kind of &quot;sub-symbolic&quot; problem solving:<space/><link><target>embodied agent</target></link><space/>approaches emphasize the importance of<space/><link><target>Sensory-motor coupling</target><part>sensorimotor</part></link><space/>skills to higher reasoning;<space/><link><target>neural net</target></link><space/>research attempts to simulate the structures inside the brain that give rise to this skill;<space/><link><target>#Statistical</target><part>statistical approaches to AI</part></link><space/>mimic the probabilistic nature of the human ability to guess.</paragraph><heading level='4'>Knowledge representation</heading><preblock><preline><link><target>File:GFO taxonomy tree.png</target><part>right</part><part>thumb</part><part>An ontology represents knowledge as a set of concepts within a domain and the relationships between those concepts.</part></link></preline></preblock><paragraph><template><target>Main</target><arg>Knowledge representation</arg><arg>Commonsense knowledge</arg></template></paragraph><paragraph><link><target>Knowledge representation</target></link><extension extension_name='ref' name="Knowledge representation"></extension><space/>and<space/><link><target>knowledge engineering</target></link><extension extension_name='ref' name="Knowledge engineering"></extension><space/>are central to AI research. Many of the problems machines are expected to solve will require extensive knowledge about the world. Among the things that AI needs to represent are: objects, properties, categories and relations between objects;<extension extension_name='ref' name="Representing categories and relations"></extension><space/>situations, events, states and time;<extension extension_name='ref' name="Representing time"></extension><space/>causes and effects;<extension extension_name='ref' name="Representing causation"></extension><space/>knowledge about knowledge (what we know about what other people know);<extension extension_name='ref' name="Representing knowledge about knowledge"></extension><space/>and many other, less well researched domains. A representation of &quot;what exists&quot; is an<space/><link><target>ontology (computer science)</target><part>ontology</part></link>: the set of objects, relations, concepts and so on that the machine knows about. The most general are called<space/><link><target>upper ontology</target><part>upper ontologies</part></link>, which attempt to provide a foundation for all other knowledge.<extension extension_name='ref' name="Ontology"></extension></paragraph><paragraph>Among the most difficult problems in knowledge representation are:</paragraph><list type='def'><listitem><defkey><link><target>Default reasoning</target></link><space/>and the<space/><link><target>qualification problem</target></link></defkey><defval><space/>Many of the things people know take the form of &quot;working assumptions.&quot; For example, if a bird comes up in conversation, people typically picture an animal that is fist sized, sings, and flies. None of these things are true about all birds.<space/><link><target>John McCarthy (computer scientist)</target><part>John McCarthy</part></link><space/>identified this problem in 1969<extension extension_name='ref' name="Qualification problem"></extension><space/>as the qualification problem: for any commonsense rule that AI researchers care to represent, there tend to be a huge number of exceptions. Almost nothing is simply true or false in the way that abstract logic requires. AI research has explored a number of solutions to this problem.<extension extension_name='ref' name="Default reasoning and non-monotonic logic"></extension></defval></listitem></list><list type='def'><listitem><defkey>The breadth of<space/><link><target>commonsense knowledge</target></link></defkey><defval><space/>The number of atomic facts that the average person knows is astronomical. Research projects that attempt to build a complete knowledge base of<space/><link><target>commonsense knowledge</target></link><space/>(e.g.,<space/><link><target>Cyc</target></link>) require enormous amounts of laborious<space/><link><target>ontology engineering</target><part>ontological engineering</part></link>they must be built, by hand, one complicated concept at a time.<extension extension_name='ref' name="Breadth of commonsense knowledge"></extension><space/>A major goal is to have the computer understand enough concepts to be able to learn by reading from sources like the internet, and thus be able to add to its own ontology.<template><target>Citation needed</target><arg name="date">October 2010</arg></template></defval></listitem></list><list type='def'><listitem><defkey>The subsymbolic form of some<space/><link><target>commonsense knowledge</target></link></defkey><defval><space/>Much of what people know is not represented as &quot;facts&quot; or &quot;statements&quot; that they could express verbally. For example, a chess master will avoid a particular chess position because it &quot;feels too exposed&quot;<extension extension_name='ref'><template><target>Harvnb</target><arg>Dreyfus</arg><arg>Dreyfus</arg><arg>1986</arg></template></extension><space/>or an art critic can take one look at a statue and instantly realize that it is a fake.<extension extension_name='ref'><template><target>Harvnb</target><arg>Gladwell</arg><arg>2005</arg></template></extension><space/>These are intuitions or tendencies that are represented in the brain non-consciously and sub-symbolically.<extension extension_name='ref' name="Intuition"></extension><space/>Knowledge like this informs, supports and provides a context for symbolic, conscious knowledge. As with the related problem of sub-symbolic reasoning, it is hoped that<space/><link><target>situated artificial intelligence</target><part>situated AI</part></link>,<space/><link><target>computational intelligence</target></link>, or<space/><link><target>#Statistical</target><part>statistical AI</part></link><space/>will provide ways to represent this kind of knowledge.<extension extension_name='ref' name="Intuition"></extension></defval></listitem></list><heading level='4'>Planning</heading><preblock><preline><link><target>File:Hierarchical-control-system.svg</target><part>thumb</part><part>A<space/><link><target>hierarchical control system</target></link><space/>is a form of<space/><link><target>control system</target></link><space/>in which a set of devices and governing software is arranged in a hierarchy.</part></link></preline></preblock><paragraph><template><target>Main</target><arg>Automated planning and scheduling</arg></template></paragraph><paragraph>Intelligent agents must be able to set goals and achieve them.<extension extension_name='ref' name="Planning"></extension><space/>They need a way to visualize the future (they must have a representation of the state of the world and be able to make predictions about how their actions will change it) and be able to make choices that maximize the<space/><link><target>utility</target></link><space/>(or &quot;value&quot;) of the available choices.<extension extension_name='ref' name="Information value theory"></extension></paragraph><paragraph>In classical planning problems, the agent can assume that it is the only thing acting on the world and it can be certain what the consequences of its actions may be.<extension extension_name='ref' name="Classical planning"></extension><space/>However, if the agent is not the only actor, it must periodically ascertain whether the world matches its predictions and it must change its plan as this becomes necessary, requiring the agent to reason under uncertainty.<extension extension_name='ref' name="Non-deterministic planning"></extension></paragraph><paragraph><link><target>Multi-agent planning</target></link><space/>uses the<space/><link><target>cooperation</target></link><space/>and competition of many agents to achieve a given goal.<space/><link><target>Emergent behavior</target></link><space/>such as this is used by<space/><link><target>evolutionary algorithms</target></link><space/>and<space/><link><target>swarm intelligence</target></link>.<extension extension_name='ref' name="Multi-agent planning"></extension></paragraph><heading level='4'>Learning</heading><preblock><preline><template><target>Main</target><arg>Machine learning</arg></template></preline></preblock><paragraph>Machine learning is the study of computer algorithms that improve automatically through experience<extension extension_name='ref'>This is a form of<space/><link><target>Tom M. Mitchell</target><part>Tom Mitchell</part></link>'s widely quoted definition of machine learning: &quot;A computer program is set to learn from an experience<space/><italics>E</italics><space/>with respect to some task<space/><italics>T</italics><space/>and some performance measure<space/><italics>P</italics><space/>if its performance on<space/><italics>T</italics><space/>as measured by<space/><italics>P</italics><space/>improves with experience<space/><italics>E</italics>.&quot;</extension><extension extension_name='ref' name="Machine learning"></extension><space/>and has been central to AI research since the field's inception.<extension extension_name='ref'><link><target>Alan Turing</target></link><space/>discussed the centrality of learning as early as 1950, in his classic paper &quot;<link><target>Computing Machinery and Intelligence</target></link>&quot;.<template><target>Harv</target><arg>Turing</arg><arg>1950</arg></template><space/>In 1956, at the original Dartmouth AI summer conference,<space/><link><target>Ray Solomonoff</target></link><space/>wrote a report on unsupervised probabilistic machine learning: &quot;An Inductive Inference Machine&quot;.<template><target>Harv</target><arg>Solomonoff</arg><arg>1956</arg></template></extension></paragraph><paragraph><link><target>Unsupervised learning</target></link><space/>is the ability to find patterns in a stream of input.<space/><link><target>Supervised learning</target></link><space/>includes both<space/><link><target>statistical classification</target><part>classification</part></link><space/>and numerical<space/><link><target>Regression analysis</target><part>regression</part></link>. Classification is used to determine what category something belongs in, after seeing a number of examples of things from several categories. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change. In<space/><link><target>reinforcement learning</target></link><extension extension_name='ref' name="Reinforcement learning"></extension><space/>the agent is rewarded for good responses and punished for bad ones. The agent uses this sequence of rewards and punishments to form a strategy for operating in its problem space. These three types of learning can be analyzed in terms of<space/><link><target>decision theory</target></link>, using concepts like<space/><link><target>utility (economics)</target><part>utility</part></link>. The mathematical analysis of machine learning algorithms and their performance is a branch of<space/><link><target>theoretical computer science</target></link><space/>known as<space/><link><target>computational learning theory</target></link>.<extension extension_name='ref' name="Computational learning theory"></extension></paragraph><paragraph>Within<space/><link><target>developmental robotics</target></link>, developmental learning approaches were elaborated for lifelong cumulative acquisition of repertoires of novel skills by a robot, through autonomous self-exploration and social interaction with human teachers, and using guidance mechanisms such as active learning, maturation, motor synergies, and imitation.<template><target>sfn</target><arg>Weng</arg><arg>McClelland</arg><arg>Pentland</arg><arg>Sporns</arg><arg>2001</arg></template><template><target>sfn</target><arg>Lungarella</arg><arg>Metta</arg><arg>Pfeifer</arg><arg>Sandini</arg><arg>2003</arg></template><template><target>sfn</target><arg>Asada</arg><arg>Hosoda</arg><arg>Kuniyoshi</arg><arg>Ishiguro</arg><arg>2009</arg></template><template><target>sfn</target><arg>Oudeyer</arg><arg>2010</arg></template></paragraph><heading level='4'>Natural language processing (communication)</heading><preblock><preline><link><target>File:ParseTree.svg</target><part>thumb</part><part>A<space/><link><target>parse tree</target></link><space/>represents the<space/><link><target>syntax</target><part>syntactic</part></link><space/>structure of a sentence according to some<space/><link><target>formal grammar</target></link>.</part></link></preline></preblock><paragraph><template><target>Main</target><arg>Natural language processing</arg></template></paragraph><paragraph><link><target>Natural language processing</target></link><extension extension_name='ref' name="Natural language processing"></extension><space/>gives machines the ability to read and<space/><link><target>natural language understanding</target><part>understand</part></link><space/>the languages that humans speak. A sufficiently powerful natural language processing system would enable<space/><link><target>natural language user interface</target><trail>s</trail></link><space/>and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of natural language processing include<space/><link><target>information retrieval</target></link><space/>(or<space/><link><target>text mining</target></link>),<space/><link><target>question answering</target></link><extension extension_name='ref'>&quot;<link type='external' href='https://www.academia.edu/2475776/Versatile_question_answering_systems_seeing_in_synthesis'>Versatile question answering systems: seeing in synthesis</link>&quot;, Mittal et al., IJIIDS, 5(2), 119-142, 2011</extension><space/>and<space/><link><target>machine translation</target></link>.<extension extension_name='ref' name="Applications of natural language processing"></extension></paragraph><paragraph>A common method of processing and extracting meaning from natural language is through semantic indexing. Increases in processing speeds and the drop in the cost of data storage makes indexing large volumes of abstractions of the user's input much more efficient.</paragraph><heading level='4'>Perception</heading><preblock><preline><template><target>Main</target><arg>Machine perception</arg><arg>Computer vision</arg><arg>Speech recognition</arg></template></preline></preblock><paragraph><link><target>Machine perception</target></link><extension extension_name='ref' name="Machine perception"></extension><space/>is the ability to use input from sensors (such as cameras, microphones,<space/><link><target>tactile sensor</target><trail>s</trail></link>, sonar and others more exotic) to deduce aspects of the world.<space/><link><target>Computer vision</target></link><extension extension_name='ref' name="Computer vision"></extension><space/>is the ability to analyze visual input. A few selected subproblems are<space/><link><target>speech recognition</target></link>,<extension extension_name='ref' name="Speech recognition"></extension><space/><link><target>facial recognition system</target><part>facial recognition</part></link><space/>and<space/><link><target>object recognition</target></link>.<extension extension_name='ref' name="Object recognition"></extension></paragraph><heading level='4'>Motion and manipulation</heading><preblock><preline><template><target>Main</target><arg>Robotics</arg></template></preline></preblock><paragraph>The field of<space/><link><target>robotics</target></link><extension extension_name='ref' name="Robotics"></extension><space/>is closely related to AI. Intelligence is required for robots to be able to handle such tasks as object manipulation<extension extension_name='ref' name="Configuration space"></extension><space/>and<space/><link><target>motion planning</target><part>navigation</part></link>, with sub-problems of<space/><link><target>Robot localization</target><part>localization</part></link><space/>(knowing where you are, or finding out where other things are),<space/><link><target>robotic mapping</target><part>mapping</part></link><space/>(learning what is around you, building a map of the environment), and<space/><link><target>motion planning</target></link><space/>(figuring out how to get there) or path planning (going from one point in space to another point, which may involve compliant motion where the robot moves while maintaining physical contact with an object).<template><target>sfn</target><arg>Tecuci</arg><arg>2012</arg></template><extension extension_name='ref' name="Robotic mapping"></extension></paragraph><heading level='4'>Long-term goals</heading><paragraph>Among the long-term goals in the research pertaining to artificial intelligence are: (1) Social intelligence, (2) Creativity, and (3) General intelligence.</paragraph><heading level='5'>Social intelligence</heading><preblock><preline><template><target>Main</target><arg>Affective computing</arg></template></preline></preblock><paragraph><link><target>File:Kismet robot at MIT Museum.jpg</target><part>thumb</part><part><link><target>Kismet (robot)</target><part>Kismet</part></link>, a robot with rudimentary social skills<template><target>sfn</target><arg>''Kismet''</arg></template></part></link></paragraph><paragraph>Affective computing is the study and development of systems and devices that can recognize, interpret, process, and simulate human<space/><link><target>Affect (psychology)</target><part>affects</part></link>.<template><target>sfn</target><arg>Thro</arg><arg>1993</arg></template><template><target>sfn</target><arg>Edelson</arg><arg>1991</arg></template><space/>It is an interdisciplinary field spanning<space/><link><target>computer sciences</target></link>,<space/><link><target>psychology</target></link>, and<space/><link><target>cognitive science</target></link>.<template><target>sfn</target><arg>Tao</arg><arg>Tan</arg><arg>2005</arg></template><space/>While the origins of the field may be traced as far back as to early philosophical inquiries into<space/><link><target>Emotion#The James-Lange Theory</target><part>emotion</part></link>,<template><target>sfn</target><arg>James</arg><arg>1884</arg></template><space/>the more modern branch of computer science originated with<space/><link><target>Rosalind Picard</target></link>'s 1995 paper<template><target>sfn</target><arg>Picard</arg><arg>1995</arg></template><space/>on affective computing.<extension extension_name='ref'><template><target>harvnb</target><arg>Kleine-Cosack</arg><arg>2006</arg></template>: &quot;The introduction of emotion to computer science was done by Pickard (sic) who created the field of affective computing.&quot;</extension><extension extension_name='ref'><template><target>harvnb</target><arg>Diamond</arg><arg>2003</arg></template>: &quot;Rosalind Picard, a genial MIT professor, is the field's godmother; her 1997 book, Affective Computing, triggered an explosion of interest in the emotional side of computers and their users.&quot;</extension><space/>A motivation for the research is the ability to simulate<space/><link><target>empathy</target></link>. The machine should interpret the emotional state of humans and adapt its behaviour to them, giving an appropriate response for those emotions.</paragraph><paragraph>Emotion and social skills<extension extension_name='ref' name="Emotion and affective computing"></extension><space/>play two roles for an intelligent agent. First, it must be able to predict the actions of others, by understanding their motives and emotional states. (This involves elements of<space/><link><target>game theory</target></link>,<space/><link><target>decision theory</target></link>, as well as the ability to model human emotions and the perceptual skills to detect emotions.) Also, in an effort to facilitate<space/><link><target>human-computer interaction</target></link>, an intelligent machine might want to be able to<space/><italics>display</italics><space/>emotionseven if it does not actually experience them itselfin order to appear sensitive to the emotional dynamics of human interaction.</paragraph><heading level='5'>Creativity</heading><preblock><preline><template><target>Main</target><arg>Computational creativity</arg></template></preline></preblock><paragraph>A sub-field of AI addresses<space/><link><target>creativity</target></link><space/>both theoretically (from a philosophical and psychological perspective) and practically (via specific implementations of systems that generate outputs that can be considered creative, or systems that identify and assess creativity). Related areas of computational research are<space/><link><target>Artificial intuition</target></link><space/>and Artificial thinking.</paragraph><heading level='5'>General intelligence</heading><preblock><preline><template><target>Main</target><arg>Artificial general intelligence</arg><arg>AI-complete</arg></template></preline></preblock><paragraph>Many researchers think that their work will eventually be incorporated into a machine with<space/><italics>general</italics><space/>intelligence (known as<space/><link><target>artificial general intelligence</target><part>strong AI</part></link>), combining all the skills above and exceeding human abilities at most or all of them.<extension extension_name='ref' name="General intelligence"></extension><space/>A few believe that<space/><link><target>anthropomorphic</target></link><space/>features like<space/><link><target>artificial consciousness</target></link><space/>or an<space/><link><target>artificial brain</target></link><space/>may be required for such a project.<extension extension_name='ref' name="Artificial consciousness"></extension><extension extension_name='ref' name="Brain simulation"></extension></paragraph><paragraph>Many of the problems above may require general intelligence to be considered solved. For example, even a straightforward, specific task like<space/><link><target>machine translation</target></link><space/>requires that the machine read and write in both languages (<link><target>#Natural language processing</target><part>NLP</part></link>), follow the author's argument (<link><target>#Deduction, reasoning, problem solving</target><part>reason</part></link>), know what is being talked about (<link><target>#Knowledge representation</target><part>knowledge</part></link>), and faithfully reproduce the author's intention (<link><target>#Social intelligence</target><part>social intelligence</part></link>). A problem like<space/><link><target>machine translation</target></link><space/>is considered &quot;<link><target>AI-complete</target></link>&quot;. In order to solve this particular problem, you must solve all the problems.<extension extension_name='ref' name="AI complete"></extension></paragraph><heading level='3'>Approaches</heading><paragraph>There is no established unifying theory or<space/><link><target>paradigm</target></link><space/>that guides AI research. Researchers disagree about many issues.<extension extension_name='ref'><link><target>Nils Nilsson (researcher)</target><part>Nils Nilsson</part></link><space/>writes: &quot;Simply put, there is wide disagreement in the field about what AI is all about&quot;<space/><template><target>Harv</target><arg>Nilsson</arg><arg>1983</arg><arg name="p">10</arg></template>.</extension><space/>A few of the most long standing questions that have remained unanswered are these: should artificial intelligence simulate natural intelligence by studying<space/><link><target>psychology</target></link><space/>or<space/><link><target>neurology</target></link>? Or is human biology as irrelevant to AI research as bird biology is to<space/><link><target>aeronautical engineering</target></link>?<extension extension_name='ref' name="Biological intelligence vs. intelligence in general"></extension>Can intelligent behavior be described using simple, elegant principles (such as<space/><link><target>logic</target></link><space/>or<space/><link><target>optimization (mathematics)</target><part>optimization</part></link>)? Or does it necessarily require solving a large number of completely unrelated problems?<extension extension_name='ref' name="Neats vs. scruffies"></extension>Can intelligence be reproduced using high-level symbols, similar to words and ideas? Or does it require &quot;sub-symbolic&quot; processing?<extension extension_name='ref' name="Symbolic vs. sub-symbolic"></extension>John Haugeland, who coined the term GOFAI (Good Old-Fashioned Artificial Intelligence), also proposed that AI should more properly be referred to as<space/><link><target>synthetic intelligence</target></link>,<template><target>sfn</target><arg>Haugeland</arg><arg>1985</arg><arg name="p">255</arg></template><space/>a term which has since been adopted by some non-GOFAI researchers.<template><target>sfn</target><arg>Law</arg><arg>1994</arg></template><template><target>sfn</target><arg>Bach</arg><arg>2008</arg></template></paragraph><heading level='4'>Cybernetics and brain simulation</heading><paragraph><template><target>Main</target><arg>Cybernetics</arg><arg>Computational neuroscience</arg></template>In the 1940s and 1950s, a number of researchers explored the connection between<space/><link><target>neurology</target></link>,<space/><link><target>information theory</target></link>, and<space/><link><target>cybernetics</target></link>. Some of them built machines that used electronic networks to exhibit rudimentary intelligence, such as<space/><link><target>W. Grey Walter</target></link>'s<space/><link><target>turtle (robot)</target><part>turtles</part></link><space/>and the<space/><link><target>Johns Hopkins Beast</target></link>. Many of these researchers gathered for meetings of the Teleological Society at<space/><link><target>Princeton University</target></link><space/>and the<space/><link><target>Ratio Club</target></link><space/>in England.<extension extension_name='ref' name="AI's immediate precursors"></extension><space/>By 1960, this approach was largely abandoned, although elements of it would be revived in the 1980s.</paragraph><heading level='4'>Symbolic</heading><paragraph><template><target>Main</target><arg>Symbolic AI</arg></template>When access to digital computers became possible in the middle 1950s, AI research began to explore the possibility that human intelligence could be reduced to symbol manipulation. The research was centered in three institutions:<space/><link><target>Carnegie Mellon University</target></link>,<space/><link><target>Stanford</target></link><space/>and<space/><link><target>MIT</target></link>, and each one developed its own style of research.<space/><link><target>John Haugeland</target></link><space/>named these approaches to AI &quot;good old fashioned AI&quot; or &quot;<link><target>GOFAI</target></link>&quot;.<extension extension_name='ref' name="GOFAI"></extension><space/>During the 1960s, symbolic approaches had achieved great success at simulating high-level thinking in small demonstration programs. Approaches based on<space/><link><target>cybernetics</target></link><space/>or<space/><link><target>neural network</target><trail>s</trail></link><space/>were abandoned or pushed into the background.<extension extension_name='ref'>The most dramatic case of sub-symbolic AI being pushed into the background was the devastating critique of<space/><link><target>perceptron</target><trail>s</trail></link><space/>by<space/><link><target>Marvin Minsky</target></link><space/>and<space/><link><target>Seymour Papert</target></link><space/>in 1969. See<space/><link><target>History of AI</target></link>,<space/><link><target>AI winter</target></link>, or<space/><link><target>Frank Rosenblatt</target></link>.</extension>Researchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with<space/><link><target>artificial general intelligence</target></link><space/>and considered this the goal of their field.</paragraph><list type='def'><listitem><defkey>Cognitive simulation</defkey><defval><space/>Economist<space/><link><target>Herbert A. Simon</target><part>Herbert Simon</part></link><space/>and<space/><link><target>Allen Newell</target></link><space/>studied human problem-solving skills and attempted to formalize them, and their work laid the foundations of the field of artificial intelligence, as well as<space/><link><target>cognitive science</target></link>,<space/><link><target>operations research</target></link><space/>and<space/><link><target>management science</target></link>. Their research team used the results of<space/><link><target>psychology</target><part>psychological</part></link><space/>experiments to develop programs that simulated the techniques that people used to solve problems. This tradition, centered at<space/><link><target>Carnegie Mellon University</target></link><space/>would eventually culminate in the development of the<space/><link><target>Soar (cognitive architecture)</target><part>Soar</part></link><space/>architecture in the middle 1980s.<extension extension_name='ref' name="AI at CMU in the 60s"></extension><extension extension_name='ref' name="Soar"></extension></defval></listitem></list><list type='def'><listitem><defkey>Logic-based</defkey><defval><space/>Unlike<space/><link><target>Allen Newell</target><part>Newell</part></link><space/>and<space/><link><target>Herbert A. Simon</target><part>Simon</part></link>,<space/><link><target>John McCarthy (computer scientist)</target><part>John McCarthy</part></link><space/>felt that machines did not need to simulate human thought, but should instead try to find the essence of abstract reasoning and problem solving, regardless of whether people used the same algorithms.<extension extension_name='ref' name="Biological intelligence vs. intelligence in general"></extension><space/>His laboratory at<space/><link><target>Stanford University</target><part>Stanford</part></link><space/>(<link><target>Stanford Artificial Intelligence Laboratory</target><part>SAIL</part></link>) focused on using formal<space/><link><target>logic</target></link><space/>to solve a wide variety of problems, including<space/><link><target>knowledge representation</target></link>,<space/><link><target>automated planning and scheduling</target><part>planning</part></link><space/>and<space/><link><target>machine learning</target><part>learning</part></link>.<extension extension_name='ref' name="AI at Stanford in the 60s"></extension><space/>Logic was also the focus of the work at the<space/><link><target>University of Edinburgh</target></link><space/>and elsewhere in Europe which led to the development of the programming language<space/><link><target>Prolog</target></link><space/>and the science of<space/><link><target>logic programming</target></link>.<extension extension_name='ref' name="AI at Edinburgh and France in the 60s"></extension></defval></listitem></list><list type='def'><listitem><defkey>&quot;Anti-logic&quot; or &quot;scruffy&quot;</defkey><defval><space/>Researchers at<space/><link><target>MIT</target></link><space/>(such as<space/><link><target>Marvin Minsky</target></link><space/>and<space/><link><target>Seymour Papert</target></link>)<extension extension_name='ref' name="AI at MIT in the 60s"></extension><space/>found that solving difficult problems in<space/><link><target>computer vision</target><part>vision</part></link><space/>and<space/><link><target>natural language processing</target></link><space/>required ad-hoc solutions they argued that there was no simple and general principle (like<space/><link><target>logic</target></link>) that would capture all the aspects of intelligent behavior.<space/><link><target>Roger Schank</target></link><space/>described their &quot;anti-logic&quot; approaches as &quot;<link><target>Neats vs. scruffies</target><part>scruffy</part></link>&quot; (as opposed to the &quot;<link><target>neats vs. scruffies</target><part>neat</part></link>&quot; paradigms at<space/><link><target>Carnegie Mellon University</target><part>CMU</part></link><space/>and<space/><link><target>Stanford</target></link>).<extension extension_name='ref' name="Neats vs. scruffies"></extension><space/><link><target>Commonsense knowledge bases</target></link><space/>(such as<space/><link><target>Doug Lenat</target></link>'s<space/><link><target>Cyc</target></link>) are an example of &quot;scruffy&quot; AI, since they must be built by hand, one complicated concept at a time.<extension extension_name='ref' name="Cyc"></extension></defval></listitem></list><list type='def'><listitem><defkey>Knowledge-based</defkey><defval><space/>When computers with large memories became available around 1970, researchers from all three traditions began to build<space/><link><target>knowledge representation</target><part>knowledge</part></link><space/>into AI applications.<extension extension_name='ref' name="Knowledge revolution"></extension><space/>This &quot;knowledge revolution&quot; led to the development and deployment of<space/><link><target>expert system</target><trail>s</trail></link><space/>(introduced by<space/><link><target>Edward Feigenbaum</target></link>), the first truly successful form of AI software.<extension extension_name='ref' name="Expert systems"></extension><space/>The knowledge revolution was also driven by the realization that enormous amounts of knowledge would be required by many simple AI applications.</defval></listitem></list><heading level='4'>Sub-symbolic</heading><paragraph>By the 1980s progress in symbolic AI seemed to stall and many believed that symbolic systems would never be able to imitate all the processes of human cognition, especially<space/><link><target>machine perception</target><part>perception</part></link>,<space/><link><target>robotics</target></link>,<space/><link><target>machine learning</target><part>learning</part></link><space/>and<space/><link><target>pattern recognition</target></link>. A number of researchers began to look into &quot;sub-symbolic&quot; approaches to specific AI problems.<extension extension_name='ref' name="Symbolic vs. sub-symbolic"></extension></paragraph><list type='def'><listitem><defkey>Bottom-up,<space/><link><target>embodied agent</target><part>embodied</part></link>,<space/><link><target>situated</target></link>,<space/><link><target>behavior-based AI</target><part>behavior-based</part></link><space/>or<space/><link><target>nouvelle AI</target></link></defkey><defval><space/>Researchers from the related field of<space/><link><target>robotics</target></link>, such as<space/><link><target>Rodney Brooks</target></link>, rejected symbolic AI and focused on the basic engineering problems that would allow robots to move and survive.<extension extension_name='ref' name="Embodied AI"></extension><space/>Their work revived the non-symbolic viewpoint of the early<space/><link><target>cybernetic</target><trail>s</trail></link><space/>researchers of the 1950s and reintroduced the use of<space/><link><target>control theory</target></link><space/>in AI. This coincided with the development of the<space/><link><target>embodied mind thesis</target></link><space/>in the related field of<space/><link><target>cognitive science</target></link>: the idea that aspects of the body (such as movement, perception and visualization) are required for higher intelligence.</defval></listitem></list><list type='def'><listitem><defkey><link><target>Computational intelligence</target></link><space/>and<space/><link><target>soft computing</target></link></defkey><defval><space/>Interest in<space/><link><target>neural networks</target></link><space/>and &quot;<link><target>connectionism</target></link>&quot; was revived by<space/><link><target>David Rumelhart</target></link><space/>and others in the middle 1980s.<extension extension_name='ref' name="Revival of connectionism"></extension><space/>Neural networks are an example of<space/><link><target>soft computing</target></link><space/>--- they are solutions to problems which cannot be solved with complete logical certainty, and where an approximate solution is often enough. Other soft computing approaches to AI include<space/><link><target>fuzzy system</target><trail>s</trail></link>,<space/><link><target>evolutionary computation</target></link><space/>and many statistical tools. The application of soft computing to AI is studied collectively by the emerging discipline of<space/><link><target>computational intelligence</target></link>.<extension extension_name='ref' name="Computational intelligence"></extension></defval></listitem></list><heading level='4'>Statistical</heading><paragraph>In the 1990s, AI researchers developed sophisticated mathematical tools to solve specific subproblems. These tools are truly<space/><link><target>scientific method</target><part>scientific</part></link>, in the sense that their results are both measurable and verifiable, and they have been responsible for many of AI's recent successes. The shared mathematical language has also permitted a high level of collaboration with more established fields (like<space/><link><target>mathematics</target></link>, economics or<space/><link><target>operations research</target></link>).<space/><link><target>Stuart J. Russell</target><part>Stuart Russell</part></link><space/>and<space/><link><target>Peter Norvig</target></link><space/>describe this movement as nothing less than a &quot;revolution&quot; and &quot;the victory of the<space/><link><target>neats and scruffies</target><part>neats</part></link>.&quot;<extension extension_name='ref' name="Formal methods in AI"></extension><space/>Critics argue that these techniques (with few exceptions<template><target>sfn</target><arg>Hutter</arg><arg>2012</arg></template>) are too focused on particular problems and have failed to address the long-term goal of general intelligence.<template><target>sfn</target><arg>Langley</arg><arg>2011</arg></template><space/>There is an ongoing debate about the relevance and validity of statistical approaches in AI, exemplified in part by exchanges between<space/><link><target>Peter Norvig</target></link><space/>and<space/><link><target>Noam Chomsky</target></link>.<template><target>sfn</target><arg>Katz</arg><arg>2012</arg></template><template><target>sfn</target><arg>Norvig</arg><arg>2012</arg></template></paragraph><heading level='4'>Integrating the approaches</heading><list type='def'><listitem><defkey>Intelligent agent paradigm</defkey><defval><space/>An<space/><link><target>intelligent agent</target></link><space/>is a system that perceives its environment and takes actions which maximize its chances of success. The simplest intelligent agents are programs that solve specific problems. More complicated agents include human beings and organizations of human beings (such as<space/><link><target>firm</target><trail>s</trail></link>). The paradigm gives researchers license to study isolated problems and find solutions that are both verifiable and useful, without agreeing on one single approach. An agent that solves a specific problem can use any approach that works some agents are symbolic and logical, some are sub-symbolic<space/><link><target>neural network</target><trail>s</trail></link><space/>and others may use new approaches. The paradigm also gives researchers a common language to communicate with other fieldssuch as<space/><link><target>decision theory</target></link><space/>and economicsthat also use concepts of abstract agents. The intelligent agent paradigm became widely accepted during the 1990s.<extension extension_name='ref' name="Intelligent agents"></extension></defval></listitem></list><list type='def'><listitem><defkey><link><target>Agent architecture</target><trail>s</trail></link><space/>and<space/><link><target>cognitive architecture</target><trail>s</trail></link></defkey><defval><space/>Researchers have designed systems to build intelligent systems out of interacting<space/><link><target>intelligent agents</target></link><space/>in a<space/><link><target>multi-agent system</target></link>.<extension extension_name='ref' name="Agent architectures"></extension><space/>A system with both symbolic and sub-symbolic components is a<space/><link><target>hybrid intelligent system</target></link>, and the study of such systems is<space/><link><target>artificial intelligence systems integration</target></link>. A<space/><link><target>hierarchical control system</target></link><space/>provides a bridge between sub-symbolic AI at its lowest, reactive levels and traditional symbolic AI at its highest levels, where relaxed time constraints permit planning and world modelling.<extension extension_name='ref' name="Hierarchical control system"></extension><space/><link><target>Rodney Brooks</target></link>'<space/><link><target>subsumption architecture</target></link><space/>was an early proposal for such a hierarchical system.<extension extension_name='ref' name="Subsumption architecture"></extension></defval></listitem></list><preblock><preline></preline></preblock><heading level='3'>Tools</heading><paragraph>In the course of 50 years of research, AI has developed a large number of tools to solve the most difficult problems in<space/><link><target>computer science</target></link>. A few of the most general of these methods are discussed below.</paragraph><heading level='4'>Search and optimization</heading><paragraph><template><target>Main</target><arg>Search algorithm</arg><arg>Mathematical optimization</arg><arg>Evolutionary computation</arg></template></paragraph><paragraph>Many problems in AI can be solved in theory by intelligently searching through many possible solutions:<extension extension_name='ref' name="Search"></extension><space/><link><target>:#Deduction, reasoning, problem solving</target><part>Reasoning</part></link><space/>can be reduced to performing a search. For example, logical proof can be viewed as searching for a path that leads from<space/><link><target>premise</target><trail>s</trail></link><space/>to<space/><link><target>Logical consequence</target><part>conclusions</part></link>, where each step is the application of an<space/><link><target>inference rule</target></link>.<extension extension_name='ref' name="Logic as search"></extension><space/><link><target>Automated planning and scheduling</target><part>Planning</part></link><space/>algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called<space/><link><target>means-ends analysis</target></link>.<extension extension_name='ref' name="Planning as search"></extension><space/><link><target>Robotics</target></link><space/>algorithms for moving limbs and grasping objects use<space/><link><target>local search (optimization)</target><part>local searches</part></link><space/>in<space/><link><target>configuration space</target></link>.<extension extension_name='ref' name="Configuration space"></extension><space/>Many<space/><link><target>machine learning</target><part>learning</part></link><space/>algorithms use search algorithms based on<space/><link><target>optimization (mathematics)</target><part>optimization</part></link>.</paragraph><paragraph>Simple exhaustive searches<extension extension_name='ref' name="Uninformed search"></extension><space/>are rarely sufficient for most real world problems: the<space/><link><target>search algorithm</target><part>search space</part></link><space/>(the number of places to search) quickly grows to<space/><link><target>Large numbers#Astronomically large numbers</target><part>astronomical numbers</part></link>. The result is a search that is<space/><link><target>Computation time</target><part>too slow</part></link><space/>or never completes. The solution, for many problems, is to use &quot;<link><target>heuristics</target></link>&quot; or &quot;rules of thumb&quot; that eliminate choices that are unlikely to lead to the goal (called &quot;<link><target>pruning (algorithm)</target><part>pruning</part></link><space/>the<space/><link><target>search tree</target></link>&quot;).<space/><link><target>Heuristics</target></link><space/>supply the program with a &quot;best guess&quot; for the path on which the solution lies.<extension extension_name='ref' name="Informed search"></extension><space/>Heuristics limit the search for solutions into a smaller sample size.<template><target>sfn</target><arg>Tecuci</arg><arg>2012</arg></template></paragraph><paragraph>A very different kind of search came to prominence in the 1990s, based on the mathematical theory of<space/><link><target>optimization (mathematics)</target><part>optimization</part></link>. For many problems, it is possible to begin the search with some form of a guess and then refine the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind<space/><link><target>hill climbing</target></link>: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. Other optimization algorithms are<space/><link><target>simulated annealing</target></link>,<space/><link><target>beam search</target></link><space/>and<space/><link><target>random optimization</target></link>.<extension extension_name='ref' name="Optimization search"></extension></paragraph><paragraph><link><target>Evolutionary computation</target></link><space/>uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine,<space/><link><target>natural selection</target><part>selecting</part></link><space/>only the fittest to survive each generation (refining the guesses). Forms of<space/><link><target>evolutionary computation</target></link><space/>include<space/><link><target>swarm intelligence</target></link><space/>algorithms (such as<space/><link><target>ant colony optimization</target><part>ant colony</part></link><space/>or<space/><link><target>particle swarm optimization</target></link>)<extension extension_name='ref' name="Society based learning"></extension><space/>and<space/><link><target>evolutionary algorithms</target></link><space/>(such as<space/><link><target>genetic algorithms</target></link>,<space/><link><target>gene expression programming</target></link>, and<space/><link><target>genetic programming</target></link>).<extension extension_name='ref' name="Genetic programming"></extension></paragraph><heading level='4'>Logic</heading><paragraph><template><target>Main</target><arg>Logic programming</arg><arg>Automated reasoning</arg></template></paragraph><paragraph><link><target>Logic</target></link><extension extension_name='ref' name="Logic"></extension><space/>is used for knowledge representation and problem solving, but it can be applied to other problems as well. For example, the<space/><link><target>satplan</target></link><space/>algorithm uses logic for<space/><link><target>automated planning and scheduling</target><part>planning</part></link><extension extension_name='ref' name="Satplan"></extension><space/>and<space/><link><target>inductive logic programming</target></link><space/>is a method for<space/><link><target>machine learning</target><part>learning</part></link>.<extension extension_name='ref' name="Symbolic learning techniques"></extension></paragraph><paragraph>Several different forms of logic are used in AI research.<space/><link><target>Propositional logic</target><part>Propositional</part></link><space/>or<space/><link><target>sentential logic</target></link><extension extension_name='ref' name="Propositional logic"></extension><space/>is the logic of statements which can be true or false.<space/><link><target>First-order logic</target></link><extension extension_name='ref' name="First-order logic"></extension><space/>also allows the use of<space/><link><target>quantifier (logic)</target><part>quantifiers</part></link><space/>and<space/><link><target>predicate (mathematical logic)</target><part>predicates</part></link>, and can express facts about objects, their properties, and their relations with each other.<space/><link><target>Fuzzy logic</target></link>,<extension extension_name='ref' name="Fuzzy logic"></extension><space/>is a version of first-order logic which allows the truth of a statement to be represented as a value between 0 and 1, rather than simply True (1) or False (0).<space/><link><target>Fuzzy system</target><trail>s</trail></link><space/>can be used for uncertain reasoning and have been widely used in modern industrial and consumer<space/><link><target>Pattern recognition</target><part>product control systems</part></link>.<space/><link><target>Subjective logic</target></link><extension extension_name='ref' name="Subjective logic"></extension><space/>models uncertainty in a different and more explicit manner than fuzzy-logic: a given binomial opinion satisfies belief + disbelief + uncertainty = 1 within a<space/><link><target>Beta distribution</target></link>. By this method, ignorance can be distinguished from probabilistic statements that an agent makes with high confidence.</paragraph><paragraph><link><target>Default logic</target><trail>s</trail></link>,<space/><link><target>non-monotonic logic</target><trail>s</trail></link><space/>and<space/><link><target>circumscription (logic)</target><part>circumscription</part></link><extension extension_name='ref' name="Default reasoning and non-monotonic logic"></extension><space/>are forms of logic designed to help with default reasoning and the<space/><link><target>qualification problem</target></link>. Several extensions of logic have been designed to handle specific domains of<space/><link><target>knowledge representation</target><part>knowledge</part></link>, such as:<space/><link><target>description logic</target><trail>s</trail></link>;<extension extension_name='ref' name="Representing categories and relations"></extension><space/><link><target>situation calculus</target></link>,<space/><link><target>event calculus</target></link><space/>and<space/><link><target>fluent calculus</target></link><space/>(for representing events and time);<extension extension_name='ref' name="Representing time"></extension><space/><link><target>Causality#Causal calculus</target><part>causal calculus</part></link>;<extension extension_name='ref' name="Representing causation"></extension><space/>belief calculus; and<space/><link><target>modal logic</target><trail>s</trail></link>.<extension extension_name='ref' name="Representing knowledge about knowledge"></extension></paragraph><heading level='4'>Probabilistic methods for uncertain reasoning</heading><paragraph><template><target>Main</target><arg>Bayesian network</arg><arg>Hidden Markov model</arg><arg>Kalman filter</arg><arg>Decision theory</arg><arg>Utility theory</arg></template></paragraph><paragraph>Many problems in AI (in reasoning, planning, learning, perception and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of powerful tools to solve these problems using methods from<space/><link><target>probability</target></link><space/>theory and economics.<extension extension_name='ref' name="Stochastic methods for uncertain reasoning"></extension></paragraph><paragraph><link><target>Bayesian network</target><trail>s</trail></link><extension extension_name='ref' name="Bayesian networks"></extension><space/>are a very general tool that can be used for a large number of problems: reasoning (using the<space/><link><target>Bayesian inference</target></link><space/>algorithm),<extension extension_name='ref' name="Bayesian inference"></extension><space/><link><target>Machine learning</target><part>learning</part></link><space/>(using the<space/><link><target>expectation-maximization algorithm</target></link>),<extension extension_name='ref' name="Bayesian learning"></extension><space/><link><target>Automated planning and scheduling</target><part>planning</part></link><space/>(using<space/><link><target>decision network</target><trail>s</trail></link>)<extension extension_name='ref' name="Bayesian decision networks"></extension><space/>and<space/><link><target>machine perception</target><part>perception</part></link><space/>(using<space/><link><target>dynamic Bayesian network</target><trail>s</trail></link>).<extension extension_name='ref' name="Stochastic temporal models"></extension><space/>Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping<space/><link><target>machine perception</target><part>perception</part></link><space/>systems to analyze processes that occur over time (e.g.,<space/><link><target>hidden Markov model</target><trail>s</trail></link><space/>or<space/><link><target>Kalman filter</target><trail>s</trail></link>).<extension extension_name='ref' name="Stochastic temporal models"></extension></paragraph><paragraph>A key concept from the science of economics is &quot;<link><target>utility</target></link>&quot;: a measure of how valuable something is to an intelligent agent. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using<space/><link><target>decision theory</target></link>,<space/><link><target>decision analysis</target></link>,<extension extension_name='ref' name="Decisions theory and analysis"></extension><space/>and<space/><link><target>applied information economics</target><part>information value theory</part></link>.<extension extension_name='ref' name="Information value theory"></extension><space/>These tools include models such as<space/><link><target>Markov decision process</target><trail>es</trail></link>,<extension extension_name='ref' name="Markov decision process"></extension><space/>dynamic<space/><link><target>decision network</target><trail>s</trail></link>,<extension extension_name='ref' name="Stochastic temporal models"></extension><space/><link><target>game theory</target></link><space/>and<space/><link><target>mechanism design</target></link>.<extension extension_name='ref' name="Game theory and mechanism design"></extension></paragraph><heading level='4'>Classifiers and statistical learning methods</heading><paragraph><template><target>Main</target><arg>Classifier (mathematics)</arg><arg>Statistical classification</arg><arg>Machine learning</arg></template></paragraph><paragraph>The simplest AI applications can be divided into two types: classifiers (&quot;if shiny then diamond&quot;) and controllers (&quot;if shiny then pick up&quot;). Controllers do, however, also classify conditions before inferring actions, and therefore classification forms a central part of many AI systems.<space/><link><target>Classifier (mathematics)</target><part>Classifiers</part></link><space/>are functions that use<space/><link><target>pattern matching</target></link><space/>to determine a closest match. They can be tuned according to examples, making them very attractive for use in AI. These examples are known as observations or patterns. In supervised learning, each pattern belongs to a certain predefined class. A class can be seen as a decision that has to be made. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.<extension extension_name='ref' name="Classifiers"></extension></paragraph><paragraph>A classifier can be trained in various ways; there are many statistical and<space/><link><target>machine learning</target></link><space/>approaches. The most widely used classifiers are the<space/><link><target>Artificial neural network</target><part>neural network</part></link>,<extension extension_name='ref' name="Neural networks"></extension><link><target>kernel methods</target></link><space/>such as the<space/><link><target>support vector machine</target></link>,<extension extension_name='ref' name="Kernel methods"></extension><link><target>k-nearest neighbor algorithm</target></link>,<extension extension_name='ref' name="K-nearest neighbor algorithm"></extension><link><target>Gaussian mixture model</target></link>,<extension extension_name='ref' name="Gaussian mixture model"></extension><link><target>naive Bayes classifier</target></link>,<extension extension_name='ref' name="Naive Bayes classifier"></extension>and<space/><link><target>decision tree learning</target><part>decision tree</part></link>.<extension extension_name='ref' name="Decision tree"></extension>The performance of these classifiers have been compared over a wide range of tasks. Classifier performance depends greatly on the characteristics of the data to be classified. There is no single classifier that works best on all given problems; this is also referred to as the &quot;<link><target>No free lunch in search and optimization</target><part>no free lunch</part></link>&quot; theorem. Determining a suitable classifier for a given problem is still more an art than science.<extension extension_name='ref' name="Classifier performance"></extension></paragraph><heading level='4'>Neural networks</heading><paragraph><template><target>Main</target><arg>Artificial neural network</arg><arg>Connectionism</arg></template><link><target>File:Artificial neural network.svg</target><part>thumb</part><part>A neural network is an interconnected group of nodes, akin to the vast network of<space/><link><target>neuron</target><trail>s</trail></link><space/>in the<space/><link><target>human brain</target></link>.</part></link></paragraph><paragraph>The study of<space/><link><target>artificial neural network</target><trail>s</trail></link><extension extension_name='ref' name="Neural networks"></extension><space/>began in the decade before the field of AI research was founded, in the work of<space/><link><target>Walter Pitts</target></link><space/>and<space/><link><target>Warren McCullough</target></link>. Other important early researchers were<space/><link><target>Frank Rosenblatt</target></link>, who invented the<space/><link><target>perceptron</target></link><space/>and<space/><link><target>Paul Werbos</target></link><space/>who developed the<space/><link><target>backpropagation</target></link><space/>algorithm.<extension extension_name='ref' name="Backpropagation"></extension></paragraph><paragraph>The main categories of networks are acyclic or<space/><link><target>feedforward neural network</target><trail>s</trail></link><space/>(where the signal passes in only one direction) and<space/><link><target>recurrent neural network</target><trail>s</trail></link><space/>(which allow feedback). Among the most popular feedforward networks are<space/><link><target>perceptron</target><trail>s</trail></link>,<space/><link><target>multi-layer perceptron</target><trail>s</trail></link><space/>and<space/><link><target>radial basis network</target><trail>s</trail></link>.<extension extension_name='ref' name="Feedforward neural networks"></extension><space/>Among recurrent networks, the most famous is the<space/><link><target>Hopfield net</target></link>, a form of attractor network, which was first described by<space/><link><target>John Hopfield</target></link><space/>in 1982.<extension extension_name='ref' name="Recurrent neural networks"></extension><space/>Neural networks can be applied to the problem of<space/><link><target>intelligent control</target></link><space/>(for robotics) or<space/><link><target>machine learning</target><part>learning</part></link>, using such techniques as<space/><link><target>Hebbian learning</target></link><space/>and<space/><link><target>competitive learning</target></link>.<extension extension_name='ref' name="Learning in neural networks"></extension></paragraph><paragraph><link><target>Hierarchical temporal memory</target></link><space/>is an approach that models some of the structural and algorithmic properties of the<space/><link><target>neocortex</target></link>.<extension extension_name='ref' name="Hierarchical temporal memory"></extension><space/>The term &quot;<link><target>deep learning</target></link>&quot; gained traction in the mid-2000s after a publication by<space/><link><target>Geoffrey Hinton</target></link><space/>and Ruslan Salakhutdinov showed how a many-layered<space/><link><target>feedforward neural network</target></link><space/>could be effectively pre-trained one layer at a time, treating each layer in turn as an<space/><link><target>unsupervised learning</target><part>unsupervised</part></link><space/><link><target>restricted Boltzmann machine</target></link>, then using<space/><link><target>supervised learning</target><part>supervised</part></link><space/><link><target>backpropagation</target></link><space/>for fine-tuning.<template><target>sfn</target><arg>Hinton</arg><arg>2007</arg></template></paragraph><heading level='4'>Control theory</heading><paragraph><template><target>Main</target><arg>Intelligent control</arg></template><link><target>Control theory</target></link>, the grandchild of<space/><link><target>cybernetics</target></link>, has many important applications, especially in<space/><link><target>robotics</target></link>.<extension extension_name='ref' name="Control theory"></extension></paragraph><heading level='4'>Languages</heading><paragraph><template><target>Main</target><arg>List of programming languages for artificial intelligence</arg></template></paragraph><preblock><preline>AI researchers have developed several specialized languages for AI research, including<space/><link><target>Lisp programming language</target><part>Lisp</part></link><extension extension_name='ref' name="Lisp"></extension><space/>and<space/><link><target>Prolog</target></link>.<extension extension_name='ref' name="Prolog"></extension></preline></preblock><heading level='3'>Evaluating progress</heading><paragraph><template><target>Main</target><arg>Progress in artificial intelligence</arg></template>In 1950, Alan Turing proposed a general procedure to test the intelligence of an agent now known as the<space/><link><target>Turing test</target></link>. This procedure allows almost all the major problems of artificial intelligence to be tested. However, it is a very difficult challenge and at present all agents fail.<extension extension_name='ref' name="Turing test"></extension></paragraph><paragraph>Artificial intelligence can also be evaluated on specific problems such as small problems in chemistry, hand-writing recognition and game-playing. Such tests have been termed<space/><link><target>subject matter expert Turing test</target><trail>s</trail></link>. Smaller problems provide more achievable goals and there are an ever-increasing number of positive results.<extension extension_name='ref' name="Subject matter expert Turing test"></extension></paragraph><paragraph>One classification for outcomes of an AI test is:<template><target>sfn</target><arg>Rajani</arg><arg>2011</arg></template></paragraph><list type='numbered'><listitem>Optimal: it is not possible to perform better.</listitem><listitem>Strong super-human: performs better than all humans.</listitem><listitem>Super-human: performs better than most humans.</listitem><listitem>Sub-human: performs worse than most humans.</listitem></list><paragraph>For example, performance at<space/><link><target>draughts</target></link><space/>(i.e. checkers) is optimal,<extension extension_name='ref' name="Game AI"></extension><space/>performance at chess is super-human and nearing strong super-human (see<space/><link><target>Computer chess#Computers versus humans</target><part>computer chess:&amp;nbsp;computers versus human</part></link>) and performance at many everyday tasks (such as recognizing a face or crossing a room without bumping into something) is sub-human.</paragraph><paragraph>A quite different approach measures machine intelligence through tests which are developed from<space/><italics>mathematical</italics><space/>definitions of intelligence. Examples of these kinds of tests start in the late nineties devising intelligence tests using notions from<space/><link><target>Kolmogorov complexity</target></link><space/>and<space/><link><target>data compression</target></link>.<extension extension_name='ref' name="Mathematical definitions of intelligence"></extension><space/>Two major advantages of mathematical definitions are their applicability to nonhuman intelligences and their absence of a requirement for human testers.</paragraph><paragraph>A derivative of the Turing test is the Completely Automated Public Turing test to tell Computers and Humans Apart (<link><target>CAPTCHA</target></link>). as the name implies, this helps to determine that a user is an actual person and not a computer posing as a human. In contrast to the standard Turing test, CAPTCHA administered by a machine and targeted to a human as opposed to being administered by a human and targeted to a machine. A computer asks a user to complete a simple test then generates a grade for that test. Computers are unable to solve the problem, so correct solutions are deemed to be the result of a person taking the test. A common type of CAPTCHA is the test that requires the typing of distorted letters, numbers or symbols that appear in an image undecipherable by a computer.<template><target>sfn</target><arg>O'Brien</arg><arg>Marakas</arg><arg>2011</arg></template></paragraph><heading level='2'>Applications</heading><paragraph><link><target>File:Automated online assistant.png</target><part>thumb</part><part>An<space/><link><target>automated online assistant</target></link><space/>providing customer service on a web page one of many very primitive applications of artificial intelligence.</part></link><template><target>expand section</target><arg name="talksection">Todo: Applications</arg><arg name="date">January 2011</arg></template><template><target>Main</target><arg>Applications of artificial intelligence</arg></template></paragraph><paragraph>Artificial intelligence techniques are pervasive and are too numerous to list. Frequently, when a technique reaches mainstream use, it is no longer considered artificial intelligence; this phenomenon is described as the<space/><link><target>AI effect</target></link>.<template><target>sfn</target><arg>''CNN''</arg><arg>2006</arg></template><space/>An area that artificial intelligence has contributed greatly to is<space/><link><target>Intrusion detection system</target><part>intrusion detection</part></link>.<extension extension_name='ref' name="Intrusion detection"></extension></paragraph><heading level='3'>Competitions and prizes</heading><paragraph><template><target>Main</target><arg>Competitions and prizes in artificial intelligence</arg></template>There are a number of competitions and prizes to promote research in artificial intelligence. The main areas promoted are: general machine intelligence, conversational behavior, data-mining,<space/><link><target>autonomous car</target><part>robotic cars</part></link>, robot soccer and games.</paragraph><heading level='3'>Platforms</heading><paragraph>A<space/><link><target>platform (computing)</target><part>platform</part></link><space/>(or &quot;<link><target>computing platform</target></link>&quot;) is defined as &quot;some sort of hardware architecture or software framework (including application frameworks), that allows software to run.&quot; As Rodney Brooks pointed out many years ago,<template><target>sfn</target><arg>Brooks</arg><arg>1991</arg></template><space/>it is not just the artificial intelligence software that defines the AI features of the platform, but rather the actual platform itself that affects the AI that results, i.e., there needs to be work in AI problems on real-world platforms rather than in isolation.</paragraph><paragraph>A wide variety of platforms has allowed different aspects of AI to develop, ranging from<space/><link><target>expert systems</target></link>, albeit<space/><link><target>Personal Computer</target><part>PC</part></link>-based but still an entire real-world system, to various robot platforms such as the widely available<space/><link><target>Roomba</target></link><space/>with open interface.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://hackingroomba.com/?s</arg><arg name="title">Hacking Roomba</arg><arg name="work">hackingroomba.com</arg></template></extension></paragraph><heading level='3'>Toys</heading><paragraph><link><target>AIBO</target></link>, the first robotic pet, grew out of Sony's Computer Science Laboratory (CSL). Famed engineer Toshitada Doi is credited as AIBO's original progenitor: in 1994 he had started work on robots with artificial intelligence expert Masahiro Fujita, at CSL. Doi's friend, the artist Hajime Sorayama, was enlisted to create the initial designs for the AIBO's body. Those designs are now part of the permanent collections of Museum of Modern Art and the Smithsonian Institution, with later versions of AIBO being used in studies in Carnegie Mellon University. In 2006, AIBO was added into Carnegie Mellon University's &quot;Robot Hall of Fame&quot;.</paragraph><heading level='2'>Philosophy and ethics</heading><paragraph><template><target>Main</target><arg>Philosophy of artificial intelligence</arg><arg>Ethics of artificial intelligence</arg></template>There are three philosophical questions related to AI:</paragraph><list type='numbered'><listitem>Is<space/><link><target>artificial general intelligence</target></link><space/>possible? Can a machine solve any problem that a human being can solve using intelligence? Or are there hard limits to what a machine can accomplish?</listitem><listitem>Are intelligent machines dangerous? How can we ensure that machines behave ethically and that they are used ethically?</listitem><listitem>Can a machine have a<space/><link><target>mind</target></link>,<space/><link><target>consciousness</target></link><space/>and<space/><link><target>philosophy of mind</target><part>mental states</part></link><space/>in exactly the same sense that human beings do? Can a machine be<space/><link><target>sentient</target></link>, and thus deserve certain rights? Can a machine<space/><link><target>intention</target><trail>ally</trail></link><space/>cause harm?</listitem></list><heading level='3'>The limits of artificial general intelligence</heading><paragraph><template><target>Main</target><arg>philosophy of AI</arg><arg>Turing test</arg><arg>Physical symbol systems hypothesis</arg><arg>Dreyfus' critique of AI</arg><arg>The Emperor's New Mind</arg><arg>AI effect</arg></template></paragraph><paragraph>Can a machine be intelligent? Can it &quot;think&quot;?</paragraph><list type='def'><listitem><defkey><italics><link><target>Computing Machinery and Intelligence</target><part>Turing's &quot;polite convention&quot;</part></link></italics></defkey><defval><space/>We need not decide if a machine can &quot;think&quot;; we need only decide if a machine can act as intelligently as a human being. This approach to the philosophical problems associated with artificial intelligence forms the basis of the<space/><link><target>Turing test</target></link>.<extension extension_name='ref' name="Turing test"></extension></defval></listitem></list><list type='def'><listitem><defkey><italics>The<space/><link><target>Dartmouth Conferences</target><part>Dartmouth proposal</part></link></italics></defkey><defval><space/>&quot;Every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it.&quot; This conjecture was printed in the proposal for the<space/><link><target>Dartmouth Conferences</target><part>Dartmouth Conference</part></link><space/>of 1956, and represents the position of most working AI researchers.<extension extension_name='ref' name="Dartmouth proposal"></extension></defval></listitem></list><list type='def'><listitem><defkey><italics><link><target>Physical symbol system</target><part>Newell and Simon's physical symbol system hypothesis</part></link></italics></defkey><defval><space/>&quot;A physical symbol system has the necessary and sufficient means of general intelligent action.&quot; Newell and Simon argue that intelligence consists of formal operations on symbols.<extension extension_name='ref' name="Physical symbol system hypothesis"></extension><space/><link><target>Hubert Dreyfus</target></link><space/>argued that, on the contrary, human expertise depends on unconscious instinct rather than conscious symbol manipulation and on having a &quot;feel&quot; for the situation rather than explicit symbolic knowledge. (See<space/><link><target>Dreyfus' critique of AI</target></link>.)<extension extension_name='ref'>Dreyfus criticized the<space/><link><target>necessary and sufficient</target><part>necessary</part></link><space/>condition of the<space/><link><target>physical symbol system</target></link><space/>hypothesis, which he called the &quot;psychological assumption&quot;: &quot;The mind can be viewed as a device operating on bits of information according to formal rules&quot;.<space/><template><target>Harv</target><arg>Dreyfus</arg><arg>1992</arg><arg name="p">156</arg></template></extension><extension extension_name='ref' name="Dreyfus' critique"></extension></defval></listitem></list><list type='def'><listitem><defkey><italics>Gdelian arguments</italics></defkey><defval><space/><link><target>Gdel</target></link><space/>himself,<extension extension_name='ref' name="Gdel himself"></extension><space/><link><target>John Lucas (philosopher)</target><part>John Lucas</part></link><space/>(in 1961) and<space/><link><target>Roger Penrose</target></link><space/>(in a more detailed argument from 1989 onwards) argued that humans are not reducible to Turing machines.<extension extension_name='ref' name="The mathematical objection"></extension><space/>The detailed arguments are complex, but in essence they derive from<space/><link><target>Kurt Gdel</target></link>'s 1931 proof in his<space/><link><target>Gdel's first incompleteness theorem</target><part>first incompleteness theorem</part></link><space/>that it is always possible to create<space/><link><target>statement (logic)</target><part>statement</part><trail>s</trail></link><space/>that a<space/><link><target>formal system</target></link><space/>could not prove. A human being, however, can (with some thought) see the truth of these &quot;Gdel statements&quot;. Any Turing program designed to search for these statements can have its methods reduced to a formal system, and so will always have a &quot;Gdel statement&quot; derivable from its program which it can never discover. However, if humans are indeed capable of understanding mathematical truth, it doesn't seem possible that we could be limited in the same way. This is quite a general result, if accepted, since it can be shown that hardware neural nets, and computers based on random processes (e.g. annealing approaches) and quantum computers based on entangled qubits (so long as they involve no new physics) can all be reduced to Turing machines. All they do is reduce the complexity of the tasks, not permit new types of problems to be solved. Roger Penrose speculates that there may be new physics involved in our brain, perhaps at the intersection of gravity and quantum mechanics at the<space/><link><target>Planck scale</target></link>. This argument, if accepted does not rule out the possibility of true artificial intelligence, but means it has to be biological in basis or based on new physical principles. The argument has been followed up by many counter arguments, and then Roger Penrose has replied to those with counter counter examples, and it is now an intricate complex debate.<extension extension_name='ref'><link type='external' href='http://www.calculemus.org/MathUniversalis/NS/10/01penrose.html'>Beyond the Doubting of a Shadow, A Reply to Commentaries on Shadows of the Mind</link>, Roger Penrose 1996 The links to the original articles he responds to there are easily found in the Wayback machine:<space/><link type='external' href='http://web.archive.org/web/20090415202652/http://psyche.cs.monash.edu.au/v2/psyche-2-08-baars.html'>Can Physics Provide a Theory of Consciousness?</link><space/>Barnard J. Bars,<space/><link type='external' href='http://web.archive.org/web/20090912183204/http://psyche.cs.monash.edu.au/v2/psyche-2-07-feferman.html'>Penrose's Gdelian Argument</link><space/>etc.</extension><space/>For details see<space/><link><target>Philosophy of artificial intelligence#Lucas, Penrose and Gdel</target><part>Philosophy of artificial intelligence: Lucas, Penrose and Gdel</part></link></defval></listitem></list><list type='def'><listitem><defkey><italics>The<space/><link><target>artificial brain</target></link><space/>argument</italics></defkey><defval><space/>The brain can be simulated by machines and because brains are intelligent, simulated brains must also be intelligent; thus machines can be intelligent.<space/><link><target>Hans Moravec</target></link>,<space/><link><target>Ray Kurzweil</target></link><space/>and others have argued that it is technologically feasible to copy the brain directly into hardware and software, and that such a simulation will be essentially identical to the original.<extension extension_name='ref' name="Brain simulation"></extension></defval></listitem></list><list type='def'><listitem><defkey><italics>The<space/><link><target>AI effect</target></link></italics></defkey><defval><space/>Machines are<space/><italics>already</italics><space/>intelligent, but observers have failed to recognize it. When<space/><link><target>Deep Blue (chess computer)</target><part>Deep Blue</part></link><space/>beat<space/><link><target>Gary Kasparov</target></link><space/>in chess, the machine was acting intelligently. However, onlookers commonly discount the behavior of an artificial intelligence program by arguing that it is not &quot;real&quot; intelligence after all; thus &quot;real&quot; intelligence is whatever intelligent behavior people can do that machines still can not. This is known as the AI Effect: &quot;AI is whatever hasn't been done yet.&quot;</defval></listitem></list><heading level='3'>Intelligent behaviour and machine ethics</heading><paragraph>As a minimum, an AI system must be able to reproduce aspects of human intelligence. This raises the issue of how ethically the machine should behave towards both humans and other AI agents. This issue was addressed by Wendell Wallach in his book titled<space/><italics>Moral Machines</italics><space/>in which he introduced the concept of<space/><link><target>Moral agency#Artificial moral agents</target><part>artificial moral agents</part></link><space/>(AMA).<extension extension_name='ref'>Wendell Wallach (2010).<space/><italics>Moral Machines</italics>, Oxford University Press.</extension><space/>For Wallach, AMAs have become a part of the research landscape of artificial intelligence as guided by its two central questions which he identifies as &quot;Does Humanity Want Computers Making Moral Decisions&quot;<extension extension_name='ref'>Wallach, pp 3754.</extension><space/>and &quot;Can (Ro)bots Really Be Moral&quot;.<extension extension_name='ref'>Wallach, pp 5573.</extension><space/>For Wallach the question is not centered on the issue of<space/><italics>whether</italics><space/>machines can demonstrate the equivalent of moral behavior in contrast to the<space/><italics>constraints</italics><space/>which society may place on the development of AMAs.<extension extension_name='ref'>Wallach, Introduction chapter.</extension></paragraph><heading level='4'>Machine ethics</heading><paragraph><template><target>Main</target><arg>Machine ethics</arg></template>The field of machine ethics is concerned with giving machines ethical principles, or a procedure for discovering a way to resolve the ethical dilemmas they might encounter, enabling them to function in an ethically responsible manner through their own ethical decision making.<extension extension_name='ref' name="autogenerated1">Michael Anderson and Susan Leigh Anderson (2011), Machine Ethics, Cambridge University Press.</extension><space/>The field was delineated in the AAAI Fall 2005 Symposium on Machine Ethics: &quot;Past research concerning the relationship between technology and ethics has largely focused on responsible and irresponsible use of technology by human beings, with a few people being interested in how human beings ought to treat machines. In all cases, only human beings have engaged in ethical reasoning. The time has come for adding an ethical dimension to at least some machines. Recognition of the ethical ramifications of behavior involving machines, as well as recent and potential developments in machine autonomy, necessitate this. In contrast to computer hacking, software property issues, privacy issues and other topics normally ascribed to computer ethics, machine ethics is concerned with the behavior of machines towards human users and other machines. Research in machine ethics is key to alleviating concerns with autonomous systems it could be argued that the notion of autonomous machines without such a dimension is at the root of all fear concerning machine intelligence. Further, investigation of machine ethics could enable the discovery of problems with current ethical theories, advancing our thinking about Ethics.&quot;<extension extension_name='ref' name="autogenerated2"><template><target>cite web</target><arg name="url">http://www.aaai.org/Library/Symposia/Fall/fs05-06</arg><arg name="title">Machine Ethics</arg><arg name="work">aaai.org</arg></template></extension><space/>Machine ethics is sometimes referred to as machine morality, computational ethics or computational morality. A variety of perspectives of this nascent field can be found in the collected edition &quot;Machine Ethics&quot;<space/><extension extension_name='ref' name="autogenerated1"></extension><space/>that stems from the AAAI Fall 2005 Symposium on Machine Ethics.<extension extension_name='ref' name="autogenerated2"></extension></paragraph><heading level='4'>Malevolent and friendly AI</heading><paragraph><template><target>Main</target><arg>Friendly AI</arg></template>Political scientist<space/><link><target>Charles T. Rubin</target></link><space/>believes that AI can be neither designed nor guaranteed to be benevolent.<extension extension_name='ref'><template><target>cite journal</target><arg name="last">Rubin</arg><arg name="first">Charles</arg><arg name="authorlink">Charles T. Rubin</arg><arg name="date">Spring 2003</arg><arg name="title">Artificial Intelligence and Human Nature</arg><arg name="journal">The New Atlantis</arg><arg name="volume">1</arg><arg name="pages">88–100</arg><arg name="url">http://www.thenewatlantis.com/publications/artificial-intelligence-and-human-nature</arg></template></extension><space/>He argues that &quot;any sufficiently advanced benevolence may be indistinguishable from malevolence.&quot; Humans should not assume machines or robots would treat us favorably, because there is no<space/><italics>a priori</italics><space/>reason to believe that they would be sympathetic to our system of morality, which has evolved along with our particular biology (which AIs would not share). Hyper-intelligent software may not necessarily decide to support the continued existence of mankind, and would be extremely difficult to stop. This topic has also recently begun to be discussed in academic publications as a real source of risks to civilization, humans, and planet Earth.</paragraph><paragraph>Physicist<space/><link><target>Stephen Hawking</target></link>,<space/><link><target>Microsoft</target></link><space/>founder<space/><link><target>Bill Gates</target></link><space/>and<space/><link><target>SpaceX</target></link><space/>founder<space/><link><target>Elon Musk</target></link><space/>have expressed concerns about the possibility that AI could evolve to the point that humans could not control it, with Hawking theorizing that this could &quot;<link><target>Global catastrophic risk</target><part>spell the end of the human race</part></link>&quot;.<extension extension_name='ref'><template><target>cite web</target><arg name="last1">Rawlinson</arg><arg name="first1">Kevin</arg><arg name="title">Microsoft's Bill Gates insists AI is a threat</arg><arg name="url">http://www.bbc.co.uk/news/31047780</arg><arg name="publisher">BBC News</arg><arg name="accessdate">30 January 2015</arg></template></extension></paragraph><paragraph>One proposal to deal with this is to ensure that the first generally intelligent AI is '<link><target>Friendly AI</target></link>', and will then be able to control subsequently developed AIs. Some question whether this kind of check could really remain in place.</paragraph><paragraph>Leading AI researcher<space/><link><target>Rodney Brooks</target></link><space/>writes, &quot;I think it is a mistake to be worrying about us developing malevolent AI anytime in the next few hundred years. I think the worry stems from a fundamental error in not distinguishing the difference between the very real recent advances in a particular aspect of AI, and the enormity and complexity of building sentient volitional intelligence.&quot;<extension extension_name='ref'><template><target>cite web</target><arg name="last">Brooks</arg><arg name="first">Rodney</arg><arg name="title">artificial intelligence is a tool, not a threat</arg><arg name="date">10 November 2014</arg><arg name="url">http://www.rethinkrobotics.com/artificial-intelligence-tool-threat/</arg></template></extension></paragraph><heading level='4'>Devaluation of humanity</heading><paragraph><template><target>Main</target><arg>Computer Power and Human Reason</arg></template><link><target>Joseph Weizenbaum</target></link><space/>wrote that AI applications can not, by definition, successfully simulate genuine human empathy and that the use of AI technology in fields such as<space/><link><target>customer service</target></link><space/>or<space/><link><target>psychotherapy</target></link><extension extension_name='ref'>In the early 1970s,<space/><link><target>Kenneth Colby</target></link><space/>presented a version of Weizenbaum's<space/><link><target>ELIZA</target></link><space/>known as DOCTOR which he promoted as a serious therapeutic tool.<space/><template><target>Harv</target><arg>Crevier</arg><arg>1993</arg><arg name="pp">132–144</arg></template></extension><space/>was deeply misguided. Weizenbaum was also bothered that AI researchers (and some philosophers) were willing to view the human mind as nothing more than a computer program (a position now known as<space/><link><target>computationalism</target></link>). To Weizenbaum these points suggest that AI research devalues human life.<extension extension_name='ref' name="Weizenbaum's critique"></extension></paragraph><heading level='4'>Decrease in demand for human labor</heading><paragraph>Martin Ford, author of<space/><italics>The Lights in the Tunnel: Automation, Accelerating Technology and the Economy of the Future</italics>,<extension extension_name='ref' name="Ford2009Lights"><template><target>Ford 2009 The lights in the tunnel</target></template></extension><space/>and others argue that specialized artificial intelligence applications, robotics and other forms of automation will ultimately result in significant unemployment as machines begin to match and exceed the capability of workers to perform most routine and repetitive jobs. Ford predicts that many knowledge-based occupationsand in particular entry level jobswill be increasingly susceptible to automation via expert systems, machine learning<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://econfuture.wordpress.com/2011/04/14/machine-learning-a-job-killer/</arg><arg name="title">Machine Learning: A job killer?</arg><arg name="work">econfuture - Robots, AI and Unemployment - Future Economics and Technology</arg></template></extension><space/>and other AI-enhanced applications. AI-based applications may also be used to amplify the capabilities of low-wage offshore workers, making it more feasible to<space/><link><target>outsource</target></link><space/><link><target>knowledge worker</target><part>knowledge work</part></link>.<extension extension_name='ref' name="Replaced by machines"></extension></paragraph><heading level='3'>Machine consciousness, sentience and mind</heading><paragraph><template><target>Main</target><arg>Artificial consciousness</arg></template>If an AI system replicates all key aspects of human intelligence, will that system also be<space/><link><target>sentient</target></link><space/>will it have a<space/><link><target>mind</target></link><space/>which has<space/><link><target>consciousness</target><part>conscious experiences</part></link>? This question is closely related to the philosophical problem as to the nature of human consciousness, generally referred to as the<space/><link><target>hard problem of consciousness</target></link>.</paragraph><heading level='4'>Consciousness</heading><paragraph><template><target>Main</target><arg>Hard problem of consciousness</arg><arg>Theory of mind</arg></template>There are no objective criteria for knowing whether an intelligent agent is sentient&amp;nbsp; that it has conscious experiences. We assume that other people do because we do and they tell us that they do, but this is only a subjective determination. The lack of any hard criteria is known as the &quot;hard problem&quot; in the theory of consciousness. The problem applies not only to other people but to the higher animals and, by extension, to AI agents.</paragraph><heading level='4'>Computationalism</heading><paragraph><template><target>Main</target><arg>Computationalism</arg><arg>Functionalism (philosophy of mind)</arg></template>Are human intelligence,<space/><link><target>consciousness</target></link><space/>and<space/><link><target>mind</target></link><space/>products of<space/><link><target>information processing</target></link>? Is the brain essentially a computer?</paragraph><paragraph>Computationalism is the idea that &quot;the human mind or the human brain (or both) is an information processing system and that thinking is a form of computing&quot;. AI, or implementing machines with human intelligence was founded on the claim that &quot;a central property of humans, intelligence can be so precisely described that a machine can be made to simulate it&quot;. A program can then be derived from this human computer and implemented into an artificial one to create efficient artificial intelligence. This program would act upon a set of outputs that result from set inputs of the internal memory of the computer, that is, the machine can only act with what it has implemented in it to start with. A long term goal for AI researchers is to provide machines with a deep understanding of the many abilities of a human being to replicate a general intelligence or STRONG AI, defined as a machine surpassing human abilities to perform the skills implanted in it, a scary thought to many, who fear losing control of such a powerful machine. Obstacles for researchers are mainly time contstraints. That is, AI scientists cannot establish much of a database for commonsense knowledge because it must be ontologically crafted into the machine which takes up a tremendous amount of time. To combat this, AI research looks to have the machine able to understand enough concepts in order to add to its own ontology, but how can it do this when machine ethics is primarily concerned with behavior of machines towards humans or other machines, limiting the extent of developing AI. In order to function like a common human AI must also display, &quot;the ability to solve subsymbolic commonsense knowledge tasks such as how artists can tell statues are fake or how chess masters dont move certain spots to avoid exposure,&quot; but by developing machines who can do it all AI research is faced with the difficulty of potentially putting a lot of people out of work, while on the economy side of things businesses would boom from efficiency, thus forcing AI into a bottleneck trying to developing self improving machines.</paragraph><heading level='4'>Strong AI hypothesis</heading><paragraph><template><target>Main</target><arg>Chinese room</arg></template><link><target>Strong AI hypothesis</target><part>Searle's strong AI hypothesis</part></link><space/>states that &quot;The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.&quot;<extension extension_name='ref' name="Searle's strong AI"></extension><space/>John Searle counters this assertion with his<space/><link><target>Chinese room</target></link><space/>argument, which asks us to look<space/><italics>inside</italics><space/>the computer and try to find where the &quot;mind&quot; might be.<extension extension_name='ref' name="Chinese room"></extension></paragraph><heading level='4'>Robot rights</heading><paragraph><template><target>Main</target><arg>Robot rights</arg></template><link><target>Mary Shelley</target></link>'s<space/><italics><link><target>Frankenstein</target></link></italics><space/>considers a key issue in the<space/><link><target>ethics of artificial intelligence</target></link>: if a machine can be created that has intelligence, could it also<space/><italics><link><target>sentience</target><part>feel</part></link></italics>? If it can feel, does it have the same rights as a human? The idea also appears in modern science fiction, such as the film<space/><italics><link><target>A.I.: Artificial Intelligence</target></link></italics>, in which humanoid machines have the ability to feel emotions. This issue, now known as &quot;<link><target>robot rights</target></link>&quot;, is currently being considered by, for example, California's<space/><link><target>Institute for the Future</target></link>, although many critics believe that the discussion is premature.<extension extension_name='ref' name="Robot rights"></extension><space/>The subject is profoundly discussed in the 2010 documentary film<space/><italics><link><target>Plug &amp; Pray</target></link></italics>.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.plugandpray-film.de/en/content.html</arg><arg name="title">Content: Plug & Pray Film - Artificial Intelligence - Robots -<space/></arg><arg name="author">maschafilm</arg><arg name="work">plugandpray-film.de</arg></template></extension></paragraph><heading level='3'>Superintelligence</heading><paragraph><template><target>Main</target><arg>Superintelligence</arg></template>Are there limits to how intelligent machines&amp;nbsp; or human-machine hybrids&amp;nbsp; can be? A superintelligence, hyperintelligence, or superhuman intelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. Superintelligence may also refer to the form or degree of intelligence possessed by such an agent.</paragraph><heading level='4'>Technological singularity</heading><paragraph><template><target>Main</target><arg>Technological singularity</arg><arg>Moore's law</arg></template>If research into<space/><link><target>artificial general intelligence</target><part>Strong AI</part></link><space/>produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to<space/><link><target>recursive self-improvement</target></link>.<extension extension_name='ref' name="recurse"></extension><space/>The new intelligence could thus increase exponentially and dramatically surpass humans. Science fiction writer<space/><link><target>Vernor Vinge</target></link><space/>named this scenario &quot;<link><target>technological singularity</target><part>singularity</part></link>&quot;.<extension extension_name='ref' name="Singularity"></extension><space/>Technological singularity is when accelerating progress in technologies will cause a runaway effect wherein artificial intelligence will exceed human intellectual capacity and control, thus radically changing or even ending civilization. Because the capabilities of such an intelligence may be impossible to comprehend, the technological singularity is an occurrence beyond which events are unpredictable or even unfathomable.<extension extension_name='ref' name="Singularity"></extension></paragraph><paragraph><link><target>Ray Kurzweil</target></link><space/>has used<space/><link><target>Moore's law</target></link><space/>(which describes the relentless exponential improvement in digital technology) to calculate that<space/><link><target>desktop computer</target><trail>s</trail></link><space/>will have the same processing power as human brains by the year 2029, and predicts that the singularity will occur in 2045.<extension extension_name='ref' name="Singularity"></extension></paragraph><heading level='4'>Transhumanism</heading><paragraph><template><target>Main</target><arg>Transhumanism</arg></template><template><target>quote</target><arg>You awake one morning to find your brain has another lobe functioning. Invisible, this auxiliary lobe answers your questions with information beyond the realm of your own memory, suggests plausible courses of action, and asks questions that help bring out relevant facts. You quickly come to rely on the new lobe so much that you stop wondering how it works. You just use it. This is the dream of artificial intelligence.</arg><arg name="''[[BYTE]]'', April 1985<ref name">"lemmon198504">{{cite news | url</arg></template>Robot designer<space/><link><target>Hans Moravec</target></link>, cyberneticist<space/><link><target>Kevin Warwick</target></link><space/>and inventor<space/><link><target>Ray Kurzweil</target></link><space/>have predicted that humans and machines will merge in the future into<space/><link><target>cyborg</target><trail>s</trail></link><space/>that are more capable and powerful than either.<extension extension_name='ref' name="Transhumanism"></extension><space/>This idea, called<space/><link><target>transhumanism</target></link>, which has roots in<space/><link><target>Aldous Huxley</target></link><space/>and<space/><link><target>Robert Ettinger</target></link>, has been illustrated in fiction as well, for example in the<space/><link><target>manga</target></link><space/><italics><link><target>Ghost in the Shell</target></link></italics><space/>and the science-fiction series<space/><italics><link><target>Dune (novel)</target><part>Dune</part></link></italics>.</paragraph><paragraph>In the 1980s artist<space/><link><target>Hajime Sorayama</target></link>'s Sexy Robots series were painted and published in Japan depicting the actual organic human form with lifelike muscular metallic skins and later &quot;the Gynoids&quot; book followed that was used by or influenced movie makers including<space/><link><target>George Lucas</target></link><space/>and other creatives. Sorayama never considered these organic robots to be real part of nature but always unnatural product of the human mind, a fantasy existing in the mind even when realized in actual form.</paragraph><paragraph><link><target>Edward Fredkin</target></link><space/>argues that &quot;artificial intelligence is the next stage in evolution&quot;, an idea first proposed by<space/><link><target>Samuel Butler (novelist)</target><part>Samuel Butler</part></link>'s &quot;<link><target>Darwin among the Machines</target></link>&quot; (1863), and expanded upon by<space/><link><target>George Dyson (science historian)</target><part>George Dyson</part></link><space/>in his book of the same name in 1998.<extension extension_name='ref' name="AI as evolution"></extension></paragraph><heading level='3'>Existential Risk</heading><paragraph><extension extension_name='blockquote'>&quot;The development of full artificial intelligence could spell the end of the human race.&quot; -Stephen Hawking<extension extension_name='ref'><template><target>Cite web</target><arg name="title"><space/>Stephen Hawking warns artificial intelligence could end mankind - BBC News</arg><arg name="url"><space/>http://www.bbc.com/news/technology-30290540</arg><arg name="website"><space/>BBC News</arg><arg name="accessdate"><space/>2015-10-30</arg><arg name="language"><space/>en-GB</arg></template></extension></extension>A common concern about the development of artificial intelligence is the potential threat it could pose to mankind, possibly to its very existence. The issue has come to gain popular attention, especially in light of concerns expressed by individuals such as<space/><link><target>Stephen Hawking</target></link>,<space/><link><target>Bill Gates</target></link>,<extension extension_name='ref' name="Holley"><template><target>Cite news</target><arg name="title"><space/>Bill Gates on dangers of artificial intelligence: ‘I don’t understand why some people are not concerned’</arg><arg name="url"><space/>https://www.washingtonpost.com/news/the-switch/wp/2015/01/28/bill-gates-on-dangers-of-artificial-intelligence-dont-understand-why-some-people-are-not-concerned/</arg><arg name="newspaper"><space/>The Washington Post</arg><arg name="date"><space/>2015-01-28</arg><arg name="access-date"><space/>2015-10-30</arg><arg name="issn"><space/>0190-8286</arg><arg name="language"><space/>en-US</arg><arg name="first"><space/>Peter</arg><arg name="last"><space/>Holley</arg></template></extension><space/>and<space/><link><target>Elon Musk</target></link>.<extension extension_name='ref'><template><target>Cite web</target><arg name="title"><space/>Elon Musk: artificial intelligence is our biggest existential threat</arg><arg name="url"><space/>http://www.theguardian.com/technology/2014/oct/27/elon-musk-artificial-intelligence-ai-biggest-existential-threat</arg><arg name="website"><space/>the Guardian</arg><arg name="accessdate"><space/>2015-10-30</arg><arg name="first"><space/>Samuel</arg><arg name="last"><space/>Gibbs</arg></template></extension></paragraph><paragraph>In his book,<space/><link><target>Superintelligence: Paths, Dangers, Strategies</target><part>Superintelligence</part></link>,<space/><link><target>Nick Bostrom</target></link><space/>provides a detailed argument for the threat Artificial Intelligence may prove to mankind. He states that there are a series of phases as to how an AI system can achieve world dominance. The Pre-Criticality Phase entails the creation of the seed AI. The seed AI is dependent from human intervening and can improve its own intelligence until it reaches phase two, the Recursive Self-Improvement Phase. In this phase, the AI becomes better at designing itself than the human programmers are capable of - surpassing human intelligence itself. In phase two, the AI could develop such superpowers such as (1) intelligence amplification (2) strategizing (3) social manipulation and (4) hacking. After a phase two, the AI could reach the Covert Preparation Phase, where it uses its new skills of strategizing to achieve more long term goals. It may begin to mask their abilities. Thus, the AI reaches a final phase 4, the Overt Implementation Phase which is when the AI might strike and cause threat, eliminating the human species and any opposition humans may have set forth to prepare. A possibility of the destruction that could ensue would be major<space/><link><target>habitat destruction</target></link>. A major aspect of an AI being a threat to mankind stems from its magnitude of capability to destroy compared to other agents with possibly different goals.</paragraph><paragraph>An AI's capacity for malevolence would be dependent upon a capacity to match human intelligence and evolve and develop intelligence of its own. A Seattle AI system has been made intelligent enough to answer the average 11th grade SAT questions. This would exhibit the potential for the AI to possess a degree of human-level intelligence, a prerequisite for its ability to evolve and potentially take over mankind.<extension extension_name='ref'><template><target>Cite news</target><arg name="title"><space/>Software Is Smart Enough for SAT, but Still Far From Intelligent</arg><arg name="url"><space/>http://www.nytimes.com/2015/09/21/technology/personaltech/software-is-smart-enough-for-sat-but-still-far-from-intelligent.html</arg><arg name="newspaper"><space/>The New York Times</arg><arg name="date"><space/>2015-09-20</arg><arg name="access-date"><space/>2015-10-30</arg><arg name="issn"><space/>0362-4331</arg><arg name="first"><space/>John</arg><arg name="last"><space/>Markoff</arg></template></extension></paragraph><paragraph>However, for AIs to pose a threat, AIs must be superintelligent, meaning they have to surpass the intelligence of modern humans. While many people in the technological and scientific world, such as Bostrom, find this threat very plausible, much scientific evidence proves otherwise. Current AIs have neither the capacity to surpass our intelligence nor the ability to come together and find the initiative to undermine mankind. In order to exceed human intelligence, computers would first have to achieve human intelligence a feat which would be very difficult. For a computer to mimic on the human brain, its processors would need to be based on neurons, which are extremely intricate and variable. Modeling a computer after another computer is simple the processes simply must be copied. The human brain, however, cannot simply be copied, and any slight error or miscalculation would result in a wildly inaccurate product.</paragraph><paragraph>No matter how advanced a machine is, it cannot rely on itself, or another machine, for repairs and assistance. Humanity, therefore, is necessary for the preservation of artificial intelligence. A supercomputer that extinguished humanity would be extinguishing itself. Such a computer, with above-human intelligence, would undoubtedly realize this, and keep humanity alive to ensure the perpetuation of its kind. Some argue that other machines could be built to aid these computers, but those machines in turn would need repairs. The creation of self-service machines is impossible for the foreseeable future, making it impossible for artificial intelligence to exist without humanity.<extension extension_name='ref'><template><target>Cite web</target><arg name="title"><space/>Will artificial intelligence destroy humanity? Here are 5 reasons not to worry.</arg><arg name="url"><space/>http://www.vox.com/2014/8/22/6043635/5-reasons-we-shouldnt-worry-about-super-intelligent-computers-taking</arg><arg name="website"><space/>Vox</arg><arg name="accessdate"><space/>2015-10-30</arg></template></extension></paragraph><paragraph>The belief in the rise of Artificial Intelligence heightened during the mid-twentieth century. The rate at which technological advances were being made lead to the assumption of the possibility of man being able to create intelligence that could rival his own. But after decades of research, a notable example,<space/><link><target>Herbert A. Simon</target><part>Simon</part></link><space/>and<space/><link><target>Allen Newell</target><part>Newell</part></link><extension extension_name='nowiki'></extension>s<space/><link><target>General Problem Solver</target></link>, the only intelligence computers have been able to display is that of logical or mathematical problem solving, puzzles and theorems and pattern recognition. At this, AI has proven to be very effective. However, complex real-world problems remain well beyond the grasp of computers.<extension extension_name='ref'><template><target>Cite web</target><arg name="title"><space/>Is artificial intelligence really an existential threat to humanity?</arg><arg name="url"><space/>http://thebulletin.org/artificial-intelligence-really-existential-threat-humanity8577</arg><arg name="website"><space/>Bulletin of the Atomic Scientists</arg><arg name="accessdate"><space/>2015-10-30</arg></template></extension><space/>Humans themselves have been unable to solve these issues and so cannot program something to do the same. They cannot provide it with the instructions it must follow or even delineate the goals it must achieve. Technology as it now exists can only work with what it is given. Superintelligence is certainly impossible if something lacks the capacity to do more than perform computations and store and organize information.</paragraph><paragraph>Development of militarized artificial intelligence is a cause for concern. Currently 50 countries are in the process of researching and developing battlefield robots. Among them are major powers such as the United States, China, Russia, and the United Kingdom. The Google-owned company Boston Dynamics has already created Atlas, a 6 foot tall humanoid robot capable of moving across rugged terrain.<extension extension_name='ref'><template><target>Cite web</target><arg name="title"><space/>Stephen Hawking, Elon Musk, and Bill Gates Warn About Artificial Intelligence</arg><arg name="url"><space/>http://observer.com/2015/08/stephen-hawking-elon-musk-and-bill-gates-warn-about-artificial-intelligence/</arg><arg name="website"><space/>Observer</arg><arg name="publisher"><space/>https://plus.google.com/112242738293247903578/</arg><arg name="accessdate"><space/>2015-10-30</arg><arg name="language"><space/>en-US</arg></template></extension><space/>Bill Gates has stated that this advancement in technology is a major threat. According to Gates, the next ten years will show big improvements in visual and speech understanding in computers, and combined with the increased mobility of machines like Atlas, will lead to extensive use of machines.<extension extension_name='ref' name="Holley"></extension><space/>Elon Musk combats this threat by supporting research of artificial intelligence. Musk donated ten million dollars to the Future of Life Institute to fund research on understanding AI decision making. The goal of the institute is to &quot;grow wisdom with which we manage&quot; the growing power of technology. He also funds companies developing artificial intelligence such as Google DeepMind and Vicarious in order to just keep an eye on whats going on with artificial intelligence.<extension extension_name='ref'><template><target>Cite web</target><arg name="title"><space/>The mysterious artificial intelligence company Elon Musk invested in is developing game-changing smart computers</arg><arg name="url"><space/>http://www.techinsider.io/mysterious-artificial-intelligence-company-elon-musk-investment-2015-10</arg><arg name="website"><space/>Tech Insider</arg><arg name="accessdate"><space/>2015-10-30</arg></template></extension><space/>I think there is potentially a dangerous outcome there.<extension extension_name='ref'><template><target>Cite web</target><arg name="title"><space/>Musk-Backed Group Probes Risks Behind Artificial Intelligence</arg><arg name="url"><space/>http://www.bloomberg.com/news/articles/2015-07-01/musk-backed-group-probes-risks-behind-artificial-intelligence</arg><arg name="website"><space/>Bloomberg.com</arg><arg name="accessdate"><space/>2015-10-30</arg><arg name="first"><space/>Jack</arg><arg name="last"><space/>Clark</arg></template></extension><extension extension_name='ref'><template><target>Cite web</target><arg name="title"><space/>Elon Musk Is Donating $10M Of His Own Money To Artificial Intelligence Research</arg><arg name="url"><space/>http://www.fastcompany.com/3041007/fast-feed/elon-musk-is-donating-10m-of-his-own-money-to-artificial-intelligence-research</arg><arg name="website"><space/>Fast Company</arg><arg name="accessdate"><space/>2015-10-30</arg><arg name="language"><space/>en-US</arg></template></extension></paragraph><paragraph>There is also no connection between superintelligence and the desire to destroy all of humanity. It is unclear where this assumption comes from, as the logical conclusion would be to assist humanity. This irrational belief in the inherent malevolence and hostility of artificial intelligence may be the result of human guilt or ignorance, and its causes should be further explored.<extension extension_name='ref'><template><target>Cite web</target><arg name="title"><space/>The founder of Evernote made a great point about why AI (probably) won't kill us all</arg><arg name="url"><space/>http://www.vox.com/2015/8/12/9143071/evernote-artificial-intelligence</arg><arg name="website"><space/>Vox</arg><arg name="accessdate"><space/>2015-10-30</arg></template></extension></paragraph><paragraph>The possibility that Artificial Intelligence may come to be a threat to mankind cannot be eliminated, should new discoveries be made, but with regards to current research, there is little evidence for the possibility of a superintelligent computer coming into existence at all.</paragraph><heading level='2'>In fiction</heading><paragraph><template><target>Main</target><arg>Artificial intelligence in fiction</arg></template></paragraph><preblock><preline>The implications of artificial intelligence have been a persistent theme in<space/><link><target>science fiction</target></link>. Early stories typically revolved around intelligent robots. The word &quot;robot&quot; itself was coined by<space/><link><target>Karel apek</target></link><space/>in his 1921 play<space/><italics><link><target>R.U.R.</target></link></italics>, the title standing for &quot;<link><target>Rossum's Universal Robots</target></link>&quot;. Later, the SF writer<space/><link><target>Isaac Asimov</target></link><space/>developed the<space/><link><target>three laws of robotics</target></link><space/>which he subsequently explored in a long series of robot stories. These laws have since gained some traction in genuine AI research.</preline></preblock><paragraph>Other influential fictional intelligences include<space/><link><target>HAL 9000</target><part>HAL</part></link>, the computer in charge of the spaceship in<space/><italics><link><target>2001: A Space Odyssey</target></link></italics>, released as both a film and a book in 1968 and written by<space/><link><target>Arthur C. Clarke</target></link>.</paragraph><paragraph>Since then, AI has become firmly rooted in popular culture.</paragraph><paragraph><template><target>div col end</target></template></paragraph><heading level='2'>Notes</heading><paragraph><template><target>reflist</target><arg>30em</arg><arg name="refs">
 
 
<ref name</arg></template></paragraph><heading level='2'>References</heading><heading level='3'>AI textbooks</heading><paragraph><template><target>refbegin</target></template></paragraph><list type='bullet'><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Hutter<space/></arg><arg name="first">Marcus<space/></arg><arg name="author-link">Marcus Hutter<space/></arg><arg name="year">2005
</arg><arg name="title">[[AIXI|Universal Artificial Intelligence]]
</arg><arg name="isbn">978-3-540-22139-5
</arg><arg name="publisher">Springer
</arg><arg name="location">Berlin
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last1">Luger<space/></arg><arg name="first1">George<space/></arg><arg name="author-link">George Luger
</arg><arg name="last2">Stubblefield<space/></arg><arg name="first2">William<space/></arg><arg name="author2-link">William Stubblefield
</arg><arg name="year">2004
</arg><arg name="title">Artificial Intelligence: Structures and Strategies for Complex Problem Solving
</arg><arg name="publisher">Benjamin/Cummings<space/></arg><arg name="edition">5th
</arg><arg name="isbn">0-8053-4780-1
</arg><arg name="url">http://www.cs.unm.edu/~luger/ai-final/tocfull.html
</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Neapolitan<space/></arg><arg name="first">Richard<space/></arg><arg name="last2">Jiang<space/></arg><arg name="first2">Xia<space/></arg><arg name="year">2012
</arg><arg name="title">Contemporary Artificial Intelligence
</arg><arg name="publisher">Chapman & Hall/CRC
</arg><arg name="isbn">978-1-4398-4469-4
</arg><arg name="url">http://www.crcpress.com/product/isbn/9781439844694
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Nilsson<space/></arg><arg name="first">Nils<space/></arg><arg name="author-link">Nils Nilsson (researcher)<space/></arg><arg name="year">1998
</arg><arg name="title">Artificial Intelligence: A New Synthesis
</arg><arg name="publisher">Morgan Kaufmann
</arg><arg name="isbn">978-1-55860-467-4
</arg></template></listitem><listitem><template><target>Russell Norvig 2003</target></template>.</listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="first1">David<space/></arg><arg name="last1">Poole<space/></arg><arg name="author-link">David Poole (researcher)
</arg><arg name="first2">Alan<space/></arg><arg name="last2">Mackworth<space/></arg><arg name="author2-link">Alan Mackworth
</arg><arg name="first3">Randy<space/></arg><arg name="last3">Goebel<space/></arg><arg name="author3-link">Randy Goebel
</arg><arg name="year">1998
</arg><arg name="title">Computational Intelligence: A Logical Approach
</arg><arg name="publisher">Oxford University Press<space/></arg><arg name="location"><space/>New York
</arg><arg name="isbn">0-19-510270-3
</arg><arg name="url">http://www.cs.ubc.ca/spider/poole/ci.html
</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Winston<space/></arg><arg name="first">Patrick Henry<space/></arg><arg name="author-link">Patrick Winston<space/></arg><arg name="year">1984
</arg><arg name="title">Artificial Intelligence
</arg><arg name="publisher">Addison-Wesley<space/></arg><arg name="location">Reading, MA
</arg><arg name="isbn">0-201-08259-4
</arg></template></listitem><listitem><template><target>cite book</target><arg name="last">Rich<space/></arg><arg name="first">Elaine<space/></arg><arg name="author-link">Elaine Rich<space/></arg><arg name="year">1983
</arg><arg name="title">Artificial Intelligence
</arg><arg name="publisher"><space/>McGraw-Hill
</arg><arg name="isbn">0-07-052261-8
</arg></template></listitem></list><paragraph><template><target>refend</target></template></paragraph><heading level='3'>History of AI</heading><paragraph><template><target>refbegin</target></template></paragraph><list type='bullet'><listitem><template><target>Crevier 1993</target></template>.</listitem><listitem><template><target>McCorduck 2004</target></template>.</listitem><listitem><template><target>cite book</target><arg name="last">Nilsson<space/></arg><arg name="first">Nils<space/></arg><arg name="author-link">Nils Nilsson (researcher)<space/></arg><arg name="year">2010
</arg><arg name="title">The Quest for Artificial Intelligence: A History of Ideas and Achievements
</arg><arg name="publisher">Cambridge University Press<space/></arg><arg name="location">New York
</arg><arg name="isbn">978-0-521-12293-1
</arg></template></listitem></list><paragraph><template><target>refend</target></template></paragraph><heading level='3'>Other sources</heading><paragraph><template><target>refbegin</target><arg name="colwidth">60em</arg></template></paragraph><list type='bullet'><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last1">Asada<space/></arg><arg name="first1">M.<space/></arg><arg name="last2">Hosoda<space/></arg><arg name="first2">K.<space/></arg><arg name="last3">Kuniyoshi<space/></arg><arg name="first3">Y.
</arg><arg name="last4">Ishiguro<space/></arg><arg name="first4">H.<space/></arg><arg name="last5">Inui<space/></arg><arg name="first5">T.<space/></arg><arg name="last6">Yoshikawa<space/></arg><arg name="first6">Y.
</arg><arg name="last7">Ogino<space/></arg><arg name="first7">M.<space/></arg><arg name="last8">Yoshida<space/></arg><arg name="first8">C.<space/></arg><arg name="year">2009
</arg><arg name="title">Cognitive developmental robotics: a survey
</arg><arg name="journal">IEEE Transactions on Autonomous Mental Development<space/></arg><arg name="volume">1<space/></arg><arg name="issue">1<space/></arg><arg name="pages">12–34
</arg><arg name="url">http://ieeexplore.ieee.org/xpl/login.jsp?tp</arg><arg name="doi">10.1109/tamd.2009.2021702
</arg></template><template><target>dead link</target><arg name="date">March 2015</arg></template></listitem><listitem><template><target>cite web</target><arg name="ref">{{harvid|ACM|1998}}
</arg><arg name="publisher">[[Association for Computing Machinery|ACM]]
</arg><arg name="year">1998
</arg><arg name="title">ACM Computing Classification System: Artificial intelligence
</arg><arg name="url">http://www.acm.org/class/1998/I.2.html<space/></arg><arg name="accessdate">30 August 2007
</arg></template></listitem><listitem><template><target>cite encyclopedia</target><arg name="ref">harv
</arg><arg name="last">Albus<space/></arg><arg name="first">J. S.<space/></arg><arg name="year">2002<space/></arg><arg name="pages">11–20
</arg><arg name="title">4-D/RCS: A Reference Model Architecture for Intelligent Unmanned Ground Vehicles
</arg><arg name="editor1-last">Gerhart<space/></arg><arg name="editor-first">G.<space/></arg><arg name="editor2-last">Gunderson<space/></arg><arg name="editor2-first">R.
</arg><arg name="editor3-last">Shoemaker<space/></arg><arg name="editor3-first">C.
</arg><arg name="encyclopedia">Proceedings of the SPIE AeroSense Session on Unmanned Ground Vehicle Technology<space/></arg><arg name="volume">3693
</arg><arg name="url">http://www.isd.mel.nist.gov/documents/albus/4DRCS.pdf
</arg><arg name="archiveurl">http://web.archive.org/web/20040725051856/http://www.isd.mel.nist.gov/documents/albus/4DRCS.pdf
</arg><arg name="archivedate">25 July 2004
</arg></template></listitem><listitem><template><target>Cite book</target><arg name="last"><space/>Aleksander<space/></arg><arg name="first"><space/>Igor<space/></arg><arg name="authorlink"><space/>Igor Aleksander
</arg><arg name="year">1995
</arg><arg name="title"><space/>Artificial Neuroconsciousness: An Update
</arg><arg name="publisher">IWANN
</arg><arg name="url"><space/>http://www.ee.ic.ac.uk/research/neural/publications/iwann.html
</arg><arg name="archiveurl"><space/>http://web.archive.org/web/19970302014628/http://www.ee.ic.ac.uk/research/neural/publications/iwann.html
</arg><arg name="archivedate"><space/>2 March 1997
</arg><arg name="ref"><space/>harv
</arg></template><space/><link type='external' href='http://dblp.uni-trier.de/rec/bibtex/conf/iwann/Aleksander95'>BibTex</link><space/><template><target>Wayback</target><arg name="df">yes</arg><arg name="date">19970302014628<space/></arg><arg name="url">http://www.ee.ic.ac.uk/research/neural/publications/iwann.html<space/></arg><arg name="title">
</arg></template>.</listitem><listitem><template><target>cite encyclopedia</target><arg name="ref">harv
</arg><arg name="last">Bach<space/></arg><arg name="first">Joscha<space/></arg><arg name="year">2008<space/></arg><arg name="pages">63–74
</arg><arg name="title">Seven Principles of Synthetic Intelligence
</arg><arg name="editor1-last">Wang<space/></arg><arg name="editor1-first">Pei<space/></arg><arg name="editor2-last">Goertzel<space/></arg><arg name="editor2-first">Ben<space/></arg><arg name="editor3-last">Franklin<space/></arg><arg name="editor3-first">Stan
</arg><arg name="work">Artificial General Intelligence, 2008: Proceedings of the First AGI Conference
</arg><arg name="publisher">IOS Press<space/></arg><arg name="isbn">978-1-58603-833-5
</arg><arg name="url">http://books.google.com/books?id</arg></template></listitem><listitem><template><target>cite news</target><arg name="ref">{{harvid|''BBC News''|2006}}
</arg><arg name="date">21 December 2006
</arg><arg name="title">Robots could demand legal rights<space/></arg><arg name="work">BBC News
</arg><arg name="url">http://news.bbc.co.uk/2/hi/technology/6200005.stm<space/></arg><arg name="accessdate">3 February 2011
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last">Brooks<space/></arg><arg name="first">Rodney<space/></arg><arg name="authorlink">Rodney Brooks<space/></arg><arg name="year">1990
</arg><arg name="title">Elephants Don't Play Chess
</arg><arg name="journal">Robotics and Autonomous Systems<space/></arg><arg name="volume">6<space/></arg><arg name="pages">3–15
</arg><arg name="doi">10.1016/S0921-8890(05)80025-9
</arg><arg name="url">http://people.csail.mit.edu/brooks/papers/elephants.pdf<space/></arg><arg name="format">PDF
</arg><arg name="archiveurl"><space/>http://web.archive.org/web/20070809020912/http://people.csail.mit.edu/brooks/papers/elephants.pdf
</arg><arg name="archivedate">9 August 2007<space/></arg><arg name="deadurl">no
</arg></template></listitem><listitem><template><target>cite encyclopedia</target><arg name="ref">harv
</arg><arg name="last">Brooks<space/></arg><arg name="first">R. A.<space/></arg><arg name="year">1991<space/></arg><arg name="pages">225–239
</arg><arg name="title">How to build complete creatures rather than isolated cognitive simulators
</arg><arg name="editor-last">VanLehn<space/></arg><arg name="editor-first">K.
</arg><arg name="encyclopedia">Architectures for Intelligence<space/></arg><arg name="location">Hillsdale, NJ<space/></arg><arg name="publisher">Lawrence Erlbaum Associates
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last">Buchanan<space/></arg><arg name="first">Bruce G.<space/></arg><arg name="year">2005<space/></arg><arg name="pages">53–60
</arg><arg name="title">A (Very) Brief History of Artificial Intelligence
</arg><arg name="journal">AI Magazine
</arg><arg name="url">http://www.aaai.org/AITopics/assets/PDF/AIMag26-04-016.pdf<space/></arg><arg name="format">PDF
</arg><arg name="archiveurl">http://web.archive.org/web/20070926023314/http://www.aaai.org/AITopics/assets/PDF/AIMag26-04-016.pdf
</arg><arg name="archivedate">26 September 2007<space/></arg><arg name="deadurl">no
</arg></template></listitem><listitem><template><target>cite news</target><arg name="ref">harv
</arg><arg name="last">Butler<space/></arg><arg name="first">Samuel<space/></arg><arg name="authorlink">Samuel Butler (novelist)<space/></arg><arg name="date">13 June 1863
</arg><arg name="title">Darwin among the Machines
</arg><arg name="newspaper">The Press<space/></arg><arg name="location">Christchurch, New Zealand<space/></arg><arg name="department">Letters to the Editor
</arg><arg name="url">http://www.nzetc.org/tm/scholarly/tei-ButFir-t1-g1-t1-g1-t4-body.html<space/></arg><arg name="accessdate">16 October 2014
</arg><arg name="via">Victoria University of Wellington
</arg></template></listitem><listitem><template><target>cite news</target><arg name="ref">{{harvid|''CNN''|2006}}
</arg><arg name="title">AI set to exceed human brain power
</arg><arg name="work">CNN<space/></arg><arg name="date">26 July 2006
</arg><arg name="url">http://www.cnn.com/2006/TECH/science/07/24/ai.bostrom/
</arg><arg name="archiveurl"><space/>http://web.archive.org/web/20080219001624/http://www.cnn.com/2006/TECH/science/07/24/ai.bostrom/
</arg><arg name="archivedate">19 February 2008<space/></arg><arg name="deadurl">no
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Dennett<space/></arg><arg name="first">Daniel<space/></arg><arg name="author-link">Daniel Dennett
</arg><arg name="year">1991
</arg><arg name="title">[[Consciousness Explained]]
</arg><arg name="publisher">The Penguin Press
</arg><arg name="isbn"><space/>0-7139-9037-6
</arg></template></listitem><listitem><template><target>cite web</target><arg name="ref">harv
</arg><arg name="last">Diamond<space/></arg><arg name="first">David<space/></arg><arg name="date">December 2003
</arg><arg name="title">The Love Machine; Building computers that care
</arg><arg name="publisher">Wired
</arg><arg name="url">http://www.wired.com/wired/archive/11.12/love.html
</arg><arg name="archiveurl"><space/>http://web.archive.org/web/20080518185630/http://www.wired.com/wired/archive/11.12/love.html
</arg><arg name="archivedate">18 May 2008<space/></arg><arg name="deadurl">no
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last1">Dowe<space/></arg><arg name="first1">D. L.<space/></arg><arg name="last2">Hajek<space/></arg><arg name="first2">A. R.<space/></arg><arg name="year">1997
</arg><arg name="title">A computational extension to the Turing Test
</arg><arg name="journal">Proceedings of the 4th Conference of the Australasian Cognitive Science Society
</arg><arg name="url">http://www.csse.monash.edu.au/publications/1997/tr-cs97-322-abs.html
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Dreyfus<space/></arg><arg name="first">Hubert<space/></arg><arg name="authorlink"><space/>Hubert Dreyfus
</arg><arg name="year"><space/>1972
</arg><arg name="title"><space/>[[What Computers Can't Do]]
</arg><arg name="publisher"><space/>MIT Press<space/></arg><arg name="location"><space/>New York
</arg><arg name="isbn"><space/>0-06-011082-1
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Dreyfus<space/></arg><arg name="first">Hubert<space/></arg><arg name="authorlink"><space/>Hubert Dreyfus
</arg><arg name="last2"><space/>Dreyfus<space/></arg><arg name="first2"><space/>Stuart
</arg><arg name="year"><space/>1986
</arg><arg name="title"><space/>Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer
</arg><arg name="publisher"><space/>Blackwell<space/></arg><arg name="location"><space/>Oxford, UK
</arg><arg name="isbn">0-02-908060-6
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Dreyfus<space/></arg><arg name="first">Hubert<space/></arg><arg name="authorlink"><space/>Hubert Dreyfus
</arg><arg name="year">1992
</arg><arg name="title"><space/>What Computers ''Still'' Can't Do
</arg><arg name="publisher"><space/>MIT Press<space/></arg><arg name="location"><space/>New York
</arg><arg name="isbn">0-262-54067-3
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Dyson<space/></arg><arg name="first">George<space/></arg><arg name="authorlink">George Dyson (science historian)<space/></arg><arg name="year">1998
</arg><arg name="title">Darwin among the Machines
</arg><arg name="publisher">Allan Lane Science<space/></arg><arg name="isbn">0-7382-0030-1
</arg></template></listitem><listitem><template><target>cite web</target><arg name="ref">harv
</arg><arg name="last"><space/>Edelman<space/></arg><arg name="first"><space/>Gerald<space/></arg><arg name="authorlink"><space/>Gerald Edelman
</arg><arg name="date"><space/>23 November 2007
</arg><arg name="title"><space/>Gerald Edelman – Neural Darwinism and Brain-based Devices
</arg><arg name="url"><space/>http://lis.epfl.ch/resources/podcast/2007/11/gerald-edelman-neural-darwinism-and.html
</arg><arg name="publisher"><space/>Talking Robots
</arg></template><template><target>dead link</target><arg name="date">March 2015</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Edelson<space/></arg><arg name="first">Edward<space/></arg><arg name="year">1991
</arg><arg name="title">The Nervous System
</arg><arg name="publisher">Chelsea House<space/></arg><arg name="location">New York<space/></arg><arg name="isbn">978-0-7910-0464-7
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Fearn
</arg><arg name="first"><space/>Nicholas
</arg><arg name="year">2007
</arg><arg name="title"><space/>The Latest Answers to the Oldest Questions: A Philosophical Adventure with the World's Greatest Thinkers
</arg><arg name="publisher"><space/>Grove Press
</arg><arg name="location">New York<space/></arg><arg name="isbn">0-8021-1839-9
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
<space/></arg><arg name="last"><space/>Gladwell<space/></arg><arg name="first"><space/>Malcolm<space/></arg><arg name="authorlink"><space/>Malcolm Gladwell
<space/></arg><arg name="year"><space/>2005
<space/></arg><arg name="title"><space/>[[Blink (book)|Blink]]
<space/></arg><arg name="isbn"><space/>0-316-17232-4
<space/></arg><arg name="publisher"><space/>Little, Brown and Co.<space/></arg><arg name="location"><space/>New York
</arg></template></listitem><listitem><template><target>cite conference</target><arg name="ref">harv
</arg><arg name="last">Gödel<space/></arg><arg name="first">Kurt<space/></arg><arg name="authorlink">Kurt Gödel<space/></arg><arg name="year">1951
</arg><arg name="title">Some basic theorems on the foundations of mathematics and their implications
</arg><arg name="conference">Gibbs Lecture
</arg></template><space/>In<xhtml:br></xhtml:br><space/><template><target>cite book</target><arg name="editor-last">Feferman<space/></arg><arg name="editor-first">Solomon<space/></arg><arg name="editorlink">Solomon Feferman<space/></arg><arg name="year">1995<space/></arg><arg name="pages">304–23
</arg><arg name="title">Kurt Gödel: Collected Works, Vol. III: Unpublished Essays and Lectures
</arg><arg name="publisher">Oxford University Press<space/></arg><arg name="isbn">978-0-19-514722-3
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Haugeland<space/></arg><arg name="first">John<space/></arg><arg name="author-link"><space/>John Haugeland
</arg><arg name="year"><space/>1985
</arg><arg name="title"><space/>Artificial Intelligence: The Very Idea
</arg><arg name="publisher">MIT Press</arg><arg name="location"><space/>Cambridge, Mass.
</arg><arg name="isbn">0-262-08153-9
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Hawkins<space/></arg><arg name="first">Jeff<space/></arg><arg name="author-link">Jeff Hawkins
</arg><arg name="last2">Blakeslee<space/></arg><arg name="first2">Sandra
</arg><arg name="year">2005
</arg><arg name="title">[[On Intelligence]]
</arg><arg name="publisher">Owl Books<space/></arg><arg name="location">New York, NY
</arg><arg name="isbn">0-8050-7853-3
</arg></template></listitem><listitem><template><target>cite news</target><arg name="ref">harv
</arg><arg name="last">Henderson<space/></arg><arg name="first">Mark<space/></arg><arg name="date">24 April 2007
</arg><arg name="title">Human rights for robots? We're getting carried away
</arg><arg name="url">http://www.thetimes.co.uk/tto/technology/article1966391.ece
</arg><arg name="work">The Times Online<space/></arg><arg name="location">London
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last">Hernandez-Orallo<space/></arg><arg name="first">Jose<space/></arg><arg name="year">2000
</arg><arg name="title">Beyond the Turing Test
</arg><arg name="journal">Journal of Logic, Language and Information<space/></arg><arg name="volume">9<space/></arg><arg name="issue">4<space/></arg><arg name="pages">447–466
</arg><arg name="doi">10.1023/A:1008367325700
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last1">Hernandez-Orallo<space/></arg><arg name="first1">J.<space/></arg><arg name="last2">Dowe<space/></arg><arg name="first2">D. L.<space/></arg><arg name="year">2010
</arg><arg name="title">Measuring Universal Intelligence: Towards an Anytime Intelligence Test
</arg><arg name="journal">Artificial Intelligence Journal<space/></arg><arg name="volume">174<space/></arg><arg name="issue">18<space/></arg><arg name="pages">1508–1539
</arg><arg name="doi">10.1016/j.artint.2010.09.006
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last">Hinton<space/></arg><arg name="first">G. E.<space/></arg><arg name="year">2007
</arg><arg name="title">Learning multiple layers of representation
</arg><arg name="journal">Trends in Cognitive Sciences<space/></arg><arg name="volume">11<space/></arg><arg name="pages">428–434<space/></arg><arg name="doi">10.1016/j.tics.2007.09.004
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Hofstadter<space/></arg><arg name="first"><space/>Douglas<space/></arg><arg name="author-link"><space/>Douglas Hofstadter
</arg><arg name="year"><space/>1979
</arg><arg name="title"><space/>[[Gödel, Escher, Bach|Gödel, Escher, Bach: an Eternal Golden Braid]]
</arg><arg name="isbn">0-394-74502-7
</arg><arg name="publisher">Vintage Books
</arg><arg name="location">New York, NY
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Holland<space/></arg><arg name="first">John H.<space/></arg><arg name="year">1975
</arg><arg name="title">Adaptation in Natural and Artificial Systems
</arg><arg name="publisher">University of Michigan Press<space/></arg><arg name="isbn">0-262-58111-6
</arg></template></listitem><listitem><template><target>cite web</target><arg name="ref">harv
</arg><arg name="first"><space/>J.<space/></arg><arg name="last"><space/>Howe
</arg><arg name="date"><space/>November 1994
</arg><arg name="title"><space/>Artificial Intelligence at Edinburgh University: a Perspective
</arg><arg name="url">http://www.inf.ed.ac.uk/about/AIhistory.html<space/></arg><arg name="accessdate">30 August 2007
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Hutter<space/></arg><arg name="first">M.<space/></arg><arg name="year">2012
</arg><arg name="title">Theoretical Foundations of Artificial General Intelligence
</arg><arg name="chapter">One Decade of Universal Artificial Intelligence
</arg><arg name="volume">4<space/></arg><arg name="series">Atlantis Thinking Machines
</arg><arg name="doi">10.2991/978-94-91216-62-6_5<space/></arg><arg name="isbn">978-94-91216-61-9
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last">James<space/></arg><arg name="first">William<space/></arg><arg name="year">1884
</arg><arg name="title">What is Emotion
</arg><arg name="journal">Mind<space/></arg><arg name="volume">9<space/></arg><arg name="pages">188–205<space/></arg><arg name="doi">10.1093/mind/os-IX.34.188
</arg></template><space/>Cited by<space/><template><target>harvnb</target><arg>Tao</arg><arg>Tan</arg><arg>2005</arg></template>.</listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Kahneman<space/></arg><arg name="first">Daniel<space/></arg><arg name="author-link">Daniel Kahneman
</arg><arg name="last2">Slovic<space/></arg><arg name="first2"><space/>D.
</arg><arg name="last3">Tversky<space/></arg><arg name="first3">Amos<space/></arg><arg name="author3-link">Amos Tversky
</arg><arg name="year">1982
</arg><arg name="title">Judgment under uncertainty: Heuristics and biases
</arg><arg name="publisher">Cambridge University Press<space/></arg><arg name="location">New York
</arg><arg name="isbn">0-521-28414-7
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last">Katz<space/></arg><arg name="first">Yarden<space/></arg><arg name="date">1 November 2012
</arg><arg name="title">Noam Chomsky on Where Artificial Intelligence Went Wrong
</arg><arg name="work">The Atlantic
</arg><arg name="url">http://www.theatlantic.com/technology/archive/2012/11/noam-chomsky-on-where-artificial-intelligence-went-wrong/261637/?single_page</arg><arg name="accessdate">26 October 2014
</arg></template></listitem><listitem><template><target>cite web</target><arg name="ref">{{harvid|''Kismet''}}
</arg><arg name="title">Kismet
</arg><arg name="publisher">MIT Artificial Intelligence Laboratory, Humanoid Robotics Group
</arg><arg name="url">http://www.ai.mit.edu/projects/humanoid-robotics-group/kismet/kismet.html<space/></arg><arg name="accessdate">25 October 2014
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Koza<space/></arg><arg name="first">John R.<space/></arg><arg name="year">1992
</arg><arg name="title">Genetic Programming (On the Programming of Computers by Means of Natural Selection)
</arg><arg name="publisher">MIT Press<space/></arg><arg name="isbn">0-262-11170-5
</arg></template></listitem><listitem><template><target>cite web</target><arg name="ref">harv
</arg><arg name="last">Kleine-Cosack<space/></arg><arg name="first">Christian<space/></arg><arg name="date">October 2006<space/></arg><arg name="format">PDF
</arg><arg name="title"><space/>Recognition and Simulation of Emotions
</arg><arg name="url"><space/>http://ls12-www.cs.tu-dortmund.de//~fink/lectures/SS06/human-robot-interaction/Emotion-RecognitionAndSimulation.pdf
</arg><arg name="archiveurl">http://web.archive.org/web/20080528135730/http://ls12-www.cs.tu-dortmund.de/~fink/lectures/SS06/human-robot-interaction/Emotion-RecognitionAndSimulation.pdf<space/></arg><arg name="archivedate">28 May 2008
</arg></template></listitem><listitem><template><target>Cite journal</target><arg name="ref">harv
</arg><arg name="first"><space/>G.<space/></arg><arg name="last">Kolata
</arg><arg name="year">1982
</arg><arg name="title">How can computers get common sense?
</arg><arg name="journal">Science<space/></arg><arg name="issue"><space/>4566</arg><arg name="pages">1237–1238
</arg><arg name="doi"><space/>10.1126/science.217.4566.1237
</arg><arg name="volume"><space/>217<space/></arg><arg name="pmid">17837639
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last1">Kumar<space/></arg><arg name="first1">Gulshan
</arg><arg name="last2">Kumar<space/></arg><arg name="first2">Krishan
</arg><arg name="title">The Use of Artificial-Intelligence-Based Ensembles for Intrusion Detection: A Review
</arg><arg name="journal">Applied Computational Intelligence and Soft Computing
</arg><arg name="year">2012
</arg><arg name="volume">2012
</arg><arg name="pages">1–20
</arg><arg name="doi">10.1155/2012/850160
</arg><arg name="url">http://www.hindawi.com.proxy.lib.umich.edu/journals/acisc/2012/850160/
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Kurzweil<space/></arg><arg name="first">Ray<space/></arg><arg name="author-link">Ray Kurzweil
</arg><arg name="year">1999
</arg><arg name="title">[[The Age of Spiritual Machines]]
</arg><arg name="publisher">Penguin Books
</arg><arg name="isbn">0-670-88217-8
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Kurzweil<space/></arg><arg name="first">Ray<space/></arg><arg name="author-link">Ray Kurzweil
</arg><arg name="year">2005
</arg><arg name="title">[[The Singularity is Near]]
</arg><arg name="publisher">Penguin Books
</arg><arg name="isbn">0-670-03384-7
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Lakoff<space/></arg><arg name="first">George<space/></arg><arg name="author-link">George Lakoff
</arg><arg name="last2">Núñez<space/></arg><arg name="first2">Rafael E.<space/></arg><arg name="author2-link">Rafael E. Núñez</arg><arg name="year">2000
</arg><arg name="title">[[Where Mathematics Comes From|Where Mathematics Comes From: How the Embodied Mind Brings Mathematics into Being]]
</arg><arg name="publisher">Basic Books
</arg><arg name="isbn"><space/>0-465-03771-2
</arg></template></listitem><listitem><template><target>Cite journal</target><arg name="ref">harv
</arg><arg name="last1">Langley<space/></arg><arg name="first1">Pat<space/></arg><arg name="year">2011
</arg><arg name="title">The changing science of machine learning
</arg><arg name="journal">[[Machine Learning (journal)|Machine Learning]]
</arg><arg name="volume">82<space/></arg><arg name="issue">3<space/></arg><arg name="pages">275–279
</arg><arg name="doi">10.1007/s10994-011-5242-y
</arg></template></listitem><listitem><template><target>cite techreport</target><arg name="ref">harv
</arg><arg name="last">Law<space/></arg><arg name="first">Diane<space/></arg><arg name="date">June 1994
</arg><arg name="title">Searle, Subsymbolic Functionalism and Synthetic Intelligence
</arg><arg name="institution">University of Texas at Austin<space/></arg><arg name="page">AI94-222
</arg><arg name="id"><space/>{{citeseerx|10.1.1.38.8384}}
</arg></template></listitem><listitem><template><target>cite techreport</target><arg name="ref">harv
</arg><arg name="last1">Legg<space/></arg><arg name="first1">Shane<space/></arg><arg name="last2">Hutter<space/></arg><arg name="first2">Marcus<space/></arg><arg name="date">15 June 2007
</arg><arg name="title">A Collection of Definitions of Intelligence
</arg><arg name="institution">[[IDSIA]]<space/></arg><arg name="number">07-07<space/></arg><arg name="arxiv">0706.3639
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Lenat<space/></arg><arg name="first">Douglas<space/></arg><arg name="author-link">Douglas Lenat
</arg><arg name="last2">Guha<space/></arg><arg name="first2">R. V.
</arg><arg name="year"><space/>1989
</arg><arg name="title"><space/>Building Large Knowledge-Based Systems
</arg><arg name="publisher"><space/>Addison-Wesley
</arg><arg name="isbn">0-201-51752-3
</arg></template></listitem><listitem><template><target>Cite book</target><arg name="ref">harv
</arg><arg name="last">Lighthill<space/></arg><arg name="first">James<space/></arg><arg name="author-link">James Lighthill<space/></arg><arg name="year">1973
</arg><arg name="contribution"><space/>Artificial Intelligence: A General Survey
</arg><arg name="title">Artificial Intelligence: a paper symposium
</arg><arg name="publisher">Science Research Council
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Lucas<space/></arg><arg name="first"><space/>John<space/></arg><arg name="author-link"><space/>John Lucas (philosopher)
</arg><arg name="year"><space/>1961
</arg><arg name="contribution">Minds, Machines and Gödel
</arg><arg name="editor-last"><space/>Anderson<space/></arg><arg name="editor-first">A.R.
</arg><arg name="title">Minds and Machines
</arg><arg name="url"><space/>http://users.ox.ac.uk/~jrlucas/Godel/mmg.html<space/></arg><arg name="accessdate">30 August 2007
</arg><arg name="archiveurl"><space/>http://web.archive.org/web/20070819165214/http://users.ox.ac.uk/~jrlucas/Godel/mmg.html</arg><arg name="archivedate"><space/>19 August 2007<space/></arg><arg name="deadurl"><space/>no
</arg></template></listitem><listitem><template><target>cite paper</target><arg name="ref">harv
</arg><arg name="last1">Lungarella<space/></arg><arg name="first1">M.<space/></arg><arg name="last2">Metta<space/></arg><arg name="first2">G.<space/></arg><arg name="last3">Pfeifer<space/></arg><arg name="first3">R.<space/></arg><arg name="last4">Sandini<space/></arg><arg name="first4">G.<space/></arg><arg name="year">2003
</arg><arg name="title">Developmental robotics: a survey
</arg><arg name="journal">Connection Science<space/></arg><arg name="volume">15<space/></arg><arg name="pages">151–190<space/></arg><arg name="id">{{citeseerx|10.1.1.83.7615}}<space/></arg><arg name="doi">10.1080/09540090310001655110
</arg></template></listitem><listitem><template><target>cite web</target><arg name="ref">harv
</arg><arg name="last"><space/>Maker<space/></arg><arg name="first"><space/>Meg Houston
</arg><arg name="year"><space/>2006
</arg><arg name="title"><space/>AI@50: AI Past, Present, Future<space/></arg><arg name="location">Dartmouth College
</arg><arg name="url"><space/>http://www.engagingexperience.com/2006/07/ai50_ai_past_pr.html<space/></arg><arg name="accessdate">16 October 2008
</arg><arg name="archiveurl"><space/>http://web.archive.org/web/20081008120238/http://www.engagingexperience.com/2006/07/ai50_ai_past_pr.html</arg><arg name="archivedate"><space/>8 October 2008<space/></arg><arg name="deadurl"><space/>no</arg></template></listitem><listitem><template><target>cite news</target><arg name="ref">harv
</arg><arg name="last">Markoff<space/></arg><arg name="first">John<space/></arg><arg name="date">16 February 2011
</arg><arg name="title">Computer Wins on 'Jeopardy!': Trivial, It's Not<space/></arg><arg name="work">The New York Times
</arg><arg name="url">http://www.nytimes.com/2011/02/17/science/17jeopardy-watson.html<space/></arg><arg name="accessdate">25 October 2014
</arg></template></listitem><listitem><template><target>cite web</target><arg name="ref">harv
</arg><arg name="last1"><space/>McCarthy<space/></arg><arg name="first1"><space/>John<space/></arg><arg name="authorlink1"><space/>John McCarthy (computer scientist)
</arg><arg name="last2"><space/>Minsky<space/></arg><arg name="first2"><space/>Marvin<space/></arg><arg name="authorlink2"><space/>Marvin Minsky
</arg><arg name="last3"><space/>Rochester<space/></arg><arg name="first3"><space/>Nathan<space/></arg><arg name="authorlink3"><space/>Nathan Rochester
</arg><arg name="last4"><space/>Shannon<space/></arg><arg name="first4"><space/>Claude<space/></arg><arg name="authorlink4"><space/>Claude Shannon
</arg><arg name="year"><space/>1955
</arg><arg name="title"><space/>A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence
</arg><arg name="url"><space/>http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html<space/></arg><arg name="accessdate">30 August 2007
</arg><arg name="archiveurl"><space/>http://web.archive.org/web/20070826230310/http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html</arg><arg name="archivedate"><space/>26 August 2007<space/></arg><arg name="deadurl"><space/>no</arg></template>.</listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last1"><space/>McCarthy<space/></arg><arg name="first1"><space/>John<space/></arg><arg name="author-link"><space/>John McCarthy (computer scientist)
</arg><arg name="last2"><space/>Hayes<space/></arg><arg name="first2">P. J.
</arg><arg name="year"><space/>1969
</arg><arg name="title"><space/>Some philosophical problems from the standpoint of artificial intelligence
</arg><arg name="journal">Machine Intelligence<space/></arg><arg name="volume"><space/>4<space/></arg><arg name="pages"><space/>463–502
</arg><arg name="url">http://www-formal.stanford.edu/jmc/mcchay69.html<space/></arg><arg name="accessdate">30 August 2007
</arg><arg name="archiveurl"><space/>http://web.archive.org/web/20070810233856/http://www-formal.stanford.edu/jmc/mcchay69.html</arg><arg name="archivedate"><space/>10 August 2007<space/></arg><arg name="deadurl"><space/>no</arg></template></listitem><listitem><template><target>cite web</target><arg name="ref">harv
</arg><arg name="last">McCarthy<space/></arg><arg name="first">John<space/></arg><arg name="authorlink">John McCarthy (computer scientist)
</arg><arg name="title">What Is Artificial Intelligence?
</arg><arg name="date">12 November 2007
</arg><arg name="url">http://www-formal.stanford.edu/jmc/whatisai/whatisai.html
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Minsky<space/></arg><arg name="first">Marvin<space/></arg><arg name="author-link">Marvin Minsky
</arg><arg name="year"><space/>1967
</arg><arg name="title"><space/>Computation: Finite and Infinite Machines
</arg><arg name="publisher"><space/>Prentice-Hall<space/></arg><arg name="location">Englewood Cliffs, N.J.
</arg><arg name="isbn">0-13-165449-7
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Minsky<space/></arg><arg name="first">Marvin<space/></arg><arg name="author-link">Marvin Minsky
</arg><arg name="year"><space/>2006
</arg><arg name="title"><space/>[[The Emotion Machine]]
</arg><arg name="publisher"><space/>Simon & Schusterl<space/></arg><arg name="publication-place">New York, NY
</arg><arg name="isbn">0-7432-7663-9
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Moravec<space/></arg><arg name="first">Hans<space/></arg><arg name="author-link">Hans Moravec
</arg><arg name="year"><space/>1988
</arg><arg name="title"><space/>Mind Children
</arg><arg name="publisher"><space/>Harvard University Press
</arg><arg name="isbn">0-674-57616-0
</arg></template></listitem><listitem><template><target>cite web</target><arg name="ref">harv
</arg><arg name="last">Norvig<space/></arg><arg name="first">Peter<space/></arg><arg name="authorlink">Peter Norvig<space/></arg><arg name="date">25 June 2012
</arg><arg name="title">On Chomsky and the Two Cultures of Statistical Learning
</arg><arg name="publisher">Peter Norvig
</arg><arg name="url">http://norvig.com/chomsky.html
</arg><arg name="archiveurl">http://web.archive.org/web/20141019223259/http://norvig.com/chomsky.html
</arg><arg name="archivedate">19 October 2014<space/></arg><arg name="deadurl">no
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">{{harvid|NRC|1999}}
</arg><arg name="author">NRC (United States National Research Council)<space/></arg><arg name="authorlink">United States National Research Council
</arg><arg name="year">1999
</arg><arg name="chapter">Developments in Artificial Intelligence
</arg><arg name="title">Funding a Revolution: Government Support for Computing Research
</arg><arg name="publisher">National Academy Press
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Needham<space/></arg><arg name="first">Joseph<space/></arg><arg name="authorlink"><space/>Joseph Needham
</arg><arg name="year">1986
</arg><arg name="title">[[Science and Civilization in China]]: Volume 2
</arg><arg name="publisher">Caves Books Ltd.
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last">Newell<space/></arg><arg name="first">Allen<space/></arg><arg name="author-link">Allen Newell
</arg><arg name="last2">Simon<space/></arg><arg name="first2">H. A.<space/></arg><arg name="authorlink2">Herbert A. Simon
</arg><arg name="year">1976
</arg><arg name="title">Computer Science as Empirical Inquiry: Symbols and Search
</arg><arg name="journal">Communications of the ACM<space/></arg><arg name="volume"><space/>19<space/></arg><arg name="issue">3<space/></arg><arg name="doi">10.1145/360018.360022 
</arg><arg name="url">http://www.rci.rutgers.edu/~cfs/472_html/AI_SEARCH/PSS/PSSH4.html<space/></arg><arg name="pages">113–126
</arg></template><template><target>dead link</target><arg name="date">March 2015</arg></template>.</listitem><listitem><template><target>Cite journal</target><arg name="ref">harv
</arg><arg name="last">Nilsson<space/></arg><arg name="first">Nils<space/></arg><arg name="author-link"><space/>Nils Nilsson (researcher)<space/></arg><arg name="year">1983
</arg><arg name="title">Artificial Intelligence Prepares for 2001
</arg><arg name="journal">AI Magazine<space/></arg><arg name="volume">1<space/></arg><arg name="number">1
</arg><arg name="url">http://ai.stanford.edu/~nilsson/OnlinePubs-Nils/General%20Essays/AIMag04-04-002.pdf
</arg></template><space/>Presidential Address to the<space/><link><target>Association for the Advancement of Artificial Intelligence</target></link>.</listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last1">O'Brien<space/></arg><arg name="first1">James<space/></arg><arg name="last2">Marakas<space/></arg><arg name="first2">George<space/></arg><arg name="year">2011
</arg><arg name="title">Management Information Systems<space/></arg><arg name="publisher">McGraw-Hill/Irwin<space/></arg><arg name="edition">10th
</arg><arg name="isbn">978-0-07-337681-3
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last">O'Connor<space/></arg><arg name="first">Kathleen Malone<space/></arg><arg name="year">1994
</arg><arg name="title">The alchemical creation of life (takwin) and other concepts of Genesis in medieval Islam
</arg><arg name="publisher">University of Pennsylvania
</arg><arg name="url">http://repository.upenn.edu/dissertations/AAI9503804
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last">Oudeyer<space/></arg><arg name="first">P-Y.<space/></arg><arg name="year">2010
</arg><arg name="title">On the impact of robotics in behavioral and cognitive sciences: from insect navigation to human cognitive development
</arg><arg name="journal">IEEE Transactions on Autonomous Mental Development<space/></arg><arg name="volume">2<space/></arg><arg name="issue">1<space/></arg><arg name="pages">2–16
</arg><arg name="url">http://www.pyoudeyer.com/IEEETAMDOudeyer10.pdf<space/></arg><arg name="doi">10.1109/tamd.2009.2039057
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Penrose<space/></arg><arg name="first">Roger<space/></arg><arg name="author-link">Roger Penrose<space/></arg><arg name="year">1989
</arg><arg name="title">The Emperor's New Mind: Concerning Computer, Minds and The Laws of Physics
</arg><arg name="publisher">[[Oxford University Press]]
</arg><arg name="isbn">0-19-851973-7
</arg></template></listitem><listitem><template><target>cite techreport</target><arg name="ref">harv
</arg><arg name="last">Picard<space/></arg><arg name="first">Rosalind<space/></arg><arg name="authorlink">Rosalind Picard<space/></arg><arg name="year">1995
</arg><arg name="title">Affective Computing<space/></arg><arg name="institution">MIT<space/></arg><arg name="number">321
</arg><arg name="url">http://affect.media.mit.edu/pdfs/95.picard.pdf
</arg><arg name="laysource">Abstract<space/></arg><arg name="layurl">http://vismod.media.mit.edu/pub/tech-reports/TR-321-ABSTRACT.html
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last1">Poli<space/></arg><arg name="first1">R.<space/></arg><arg name="last2">Langdon<space/></arg><arg name="first2">W. B.<space/></arg><arg name="last3">McPhee<space/></arg><arg name="first3">N. F.<space/></arg><arg name="year">2008
</arg><arg name="title">A Field Guide to Genetic Programming<space/></arg><arg name="publisher">Lulu.com<space/></arg><arg name="isbn">978-1-4092-0073-4
</arg><arg name="url">http://www.gp-field-guide.org.uk/<space/></arg><arg name="via">gp-field-guide.org.uk
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last">Rajani<space/></arg><arg name="first">Sandeep<space/></arg><arg name="year">2011
</arg><arg name="title">Artificial Intelligence – Man or Machine
</arg><arg name="journal">International Journal of Information Technology and Knowledge Management
</arg><arg name="volume">4<space/></arg><arg name="issue">1<space/></arg><arg name="pages">173–176
</arg><arg name="url">http://www.csjournals.com/IJITKM/PDF%204-1/35.Sandeep%20Rajani.pdf
</arg></template></listitem><listitem><template><target>Cite journal</target><arg name="ref">harv
</arg><arg name="last"><space/>Searle<space/></arg><arg name="first"><space/>John<space/></arg><arg name="author-link">John Searle
</arg><arg name="year"><space/>1980
</arg><arg name="title"><space/>Minds, Brains and Programs
</arg><arg name="journal"><space/>Behavioral and Brain Sciences<space/></arg><arg name="volume"><space/>3<space/></arg><arg name="issue"><space/>3<space/></arg><arg name="pages"><space/>417–457
</arg><arg name="url"><space/>http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html<space/></arg><arg name="doi">10.1017/S0140525X00005756
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Searle<space/></arg><arg name="first">John<space/></arg><arg name="author-link">John Searle
</arg><arg name="year"><space/>1999
</arg><arg name="title"><space/>Mind, language and society
</arg><arg name="publisher"><space/>Basic Books<space/></arg><arg name="location"><space/>New York, NY
</arg><arg name="isbn"><space/>0-465-04521-9<space/></arg><arg name="oclc"><space/>231867665 43689264
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Shapiro<space/></arg><arg name="first"><space/>Stuart C.<space/></arg><arg name="editor-first">Stuart C.<space/></arg><arg name="editor-last">Shapiro
</arg><arg name="year">1992
</arg><arg name="contribution">Artificial Intelligence
</arg><arg name="title">Encyclopedia of Artificial Intelligence<space/></arg><arg name="edition">2nd<space/></arg><arg name="pages">54–57
</arg><arg name="url">http://www.cse.buffalo.edu/~shapiro/Papers/ai.pdf
</arg><arg name="publisher"><space/>John Wiley<space/></arg><arg name="location">New York
</arg><arg name="isbn">0-471-50306-1
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Simon<space/></arg><arg name="first"><space/>H. A.<space/></arg><arg name="author-link">Herbert A. Simon
</arg><arg name="year"><space/>1965
</arg><arg name="title">The Shape of Automation for Men and Management
</arg><arg name="publisher"><space/>Harper & Row<space/></arg><arg name="publication-place"><space/>New York
</arg></template></listitem><listitem><template><target>cite web</target><arg name="ref">harv
</arg><arg name="last">Skillings<space/></arg><arg name="first">Jonathan
</arg><arg name="url">http://news.cnet.com/Getting-machines-to-think-like-us/2008-11394_3-6090207.html
</arg><arg name="title">Getting Machines to Think Like Us
</arg><arg name="work">cnet
</arg><arg name="date">3 July 2006
</arg><arg name="accessdate">3 February 2011
</arg></template></listitem><listitem><template><target>cite conference</target><arg name="ref">harv
</arg><arg name="last">Solomonoff<space/></arg><arg name="first">Ray<space/></arg><arg name="authorlink">Ray Solomonoff<space/></arg><arg name="year">1956
</arg><arg name="title">An Inductive Inference Machine
</arg><arg name="conference">Dartmouth Summer Research Conference on Artificial Intelligence
</arg><arg name="url">http://world.std.com/~rjs/indinf56.pdf<space/></arg><arg name="via">std.com, pdf scanned copy of the original
</arg></template><space/>Later published as<xhtml:br></xhtml:br><template><target>cite book</target><arg name="last">Solomonoff<space/></arg><arg name="first">Ray<space/></arg><arg name="year">1957<space/></arg><arg name="pages">56–62
</arg><arg name="chapter">An Inductive Inference Machine
</arg><arg name="title">IRE Convention Record<space/></arg><arg name="volume">Section on Information Theory, part 2
</arg></template></listitem><listitem><template><target>cite conference</target><arg name="ref">harv
</arg><arg name="last">Tao<space/></arg><arg name="first">Jianhua<space/></arg><arg name="first2">Tieniu<space/></arg><arg name="last2">Tan<space/></arg><arg name="year">2005
</arg><arg name="conference">Affective Computing: A Review
</arg><arg name="booktitle">Affective Computing and Intelligent Interaction<space/></arg><arg name="volume">[[LNCS]] 3784<space/></arg><arg name="pages">981–995
<space/></arg><arg name="publisher">Springer<space/></arg><arg name="doi">10.1007/11573548
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last">Tecuci<space/></arg><arg name="first">Gheorghe<space/></arg><arg name="date">March–April 2012
</arg><arg name="title">Artificial Intelligence
</arg><arg name="journal">Wiley Interdisciplinary Reviews: Computational Statistics
</arg><arg name="volume">4<space/></arg><arg name="issue">2<space/></arg><arg name="pages">168–180<space/></arg><arg name="publisher">Wiley<space/></arg><arg name="doi">10.1002/wics.200
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Thro<space/></arg><arg name="first">Ellen<space/></arg><arg name="year">1993
</arg><arg name="title">Robotics: The Marriage of Computers and Machines
</arg><arg name="location">New York<space/></arg><arg name="publisher">Facts on File<space/></arg><arg name="isbn">978-0-8160-2628-9
</arg></template></listitem><listitem><template><target>Turing 1950</target></template>.</listitem><listitem><template><target>cite web</target><arg name="ref">harv
</arg><arg name="last">van der Walt<space/></arg><arg name="first">Christiaan<space/></arg><arg name="last2">Bernard<space/></arg><arg name="first2">Etienne
</arg><arg name="year">2006
</arg><arg name="title"><space/>Data characteristics that determine classifier performance
</arg><arg name="url">http://www.patternrecognition.co.za/publications/cvdwalt_data_characteristics_classifiers.pdf</arg><arg name="format">PDF<space/></arg><arg name="accessdate">5 August 2009
</arg></template></listitem><listitem><template><target>cite web</target><arg name="ref">harv
</arg><arg name="last">Vinge<space/></arg><arg name="first">Vernor<space/></arg><arg name="authorlink">Vernor Vinge
</arg><arg name="year">1993
</arg><arg name="title">The Coming Technological Singularity: How to Survive in the Post-Human Era
</arg><arg name="url">http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last1">Wason<space/></arg><arg name="first1">P. C.<space/></arg><arg name="author-link">Peter Cathcart Wason
</arg><arg name="last2">Shapiro<space/></arg><arg name="first2">D.
</arg><arg name="editor">Foss, B. M.
</arg><arg name="year">1966
</arg><arg name="title">New horizons in psychology
</arg><arg name="location">Harmondsworth<space/></arg><arg name="publisher">Penguin
</arg><arg name="chapter">Reasoning
</arg></template></listitem><listitem><template><target>cite book</target><arg name="ref">harv
</arg><arg name="last">Weizenbaum<space/></arg><arg name="first"><space/>Joseph<space/></arg><arg name="authorlink">Joseph Weizenbaum
</arg><arg name="year"><space/>1976
</arg><arg name="title"><space/>[[Computer Power and Human Reason]]
</arg><arg name="publisher"><space/>W.H. Freeman & Company<space/></arg><arg name="location"><space/>San Francisco
</arg><arg name="isbn"><space/>0-7167-0464-1
</arg></template></listitem><listitem><template><target>cite journal</target><arg name="ref">harv
</arg><arg name="last1">Weng<space/></arg><arg name="first1">J.<space/></arg><arg name="last2">McClelland<space/></arg><arg name="first"><space/></arg><arg name="last3">Pentland<space/></arg><arg name="first3">A.<space/></arg><arg name="last4">Sporns<space/></arg><arg name="first4">O.
</arg><arg name="last5">Stockman<space/></arg><arg name="first5">I.<space/></arg><arg name="last6">Sur<space/></arg><arg name="first6">M.<space/></arg><arg name="last7">Thelen<space/></arg><arg name="first7">E.<space/></arg><arg name="year">2001
</arg><arg name="url">http://www.cse.msu.edu/dl/SciencePaper.pdf<space/></arg><arg name="via">msu.edu<space/></arg><arg name="doi"><space/>10.1126/science.291.5504.599 
</arg><arg name="title">Autonomous mental development by robots and animals<space/></arg><arg name="work">Science<space/></arg><arg name="volume">291<space/></arg><arg name="pages">599–600
</arg></template></listitem></list><paragraph><template><target>refend</target></template></paragraph><heading level='2'>Further reading</heading><list type='bullet'><listitem>TechCast Article Series, John Sagi,<space/><link type='external' href='https://www.techcastglobal.com/documents/10193/34869/Consciousness-Sagifinalversion'>Framing Consciousness</link></listitem><listitem><link><target>Boden, Margaret</target></link>, Mind As Machine,<space/><link><target>Oxford University Press</target></link>, 2006</listitem><listitem>Johnston, John (2008) &quot;The Allure of Machinic Life: Cybernetics, Artificial Life, and the New AI&quot;, MIT Press</listitem><listitem>Myers, Courtney Boyd ed. (2009).<space/><link type='external' href='http://www.forbes.com/2009/06/22/singularity-robots-computers-opinions-contributors-artificial-intelligence-09_land.html'>The AI Report</link>. Forbes June 2009</listitem><listitem><template><target>cite journal</target><arg name="last1"><space/>Serenko<space/></arg><arg name="first1"><space/>Alexander<space/></arg><arg name="year"><space/>2010<space/></arg><arg name="title"><space/>The development of an AI journal ranking based on the revealed preference approach<space/></arg><arg name="url"><space/>http://www.aserenko.com/papers/JOI_Serenko_AI_Journal_Ranking_Published.pdf<space/></arg><arg name="format"><space/>PDF<space/></arg><arg name="journal"><space/>Journal of Informetrics<space/></arg><arg name="volume"><space/>4<space/></arg><arg name="issue"><space/>4</arg><arg name="pages"><space/>447–459<space/></arg><arg name="doi"><space/>10.1016/j.joi.2010.04.001<space/></arg></template></listitem><listitem><template><target>cite journal</target><arg name="last1"><space/>Serenko<space/></arg><arg name="first1"><space/>Alexander<space/></arg><arg name="author2">Michael Dohan<space/></arg><arg name="year"><space/>2011<space/></arg><arg name="title"><space/>Comparing the expert survey and citation impact journal ranking methods: Example from the field of Artificial Intelligence<space/></arg><arg name="url"><space/>http://www.aserenko.com/papers/JOI_AI_Journal_Ranking_Serenko.pdf<space/></arg><arg name="format"><space/>PDF<space/></arg><arg name="journal"><space/>Journal of Informetrics<space/></arg><arg name="volume"><space/>5<space/></arg><arg name="issue"><space/>4</arg><arg name="pages"><space/>629–649<space/></arg><arg name="doi"><space/>10.1016/j.joi.2011.06.002<space/></arg></template></listitem><listitem>Sun, R. &amp; Bookman, L. (eds.),<space/><italics>Computational Architectures: Integrating Neural and Symbolic Processes</italics>. Kluwer Academic Publishers, Needham, MA. 1994.</listitem><listitem><template><target>cite web</target><arg name="url">http://www.technologyreview.com/news/533686/2014-in-computing-breakthroughs-in-artificial-intelligence/
</arg><arg name="title">2014 in Computing: Breakthroughs in Artificial Intelligence
</arg><arg name="author">Tom Simonite
</arg><arg name="date">29 December 2014
</arg><arg name="work">MIT Technology Review
</arg><arg name="publisher">
</arg><arg name="accessdate">
</arg></template></listitem></list><heading level='2'>External links</heading><paragraph><template><target>Sister project links</target><arg name="voy">no</arg><arg>Artificial Intelligence</arg></template></paragraph><list type='bullet'><listitem><link type='external' href='http://www-formal.stanford.edu/jmc/whatisai/whatisai.html'>What Is AI?</link><space/>An introduction to artificial intelligence by<space/><link><target>John McCarthy (computer scientist)</target><part>John McCarthy</part></link>&amp;mdash;a co-founder of the field, and the guy who coined the term.</listitem><listitem><link type='external' href='https://archive.org/details/handbookofartific01barr/'>The Handbook of Artificial Intelligence Volume by Avron Barr and Edward A. Feigenbaum (Stanford University)</link></listitem><listitem><template><target>IEP</target><arg>art-inte</arg><arg>Artificial Intelligence</arg></template></listitem><listitem><template><target>SEP</target><arg>logic-ai</arg><arg>Logic and Artificial Intelligence</arg><arg>Richmond Thomason</arg></template></listitem><listitem><template><target>dmoz</target><arg>Computers/Artificial_Intelligence/</arg><arg>AI</arg></template></listitem><listitem><link type='external' href='http://aitopics.org/'>AITopics</link><space/>A large directory of links and other resources maintained by the<space/><link><target>Association for the Advancement of Artificial Intelligence</target></link>, the leading organization of academic AI researchers.</listitem></list><paragraph><template><target>Clear</target></template><template><target>Navboxes</target><arg name="list">
{{John McCarthy navbox}}
{{Computable knowledge}}
{{Computer science}}
{{Evolutionary computation}}
{{Technology}}
{{philosophy of science}}
{{philosophy of mind}}
{{Robotics}}
{{Emerging technologies}}
</arg></template><template><target>Use dmy dates</target><arg name="date">December 2014</arg></template></paragraph><paragraph><template><target>Authority control</target></template></paragraph><paragraph><template><target>DEFAULTSORT:Artificial Intelligence</target></template><link><target>Category:Artificial intelligence</target><part></part></link><link><target>Category:Cybernetics</target></link><link><target>Category:Formal sciences</target></link><link><target>Category:Technology in society</target></link><link><target>Category:Computational neuroscience</target></link><link><target>Category:Emerging technologies</target></link><link><target>Category:Unsolved problems in computer science</target></link></paragraph></article>