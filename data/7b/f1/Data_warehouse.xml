<article title='Data_warehouse'><paragraph><template><target>multiple issues</target><arg name="{{Refimprove|date">February 2008}}
{{Citation style|date</arg></template></paragraph><paragraph><link><target>File:Data warehouse overview.JPG</target><part>thumb</part><part>200px</part><part>Data Warehouse Overview</part></link></paragraph><paragraph>In<space/><link><target>computing</target></link>, a<space/><bold>data warehouse</bold><space/>(<bold>DW</bold><space/>or<space/><bold>DWH</bold>), also known as an<space/><bold>enterprise data warehouse</bold><space/>(<bold>EDW</bold>), is a system used for<space/><link><target>Business reporting</target><part>reporting</part></link><space/>and<space/><link><target>data analysis</target></link>. DWs are central repositories of integrated data from one or more disparate sources. They store current and historical data and are used for creating analytical reports for knowledge workers throughout the enterprise. Examples of reports could range from annual and quarterly comparisons and trends to detailed daily sales analyses.</paragraph><paragraph>The data stored in the warehouse is<space/><link><target>upload</target><trail>ed</trail></link><space/>from the operational systems (such as marketing, sales, etc., shown in the figure to the right). The data may pass through an<space/><link><target>operational data store</target></link><space/>for additional operations before it is used in the DW for reporting.</paragraph><heading level='2'>Types of systems</heading><list type='def'><listitem><defkey><link><target>Data mart</target></link></defkey><defval><space/>A data mart is a simple form of a data warehouse that is focused on a single subject (or functional area), such as sales, finance or marketing. Data marts are often built and controlled by a single department within an organization. Given their single-subject focus, data marts usually draw data from only a few sources. The sources could be internal operational systems, a central data warehouse, or external data.<extension extension_name='ref'>http://docs.oracle.com/html/E10312_01/dm_concepts.htm Data Mart Concepts</extension><space/>Denormalization is the norm for data modeling techniques in this system.</defval></listitem></list><list type='def'><listitem><defkey><link><target>Online analytical processing</target></link><space/>(OLAP)</defkey><defval><space/>OLAP is characterized by a relatively low volume of transactions. Queries are often very complex and involve aggregations. For OLAP systems, response time is an effectiveness measure. OLAP applications are widely used by<space/><link><target>Data Mining</target></link><space/>techniques. OLAP databases store aggregated, historical data in multi-dimensional schemas (usually star schemas). OLAP systems typically have data latency of a few hours, as opposed to data marts, where latency is expected to be closer to one day.</defval></listitem></list><list type='def'><listitem><defkey><link><target>Online Transaction Processing</target></link><space/>(OLTP)</defkey><defval><space/>OLTP is characterized by a large number of short on-line transactions (INSERT, UPDATE, DELETE). OLTP systems emphasize very fast query processing and maintaining<space/><link><target>data integrity</target></link><space/>in multi-access environments. For OLTP systems, effectiveness is measured by the number of transactions per second. OLTP databases contain detailed and current data. The schema used to store transactional databases is the entity model (usually<space/><link><target>Third normal form</target><part>3NF</part></link>).<extension extension_name='ref'>http://datawarehouse4u.info/OLTP-vs-OLAP.html OLTP vs OLAP</extension><space/>Normalization is the norm for data modeling techniques in this system.</defval></listitem></list><list type='def'><listitem><defkey>Predictive analysis</defkey><defval><space/>Predictive analysis is about<space/><link><target>pattern recognition</target><part>finding</part></link><space/>and quantifying hidden patterns in the data using complex mathematical models that can be used to<space/><link><target>prediction</target><part>predict</part></link><space/>future outcomes. Predictive analysis is different from OLAP in that OLAP focuses on historical data analysis and is reactive in nature, while predictive analysis focuses on the future. These systems are also used for CRM (<link><target>Customer Relationship Management</target></link>).<extension extension_name='ref'>http://olap.com/category/bi-solutions/predictive-analytics Predictive Analysis</extension></defval></listitem></list><heading level='2'>Software tools</heading><paragraph>The typical extract-transform-load (<link><target>Extract, transform, load</target><part>ETL</part></link>)-based data warehouse uses<space/><link><target>Staging (data)</target><part>staging</part></link>,<space/><link><target>data integration</target></link>, and access layers to house its key functions. The staging layer or staging database stores raw data extracted from each of the disparate source data systems. The integration layer integrates the disparate data sets by transforming the data from the staging layer often storing this transformed data in an<space/><link><target>operational data store</target></link><space/>(ODS) database. The integrated data are then moved to yet another database, often called the data warehouse database, where the data is arranged into hierarchical groups often called dimensions and into facts and aggregate facts. The combination of facts and dimensions is sometimes called a<space/><link><target>star schema</target></link>. The access layer helps users retrieve data.<extension extension_name='ref' name="IJCA96Patil"><template><target>cite journal</target><arg name="url">http://www.ijcaonline.org/proceedings/icwet/number9/2131-db195<space/></arg><arg name="author">Patil, Preeti S.; Srikantha Rao; Suryakant B. Patil<space/></arg><arg name="title">Optimization of Data Warehousing System: Simplification in Reporting and Analysis<space/></arg><arg name="work">IJCA Proceedings on International Conference and workshop on Emerging Trends in Technology (ICWET)<space/></arg><arg name="year">2011<space/></arg><arg name="volume">9<space/></arg><arg name="issue">6<space/></arg><arg name="pages">33â€“37<space/></arg><arg name="publisher">Foundation of Computer Science</arg></template></extension></paragraph><paragraph>This definition of the data warehouse focuses on data storage. The main source of the data is cleaned, transformed, cataloged and made available for use by managers and other business professionals for<space/><link><target>data mining</target></link>,<space/><link><target>OLAP</target><part>online analytical processing</part></link>,<space/><link><target>market research</target></link><space/>and<space/><link><target>decision support</target></link>.<extension extension_name='ref'>Marakas &amp; O'Brien 2009</extension><space/>However, the means to retrieve and analyze data, to<space/><link><target>Extract, transform, load</target><part>extract, transform and load</part></link><space/>data, and to manage the<space/><link><target>data dictionary</target></link><space/>are also considered essential components of a data warehousing system. Many references to data warehousing use this broader context. Thus, an expanded definition for data warehousing includes<space/><link><target>business intelligence tools</target></link>, tools to<space/><link><target>Extract, transform, load</target><part>extract, transform and load</part></link><space/>data into the repository, and tools to manage and retrieve<space/><link><target>metadata</target></link>.</paragraph><heading level='2'>Benefits</heading><paragraph>A data warehouse maintains a copy of information from the source transaction systems. This architectural complexity provides the opportunity to :</paragraph><list type='bullet'><listitem>Congregate data from multiple sources into a single database so a single query engine can be used to present data.</listitem><listitem>Mitigate the problem of database isolation level lock contention in transaction processing systems caused by attempts to run large, long running, analysis queries in transaction processing databases.</listitem><listitem>Maintain<space/><link><target>Provenance#Data provenance</target><part>data history</part></link>, even if the source transaction systems do not.</listitem><listitem>Integrate data from multiple source systems, enabling a central view across the enterprise. This benefit is always valuable, but particularly so when the organization has grown by merger.</listitem><listitem>Improve<space/><link><target>data quality</target></link>, by providing consistent codes and descriptions, flagging or even fixing bad data.</listitem><listitem>Present the organization's information consistently.</listitem><listitem>Provide a single common data model for all data of interest regardless of the data's source.</listitem><listitem>Restructure the data so that it makes sense to the business users.</listitem><listitem>Restructure the data so that it delivers excellent query performance, even for complex analytic queries, without impacting the<space/><link><target>operational system</target><trail>s</trail></link>.</listitem><listitem>Add value to operational business applications, notably<space/><link><target>customer relationship management</target></link><space/>(CRM) systems.</listitem><listitem>Make decisionsupport queries easier to write.</listitem></list><heading level='2'>Generic data warehouse environment</heading><paragraph>The environment for data warehouses and marts includes the following:</paragraph><list type='bullet'><listitem>Source systems that provide data to the warehouse or mart;</listitem><listitem>Data integration technology and processes that are needed to prepare the data for use;</listitem><listitem>Different architectures for storing data in an organization's data warehouse or data marts;</listitem><listitem>Different tools and applications for the variety of users;</listitem><listitem>Metadata, data quality, and governance processes must be in place to ensure that the warehouse or mart meets its purposes.</listitem></list><paragraph>In regards to source systems listed above, Rainer<template><target>clarify</target><arg name="reason">Who is Rainer?</arg><arg name="date">December 2014</arg></template><space/>states, A common source for the data in data warehouses is the companys operational databases, which can be relational databases.<extension extension_name='ref' name="rainer2012"><template><target>cite book</target><arg name="last">Rainer</arg><arg name="first">R. Kelly</arg><arg name="title">Introduction to Information Systems: Enabling and Transforming Business, 4th Edition (Kindle Edition)</arg><arg name="date">2012-05-01</arg><arg name="publisher">Wiley</arg><arg name="pages">127, 128, 130, 131, 133</arg></template></extension></paragraph><paragraph>Regarding data integration, Rainer states, It is necessary to extract data from source systems, transform them, and load them into a data mart or warehouse.<extension extension_name='ref' name="rainer2012"></extension></paragraph><paragraph>Rainer discusses storing data in an organizations data warehouse or data marts.<extension extension_name='ref' name="rainer2012"></extension></paragraph><paragraph>Metadata are data about data. IT personnel need information about data sources; database, table, and column names; refresh schedules; and data usage measures.<extension extension_name='ref' name="rainer2012"></extension></paragraph><paragraph>Today, the most successful companies are those that can respond quickly and flexibly to market changes and opportunities. A key to this response is the effective and efficient use of data and information by analysts and managers.<extension extension_name='ref' name="rainer2012"></extension><space/>A data warehouse is a repository of historical data that are organized by subject to support decision makers in the organization.<extension extension_name='ref' name="rainer2012"></extension><space/>Once data are stored in a data mart or warehouse, they can be accessed.</paragraph><heading level='2'>History</heading><paragraph>The concept of data warehousing dates back to the late 1980s<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.computerworld.com/databasetopics/data/story/0,10801,70102,00.html</arg><arg name="title">The Story So Far</arg><arg name="date">2002-04-15</arg><arg name="accessdate">2008-09-21</arg></template></extension><space/>when IBM researchers Barry Devlin and Paul Murphy developed the &quot;business data warehouse&quot;. In essence, the data warehousing concept was intended to provide an architectural model for the flow of data from operational systems to<space/><link><target>decision support system</target><part>decision support environments</part></link>. The concept attempted to address the various problems associated with this flow, mainly the high costs associated with it. In the absence of a data warehousing architecture, an enormous amount of redundancy was required to support multiple decision support environments. In larger corporations it was typical for multiple decision support environments to operate independently. Though each environment served different users, they often required much of the same stored data. The process of gathering, cleaning and integrating data from various sources, usually from long-term existing operational systems (usually referred to as<space/><link><target>legacy system</target><trail>s</trail></link>), was typically in part replicated for each environment. Moreover, the operational systems were frequently reexamined as new decision support requirements emerged. Often new requirements necessitated gathering, cleaning and integrating new data from &quot;<link><target>data mart</target><trail>s</trail></link>&quot; that were tailored for ready access by users.</paragraph><paragraph>Key developments in early years of data warehousing were:</paragraph><list type='bullet'><listitem>1960s<space/><link><target>General Mills</target></link><space/>and<space/><link><target>Dartmouth College</target></link>, in a joint research project, develop the terms<space/><italics>dimensions</italics><space/>and<space/><italics>facts</italics>.<extension extension_name='ref' name="kimball16">Kimball 2002, pg. 16</extension></listitem><listitem>1970s<space/><link><target>ACNielsen</target></link><space/>and IRI provide dimensional data marts for retail sales.<extension extension_name='ref' name="kimball16"></extension></listitem><listitem>1970s<space/><link><target>Bill Inmon</target></link><space/>begins to define and discuss the term: Data Warehouse.<template><target>citation needed</target><arg name="date">June 2014</arg></template></listitem><listitem>1975<space/><link><target>Sperry Univac</target></link><space/>introduces<space/><link><target>MAPPER</target></link><space/>(MAintain, Prepare, and Produce Executive Reports) is a database management and reporting system that includes the world's first<space/><link><target>Fourth-generation programming language</target><part>4GL</part></link>. First platform designed for building Information Centers (a forerunner of contemporary Enterprise<space/><link><target>Data Warehousing</target></link><space/>platforms)</listitem><listitem>1983<space/><link><target>Teradata</target></link><space/>introduces a database management system specifically designed for decision support.</listitem><listitem>1983<space/><link><target>Sperry Corporation</target></link><space/><link><target>Martyn Richard Jones</target></link><space/><extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.martynjones.eu</arg><arg name="title">Jones, Martyn Richard<space/></arg><arg name="publisher">martynjones.eu<space/></arg><arg name="date"><space/></arg><arg name="accessdate">2014-10-01</arg></template></extension><space/>defines the Sperry Information Center approach, which while not being a true DW in the Inmon sense, did contain many of the characteristics of DW structures and process as defined previously by Inmon, and later by Devlin. First used at the<space/><link><target>Trustee Savings Bank</target><part>TSB England &amp; Wales</part></link><space/>A subset of this work found its way into the much later papers of Devlin and Murphy.</listitem><listitem>1984<space/><link><target>Metaphor Computer Systems</target></link>, founded by<space/><link><target>David Liddle</target></link><space/>and Don Massaro, releases Data Interpretation System (DIS). DIS was a hardware/software package and GUI for business users to create a database management and analytic system.</listitem><listitem>1988 Barry Devlin and Paul Murphy publish the article<space/><italics>An architecture for a business and information system</italics><space/>where they introduce the term &quot;business data warehouse&quot;.<extension extension_name='ref'><template><target>cite journal</target><arg name="url">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp</arg><arg name="title">An architecture for a business and information system</arg><arg name="journal">IBM Systems Journal</arg></template></extension></listitem><listitem>1990 Red Brick Systems, founded by<space/><link><target>Ralph Kimball</target></link>, introduces Red Brick Warehouse, a database management system specifically for data warehousing.</listitem><listitem>1991 Prism Solutions, founded by<space/><link><target>Bill Inmon</target></link>, introduces Prism Warehouse Manager, software for developing a data warehouse.</listitem><listitem>1992<space/><link><target>Bill Inmon</target></link><space/>publishes the book<space/><italics>Building the Data Warehouse</italics>.<extension extension_name='ref'><template><target>cite book</target><arg name="last">Inmon</arg><arg name="first">Bill</arg><arg name="title">Building the Data Warehouse</arg><arg name="year">1992</arg><arg name="publisher">Wiley</arg><arg name="isbn">0-471-56960-7</arg></template></extension></listitem><listitem>1995 The Data Warehousing Institute, a for-profit organization that promotes data warehousing, is founded.</listitem><listitem>1996<space/><link><target>Ralph Kimball</target></link><space/>publishes the book<space/><italics>The Data Warehouse Toolkit</italics>.<extension extension_name='ref'><template><target>cite book</target><arg name="last">Kimball</arg><arg name="first">Ralph</arg><arg name="title">The Data Warehouse Toolkit</arg><arg name="year">1996</arg><arg name="publisher">Wiley</arg><arg name="isbn">0-471-15337-0</arg></template></extension></listitem><listitem>2000<space/><link><target>Daniel Linstedt</target></link><space/>releases the<space/><italics>Data Vault</italics>, enabling real time auditable Data Warehouses warehouse.</listitem><listitem>2012<space/><link><target>Bill Inmon</target></link><space/>developed and made public technology known as textual disambiguation. Textual disambiguation applies context to raw text and reformats the raw text and context into a standard data base format. Once raw text is passed through textual disambiguation, it can easily and efficiently be accessed and analyzed by standard business intelligence technology. Textual disambiguation is accomplished through the execution of textual ETL. Textual disambiguation is useful wherever raw text is found, such as in documents, Hadoop, email, and so forth.</listitem></list><heading level='2'>Information storage</heading><heading level='3'>Facts</heading><paragraph>A fact is a value or measurement, which represents a fact about the managed entity or system.</paragraph><paragraph>Facts as reported by the reporting entity are said to be at raw level.E.g. if a BTS (Business Transformation Service) received 1,000 requests for traffic channel allocation, it allocates for 820 and rejects the remaining then it would report 3<space/><bold>facts</bold><space/>or measurements to a management system:</paragraph><list type='bullet'><listitem>tch_req_total = 1000</listitem><listitem>tch_req_success = 820</listitem><listitem>tch_req_fail = 180</listitem></list><paragraph>Facts at raw level are further aggregated to higher levels in various<space/><link><target>Dimension (data warehouse)</target><part>dimensions</part></link><space/>to extract more service or business-relevant information out of it. These are called aggregates or summaries or aggregated facts.</paragraph><paragraph>E.g. if there are 3 BTSs in a city, then facts above can be aggregated from BTS to city level in network dimension.E.g.</paragraph><list type='bullet'><listitem><extension extension_name='math'>tch\_req\_success\_city = tch\_req\_success\_bts1 + tch\_req\_success\_bts2 + tch\_req\_success\_bts3</extension></listitem><listitem><extension extension_name='math'>avg\_tch\_req\_success\_city = (tch\_req\_success\_bts1 + tch\_req\_success\_bts2 + tch\_req\_success\_bts3) / 3</extension></listitem></list><heading level='3'>Dimensional vs. normalized approach for storage of data</heading><paragraph>There are three or more leading approaches to storing data in a data warehouse&amp;nbsp; the most important approaches are the dimensional approach and the normalized approach.</paragraph><paragraph>The dimensional approach refers to<space/><link><target>Ralph Kimball</target></link>s approach in which it is stated that the data warehouse should be modeled using a Dimensional Model/<link><target>star schema</target></link>. The normalized approach, also called the<space/><link><target>Third normal form</target><part>3NF</part></link><space/>model (Third Normal Form) refers to Bill Inmon's approach in which it is stated that the data warehouse should be modeled using an E-R model/normalized model.</paragraph><paragraph>In a<space/><link><target>Star schema</target><part>dimensional approach</part></link>,<space/><link><target>transaction data</target></link><space/>are partitioned into &quot;facts&quot;, which are generally numeric transaction data, and &quot;<link><target>dimension (data warehouse)</target><part>dimensions</part></link>&quot;, which are the reference information that gives context to the facts. For example, a sales transaction can be broken up into facts such as the number of products ordered and the price paid for the products, and into dimensions such as order date, customer name, product number, order ship-to and bill-to locations, and salesperson responsible for receiving the order.</paragraph><paragraph>A key advantage of a dimensional approach is that the data warehouse is easier for the user to understand and to use. Also, the retrieval of data from the data warehouse tends to operate very quickly.<template><target>Citation needed</target><arg name="date">November 2013</arg></template><space/>Dimensional structures are easy to understand for business users, because the structure is divided into measurements/facts and context/dimensions. Facts are related to the organizations business processes and operational system whereas the dimensions surrounding them contain context about the measurement (Kimball, Ralph 2008).</paragraph><paragraph>The main disadvantages of the dimensional approach are the following:</paragraph><list type='numbered'><listitem>In order to maintain the integrity of facts and dimensions, loading the data warehouse with data from different operational systems is complicated.</listitem><listitem>It is difficult to modify the data warehouse structure if the organization adopting the dimensional approach changes the way in which it does business.</listitem></list><paragraph>In the normalized approach, the data in the data warehouse are stored following, to a degree,<space/><link><target>database normalization</target></link><space/>rules. Tables are grouped together by<space/><italics>subject areas</italics><space/>that reflect general data categories (e.g., data on customers, products, finance, etc.). The normalized structure divides data into entities, which creates several tables in a relational database. When applied in large enterprises the result is dozens of tables that are linked together by a web of joins. Furthermore, each of the created entities is converted into separate physical tables when the database is implemented (Kimball, Ralph 2008)<template><target>Citation needed</target><arg name="date">November 2013</arg></template>.The main advantage of this approach is that it is straightforward to add information into the database. Some disadvantages of this approach are that, because of the number of tables involved, it can be difficult for users to join data from different sources into meaningful information and to access the information without a precise understanding of the sources of data and of the<space/><link><target>data structure</target></link><space/>of the data warehouse.</paragraph><paragraph>Both normalized and dimensional models can be represented in entity-relationship diagrams as both contain joined relational tables. The difference between the two models is the degree of normalization (also known as<space/><link><target>Database normalization#Normal forms</target><part>Normal Forms</part></link>). These approaches are not mutually exclusive, and there are other approaches. Dimensional approaches can involve normalizing data to a degree (Kimball, Ralph 2008).</paragraph><paragraph>In<space/><italics>Information-Driven Business</italics>,<extension extension_name='ref'><template><target>cite book</target><arg name="last">Hillard</arg><arg name="first">Robert</arg><arg name="title">Information-Driven Business</arg><arg name="year">2010</arg><arg name="publisher">Wiley</arg><arg name="isbn">978-0-470-62577-4</arg></template></extension><space/>Robert Hillard proposes an approach to comparing the two approaches based on the information needs of the business problem. The technique shows that normalized models hold far more information than their dimensional equivalents (even when the same fields are used in both models) but this extra information comes at the cost of usability. The technique measures information quantity in terms of<space/><link><target>Entropy (information theory)</target><part>information entropy</part></link><space/>and usability in terms of the Small Worlds data transformation measure.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://mike2.openmethodology.org/wiki/Small_Worlds_Data_Transformation_Measure<space/></arg><arg name="title">Information Theory & Business Intelligence Strategy - Small Worlds Data Transformation Measure - MIKE2.0, the open source methodology for Information Development<space/></arg><arg name="publisher">Mike2.openmethodology.org<space/></arg><arg name="date"><space/></arg><arg name="accessdate">2013-06-14</arg></template></extension></paragraph><heading level='2'>Design methodologies</heading><paragraph><template><target>more references</target><arg>section</arg><arg name="date">July 2015</arg></template></paragraph><heading level='3'>Bottom-up design</heading><paragraph>In the<space/><italics>bottom-up</italics><space/>approach,<space/><link><target>data mart</target><trail>s</trail></link><space/>are first created to provide reporting and analytical capabilities for specific<space/><link><target>business process</target><trail>es</trail></link>. These data marts can then be integrated to create a comprehensive data warehouse. The data warehouse bus architecture is primarily an implementation of &quot;the bus&quot;, a collection of<space/><link><target>Dimension (data warehouse)#Types</target><part>conformed dimension</part><trail>s</trail></link><space/>and<space/><link><target>Facts (data warehouse)#Types</target><part>conformed fact</part><trail>s</trail></link>, which are dimensions that are shared (in a specific way) between facts in two or more data marts.</paragraph><heading level='3'>Top-down design</heading><paragraph>The<space/><italics>top-down</italics><space/>approach is designed using a normalized enterprise<space/><link><target>data model</target></link>.<space/><link><target>Data element</target><part>&quot;Atomic&quot; data</part></link>, that is, data at the lowest level of detail, are stored in the data warehouse. Dimensional data marts containing data needed for specific business processes or specific departments are created from the data warehouse.<extension extension_name='ref' name="ReferenceA">Gartner, Of Data Warehouses, Operational Data Stores, Data Marts and Data Outhouses, Dec 2005</extension></paragraph><heading level='3'>Hybrid design</heading><paragraph>Data warehouses (DW) often resemble the<space/><link><target>hub and spokes architecture</target></link>.<space/><link><target>Legacy system</target><trail>s</trail></link><space/>feeding the warehouse often include<space/><link><target>customer relationship management</target></link><space/>and<space/><link><target>enterprise resource planning</target></link>, generating large amounts of data. To consolidate these various data models, and facilitate the<space/><link><target>extract transform load</target></link><space/>process, data warehouses often make use of an<space/><link><target>operational data store</target></link>, the information from which is parsed into the actual DW. To reduce data redundancy, larger systems often store the data in a normalized way. Data marts for specific reports can then be built on top of the DW.</paragraph><paragraph>The DW database in a hybrid solution is kept on<space/><link><target>third normal form</target></link><space/>to eliminate<space/><link><target>data redundancy</target></link>. A normal relational database, however, is not efficient for business intelligence reports where dimensional modelling is prevalent. Small data marts can shop for data from the consolidated warehouse and use the filtered, specific data for the fact tables and dimensions required. The DW provides a single source of information from which the data marts can read, providing a wide range of business information. The hybrid architecture allows a DW to be replaced with a<space/><link><target>master data management</target></link><space/>solution where operational, not static information could reside.</paragraph><paragraph>The<space/><link><target>Data Vault Modeling</target></link><space/>components follow hub and spokes architecture. This modeling style is a hybrid design, consisting of the best practices from both third normal form and<space/><link><target>star schema</target></link>. The Data Vault model is not a true third normal form, and breaks some of its rules, but it is a top-down architecture with a bottom up design. The Data Vault model is geared to be strictly a data warehouse. It is not geared to be end-user accessible, which when built, still requires the use of a data mart or star schema based release area for business purposes.</paragraph><heading level='2'>Data warehouses versus operational systems</heading><paragraph>Operational systems are optimized for preservation of<space/><link><target>data integrity</target></link><space/>and speed of recording of business transactions through use of<space/><link><target>database normalization</target></link><space/>and an<space/><link><target>entity-relationship model</target></link>. Operational system designers generally follow the<space/><link><target>Codd's 12 rules</target><part>Codd rules</part></link><space/>of<space/><link><target>database normalization</target></link><space/>in order to ensure data integrity. Codd defined five increasingly stringent rules of normalization. Fully normalized database designs (that is, those satisfying all five Codd rules) often result in information from a business transaction being stored in dozens to hundreds of tables.<space/><link><target>Relational database</target><trail>s</trail></link><space/>are efficient at managing the relationships between these tables. The databases have very fast insert/update performance because only a small amount of data in those tables is affected each time a transaction is processed. Finally, in order to improve performance, older data are usually periodically purged from operational systems.</paragraph><paragraph>Data warehouses are optimized for analytic access patterns. Analytic access patterns generally involve selecting specific fields and rarely if ever 'select *' as is more common in operational databases. Because of these differences in access patterns, operational databases (loosely, OLTP) benefit from the use of a row-oriented DBMS whereas analytics databases (loosely, OLAP) benefit from the use of a column-oriented DBMS. Unlike operational systems which maintain a snapshot of the business, data warehouses generally maintain an infinite history which is implemented through ETL processes that periodically migrate data from the operational systems over to the data warehouse.</paragraph><heading level='2'>Evolution in organization use</heading><paragraph>These terms refer to the level of sophistication of a data warehouse:</paragraph><list type='def'><listitem><defkey>Offline operational data warehouse</defkey><defval><space/>Data warehouses in this stage of evolution are updated on a regular time cycle (usually daily, weekly or monthly) from the operational systems and the data is stored in an integrated reporting-oriented data</defval></listitem><listitem><defkey>Offline data warehouse</defkey><defval><space/>Data warehouses at this stage are updated from data in the operational systems on a regular basis and the data warehouse data are stored in a data structure designed to facilitate reporting.</defval></listitem><listitem><defkey>On time data warehouse</defkey><defval><space/>Online Integrated Data Warehousing represent the real time Data warehouses stage data in the warehouse is updated for every transaction performed on the source data</defval></listitem><listitem><defkey>Integrated data warehouse</defkey><defval><space/>These data warehouses assemble data from different areas of business, so users can look up the information they need across other systems.<extension extension_name='ref'><template><target>cite web</target><arg name="url">http://www.tech-faq.com/data-warehouse.html<space/></arg><arg name="title">Data Warehouse<space/></arg></template></extension></defval></listitem></list><heading level='2'>See also</heading><paragraph><template><target>colbegin</target><arg>3</arg></template></paragraph><list type='bullet'><listitem><link><target>Accounting intelligence</target></link></listitem><listitem><link><target>Anchor Modeling</target></link></listitem><listitem><link><target>Business intelligence</target></link></listitem><listitem><link><target>Business intelligence tools</target></link></listitem><listitem><link><target>Data integration</target></link></listitem><listitem><link><target>Data mart</target></link></listitem><listitem><link><target>Data mining</target></link></listitem><listitem><link><target>Data presentation architecture</target></link></listitem><listitem><link><target>Data scraping</target></link></listitem><listitem><link><target>Data warehouse appliance</target></link></listitem><listitem><link><target>Database management system</target></link></listitem><listitem><link><target>Decision support system</target></link></listitem><listitem><link><target>Data Vault Modeling</target></link></listitem><listitem><link><target>Executive information system</target></link></listitem><listitem><link><target>Extract, transform, load</target></link></listitem><listitem><link><target>Master data management</target></link></listitem><listitem><link><target>Online analytical processing</target></link></listitem><listitem><link><target>Online transaction processing</target></link></listitem><listitem><link><target>Operational data store</target></link></listitem><listitem><link><target>Semantic warehousing</target></link></listitem><listitem><link><target>Snowflake schema</target></link></listitem><listitem><link><target>Software as a service</target></link></listitem><listitem><link><target>Star schema</target></link></listitem><listitem><link><target>Slowly changing dimension</target></link></listitem></list><paragraph><template><target>colend</target></template></paragraph><heading level='2'>References</heading><paragraph><template><target>Reflist</target><arg>
</arg></template></paragraph><heading level='2'>Further reading</heading><list type='bullet'><listitem>Davenport, Thomas H. and Harris, Jeanne G.<space/><italics>Competing on Analytics: The New Science of Winning</italics><space/>(2007) Harvard Business School Press. ISBN 978-1-4221-0332-6</listitem><listitem>Ganczarski, Joe.<space/><italics>Data Warehouse Implementations: Critical Implementation Factors Study</italics><space/>(2009)<space/><link><target>VDM Verlag</target></link><space/>ISBN 3-639-18589-7 ISBN 978-3-639-18589-8</listitem><listitem>Kimball, Ralph and Ross, Margy.<space/><italics>The Data Warehouse Toolkit</italics><space/>Second Edition (2002) John Wiley and Sons, Inc. ISBN 0-471-20024-7</listitem><listitem>Linstedt, Graziano, Hultgren.<space/><italics>The Business of Data Vault Modeling</italics><space/>Second Edition (2010) Dan linstedt, ISBN 978-1-4357-1914-9</listitem><listitem>William Inmon.<space/><italics>Building the Data Warehouse</italics><space/>(2005) John Wiley and Sons, ISBN 978-8-1265-0645-3</listitem></list><heading level='2'>External links</heading><list type='bullet'><listitem><link type='external' href='http://www.kimballgroup.com/html/articles.html'>Ralph Kimball articles</link></listitem><listitem><link type='external' href='http://www.ijcaonline.org/archives/number3/77-172'>International Journal of Computer Applications</link></listitem><listitem><link type='external' href='http://dwreview.com/DW_Overview.html'>Data Warehouse Introduction</link></listitem><listitem><link type='external' href='http://www.garp.org/risk-news-and-resources/2013/june/time-to-reconsider-the-data-warehouse.aspx?'>Time to Reconsider the Data Warehouse (Global Association of Risk Professionals)</link></listitem></list><paragraph><template><target>Data warehouse</target></template></paragraph><paragraph><template><target>Authority control</target></template></paragraph><paragraph><template><target>DEFAULTSORT:Data Warehouse</target></template><link><target>Category:Business intelligence</target></link><link><target>Category:Data management</target></link><link><target>Category:Data warehousing</target><part></part></link><link><target>Category:Information technology management</target></link></paragraph></article>