<article title='Design_of_experiments'><paragraph><template><target>for</target><arg>the book</arg><arg>The Design of Experiments</arg></template><template><target>refimprove</target><arg name="date">September 2015</arg></template><template><target>original research</target><arg name="date">September 2015</arg></template></paragraph><paragraph><template><target>Use dmy dates</target><arg name="date">July 2013</arg></template><link><target>File:Response surface metodology.jpg</target><part>thumb</part><part>Design of experiments with full<space/><link><target>factorial design</target></link><space/>(left),<space/><link><target>response surface</target></link><space/>with second-degree polynomial (right)</part></link></paragraph><paragraph>The<space/><bold>design of experiments</bold><space/>(or<space/><bold>experimental design</bold>) is the design of any task that aims to describe or explain the variation of information under conditions that are hypothesized to reflect the variation. The term is generally associated with true<space/><link><target>experiments</target></link><space/>in which the design introduces conditions that directly affect the variation, but may also refer to the design of<space/><link><target>quasi-experiment</target><trail>s</trail></link>, in which<space/><link><target>naturalistic observation</target><part>natural</part></link><space/>conditions that influence the variation are selected for observation.</paragraph><paragraph>In its simplest form, an experiment aims at predicting the outcome by introducing a change of the preconditions, which is reflected in a variable called the<space/><link><target>Dependent_and_independent_variables</target><part>predictor</part></link>. The change in the predictor is generally hypothesized to result in a change in the second variable, hence called the<space/><link><target>Dependent_and_independent_variables</target><part>outcome</part></link><space/>variable. Experimental design involves not only the selection of suitable predictors and outcomes, but planning the delivery of the experiment under statistically optimal conditions given the constraints of available resources.</paragraph><paragraph>Main concerns in experimental design include the establishment of<space/><link><target>Validity_(statistics)</target><part>validity</part></link>, reliability, and<space/><link><target>Reproducibility</target><part>replicability</part></link>. For example, these concerns can be partially addressed by carefully choosing the predictor, reducing the risk of measurement error, and ensuring that the documentation of the method is sufficiently detailed. Related concerns include achieving appropriate levels of<space/><link><target>statistical power</target></link><space/>and<space/><link><target>Sensitivity_and_specificity</target><part>sensitivity</part></link>.</paragraph><paragraph>Correctly designed experiments advance knowledge in the natural and social sciences and engineering. Other applications include marketing and policy making.</paragraph><heading level='2'>History</heading><heading level='3'>Systematic clinical trials</heading><paragraph><template><target>original research</target><arg>section</arg><arg name="date">September 2015</arg></template><template><target>primary sources</target><arg>section</arg><arg name="date">September 2015</arg></template>In 1747, while serving as surgeon on<space/><link><target>HMS Salisbury (1746)</target><part>HMS ''Salisbury''</part></link>,<space/><link><target>James Lind (physician)</target><part>James Lind</part></link><space/>carried out a systematic clinical trial to compare remedies for<space/><link><target>scurvy</target></link>.<extension extension_name='ref' name="ADC1997"><template><target>Cite journal</target><arg name="last">Dunn<space/></arg><arg name="first">Peter<space/></arg><arg name="title">James Lind (1716-94) of Edinburgh and the treatment of scurvy<space/></arg><arg name="journal">Archive of Disease in Childhood Foetal Neonatal<space/></arg><arg name="volume">76<space/></arg><arg name="issue"><space/>1</arg><arg name="pages">64–65<space/></arg><arg name="publisher">British Medical Journal Publishing Group<space/></arg><arg name="location">United Kingdom<space/></arg><arg name="date"><space/>January 1997</arg><arg name="url">http://fn.bmj.com/cgi/content/full/76/1/F64<space/></arg><arg name="doi"><space/>10.1136/fn.76.1.F64</arg><arg name="pmc">1720613<space/></arg><arg name="accessdate">2009-01-17<space/></arg><arg name="pmid">9059193</arg></template></extension><space/>This systematic clinical trial constitutes a type of DOE.<template><target>cn</target><arg name="date">September 2015</arg></template><template><target>dubious</target><arg name="date">September 2015</arg></template></paragraph><paragraph>Lind selected 12 men from the ship, all suffering from scurvy. Lind limited his subjects to men who &quot;were as similar as I could have them&quot;, that is he provided strict entry requirements to reduce extraneous variation. He divided them into six pairs, giving each pair different supplements to their basic diet for two weeks. The treatments were all remedies that had been proposed:</paragraph><list type='bullet'><listitem>A quart of cider every day.</listitem><listitem>Twenty five gutts (drops) of<space/><link><target>vitriol</target></link><space/>(sulphuric acid) three times a day upon an empty stomach.</listitem><listitem>One half-pint of seawater every day.</listitem><listitem>A mixture of garlic, mustard, and horseradish in a lump the size of a nutmeg.</listitem><listitem>Two spoonfuls of vinegar three times a day.</listitem><listitem>Two oranges and one lemon every day.</listitem></list><paragraph>The citrus treatment stopped after six days when they ran out of fruit, but by that time one sailor was fit for duty while the other had almost recovered. Apart from that, only group one (cider) showed some effect of its treatment. The remainder of the crew presumably served as a control, but Lind did not report results from any control (untreated) group.</paragraph><heading level='3'>Statistical experiments, following Charles S. Peirce</heading><paragraph><template><target>Main</target><arg>Frequentist statistics</arg></template><template><target>See also</target><arg>Randomization</arg></template>A theory of statistical inference was developed by<space/><link><target>Charles Sanders Peirce</target><part>Charles S. Peirce</part></link><space/>in &quot;<link><target>Charles Sanders Peirce bibliography#illus</target><part>Illustrations of the Logic of Science</part></link>&quot; (18771878) and &quot;<link><target>Charles Sanders Peirce bibliography#SIL</target><part>A Theory of Probable Inference</part></link>&quot; (1883), two publications that emphasized the importance of randomization-based inference in statistics.</paragraph><heading level='4'>Randomized experiments</heading><paragraph><template><target>Main</target><arg>Random assignment</arg></template><template><target>See also</target><arg>Repeated measures design</arg></template>Charles S. Peirce randomly assigned volunteers to a<space/><link><target>blinding (medicine)</target><part>blinded</part></link>,<space/><link><target>repeated measures design</target><part>repeated-measures design</part></link><space/>to evaluate their ability to discriminate weights.<extension extension_name='ref' name="smalldiff"><template><target>Cite journal</target><arg name="last1"><space/>Peirce</arg><arg name="first1">Charles Sanders</arg><arg name="last2">Jastrow</arg><arg name="first2">Joseph<space/></arg><arg name="authorlink1">Charles Sanders Peirce</arg><arg name="authorlink2">Joseph Jastrow</arg><arg name="year">1885</arg><arg name="title">On Small Differences in Sensation</arg><arg name="url">http://psychclassics.yorku.ca/Peirce/small-diffs.htm</arg><arg name="journal">Memoirs of the National Academy of Sciences</arg><arg name="volume">3</arg><arg name="pages">73–83</arg></template></extension><extension extension_name='ref' name="telepathy"><template><target>Cite journal</target><arg name="first">Ian<space/></arg><arg name="last">Hacking</arg><arg name="authorlink">Ian Hacking<space/></arg><arg name="title">Telepathy: Origins of Randomization in Experimental Design</arg><arg name="journal">[[Isis (journal)|Isis]]</arg><arg name="issue">3</arg><arg name="volume">79</arg><arg name="date">September 1988<space/></arg><arg name="pages">427–451</arg><arg name="jstor">234674</arg><arg name="mr">1013489<space/></arg><arg name="doi">10.1086/354775</arg></template></extension><extension extension_name='ref' name="stigler"><template><target>Cite journal</target><arg name="author">[[Stephen M. Stigler]]</arg><arg name="title">A Historical View of Statistical Concepts in Psychology and Educational Research</arg><arg name="journal">American Journal of Education</arg><arg name="volume">101</arg><arg name="issue">1</arg><arg name="date">November 1992</arg><arg name="pages">60–70</arg><arg name="jstor">1085417</arg><arg name="doi">10.1086/444032
</arg></template></extension><extension extension_name='ref' name="dehue"><template><target>Cite journal</target><arg name="author">Trudy Dehue</arg><arg name="title">Deception, Efficiency, and Random Groups: Psychology and the Gradual Origination of the Random Group Design</arg><arg name="journal">[[Isis (journal)|Isis]]</arg><arg name="volume">88</arg><arg name="issue">4</arg><arg name="date">December 1997</arg><arg name="pages">653–673</arg><arg name="doi">10.1086/383850</arg><arg name="pmid">9519574</arg></template></extension>Peirce's experiment inspired other researchers in psychology and education, which developed a research tradition of randomized experiments in laboratories and specialized textbooks in the 1800s.<extension extension_name='ref' name="smalldiff"></extension><extension extension_name='ref' name="telepathy"></extension><extension extension_name='ref' name="stigler"></extension><extension extension_name='ref' name="dehue"></extension></paragraph><heading level='4'>Optimal designs for regression models</heading><paragraph><template><target>Main</target><arg>Response surface methodology</arg></template><template><target>See also</target><arg>Optimal design</arg></template><link><target>Charles Sanders Peirce</target><part>Charles S. Peirce</part></link><space/>also contributed the first English-language publication on an<space/><link><target>optimal design</target></link><space/>for<space/><link><target>Regression analysis</target><part>regression</part></link><space/><link><target>statistical model</target><part>models</part></link><space/>in 1876.<extension extension_name='ref'><template><target>cite journal</target><arg name="author">[[Charles Sanders Peirce|Peirce, C. S.]]<space/></arg><arg name="year">1876</arg><arg name="title">Note on the Theory of the Economy of Research<space/></arg><arg name="journal">Coast Survey Report<space/></arg><arg name="pages">197–201</arg></template>, actually published 1879, NOAA<space/><link type='external' href='http://docs.lib.noaa.gov/rescue/cgs/001_pdf/CSC-0025.PDF#page=222'>PDF Eprint</link>.<xhtml:br></xhtml:br><space/>Reprinted in<space/><italics><link><target>Charles Sanders Peirce bibliography#CP</target><part>Collected Papers</part></link></italics><space/><bold>7</bold>, paragraphs 139157, also in<space/><italics><link><target>Charles Sanders Peirce bibliography#W</target><part>Writings</part></link></italics><space/><bold>4</bold>, pp. 7278, and in<space/><template><target>cite journal</target><arg name="author">[[Charles Sanders Peirce|Peirce, C.&nbsp;S.]]<space/></arg><arg name="date">July–August 1967
</arg><arg name="title">Note on the Theory of the Economy of Research
</arg><arg name="journal">Operations Research
</arg><arg name="volume">15<space/></arg><arg name="issue">4</arg><arg name="pages">643–648
</arg><arg name="jstor">168276</arg><arg name="doi">10.1287/opre.15.4.643
</arg></template></extension><space/>A pioneering<space/><link><target>optimal design</target></link><space/>for<space/><link><target>polynomial regression</target></link><space/>was suggested by<space/><link><target>Joseph Diaz Gergonne</target><part>Gergonne</part></link><space/>in 1815. In 1918<space/><link><target>Kirstine Smith</target></link><space/>published optimal designs for polynomials of degree six (and less).</paragraph><heading level='3'>Sequences of experiments</heading><paragraph><template><target>Main</target><arg>Sequential analysis</arg></template><template><target>See also</target><arg>Multi-armed bandit problem</arg><arg>Gittins index</arg><arg>Optimal design</arg></template>The use of a sequence of experiments, where the design of each may depend on the results of previous experiments, including the possible decision to stop experimenting, is within the scope of<space/><link><target>Sequential analysis</target></link>, a field that was pioneered<extension extension_name='ref'>Johnson, N.L. (1961). &quot;Sequential analysis: a survey.&quot;<space/><italics><link><target>Journal of the Royal Statistical Society</target></link></italics>, Series A. Vol. 124 (3), 372&amp;ndash;411. (pages 375&amp;ndash;376)</extension><space/>by<space/><link><target>Abraham Wald</target></link><space/>in the context of sequential tests of statistical hypotheses.<extension extension_name='ref'>Wald, A. (1945) &quot;Sequential Tests of Statistical Hypotheses&quot;,<space/><link><target>Annals of Mathematical Statistics</target></link>, 16 (2), 117&amp;ndash;186.</extension><space/><link><target>Herman Chernoff</target></link><space/>wrote an overview of optimal sequential designs,<extension extension_name='ref' name="ref3"></extension><space/>while<space/><link><target>Minimisation (clinical trials)</target><part>adaptive designs</part></link><space/>have been surveyed by S. Zacks.<extension extension_name='ref'>Zacks, S. (1996) &quot;Adaptive Designs for Parametric Models&quot;. In: Ghosh, S. and Rao, C. R., (Eds) (1996). &quot;Design and Analysis of Experiments,&quot;<space/><italics>Handbook of Statistics</italics>, Volume 13. North-Holland. ISBN 0-444-82061-2. (pages 151&amp;ndash;180)</extension><space/>One specific type of sequential design is the &quot;two-armed bandit&quot;, generalized to the<space/><link><target>multi-armed bandit</target></link>, on which early work was done by<space/><link><target>Herbert Robbins</target></link><space/>in 1952.<extension extension_name='ref'><template><target>cite journal</target><arg name="doi"><space/>10.1090/S0002-9904-1952-09620-8<space/></arg><arg name="last1"><space/>Robbins<space/></arg><arg name="first1"><space/>H.<space/></arg><arg name="year"><space/>1952<space/></arg><arg name="title"><space/>Some Aspects of the Sequential Design of Experiments<space/></arg><arg name="url"><space/></arg><arg name="journal"><space/>Bulletin of the American Mathematical Society<space/></arg><arg name="volume"><space/>58<space/></arg><arg name="issue"><space/>5</arg><arg name="pages"><space/>527–535<space/></arg></template></extension></paragraph><heading level='2'>Fisher's principles</heading><paragraph><link><target>File:Biologist and statistician Ronald Fisher.jpg</target><part>thumb</part><part>right</part><part>199px</part><part>Ronald Fisher</part></link>A methodology for designing experiments was proposed by<space/><link><target>Ronald Fisher</target></link>, in his innovative books:<space/><italics>The Arrangement of Field Experiments</italics><space/>(1926) and<space/><italics><link><target>The Design of Experiments</target></link></italics><space/>(1935). Much of his pioneering work dealt with agricultural applications of statistical methods. As a mundane example, he described how to test the<space/><link><target>lady tasting tea</target></link><space/><link><target>hypothesis</target></link>, that a certain lady could distinguish by flavour alone whether the milk or the tea was first placed in the cup. These methods have been broadly adapted in the physical and social sciences, are still used in<space/><link><target>agricultural engineering</target></link><space/>and differ from the design and analysis of<space/><link><target>computer experiment</target><trail>s</trail></link>.</paragraph><list type='def'><listitem><defkey>Comparison</defkey></listitem></list><list type='ident'><listitem>In some fields of study it is not possible to have independent measurements to a traceable<space/><link><target>Standard (metrology)</target><part>metrology standard</part></link>. Comparisons between treatments are much more valuable and are usually preferable, and often compared against a<space/><link><target>scientific control</target></link><space/>or traditional treatment that acts as baseline.</listitem></list><list type='def'><listitem><defkey><link><target>Randomization</target></link></defkey></listitem></list><list type='ident'><listitem>Random assignment is the process of assigning individuals at random to groups or to different groups in an experiment. The random assignment of individuals to groups (or conditions within a group) distinguishes a rigorous, &quot;true&quot; experiment from an observational study or &quot;quasi-experiment&quot;.<extension extension_name='ref'>Creswell, J.W. (2008). Educational research: Planning, conducting, and evaluating quantitative and qualitative research (3rd). Upper Saddle River, NJ: Prentice Hall. 2008, p. 300. ISBN 0-13-613550-1</extension><space/>There is an extensive body of mathematical theory that explores the consequences of making the allocation of units to treatments by means of some random mechanism such as tables of random numbers, or the use of randomization devices such as playing cards or dice. Assigning units to treatments at random tends to mitigate<space/><link><target>confounding</target></link>, which makes effects due to factors other than the treatment to appear to result from the treatment. The risks associated with random allocation (such as having a serious imbalance in a key characteristic between a treatment group and a control group) are calculable and hence can be managed down to an acceptable level by using enough experimental units. The results of an experiment can be generalized reliably from the experimental units to a larger<space/><link><target>statistical population</target></link><space/>of units only if the experimental units are a<space/><link><target>Sampling (statistics)</target><part>random sample</part></link><space/>from the larger population; the probable error of such an extrapolation depends on the sample size, among other things.<space/></listitem></list><list type='def'><listitem><defkey><link><target>Replication (statistics)</target><part>Statistical replication</part></link></defkey></listitem></list><list type='ident'><listitem>Measurements are usually subject to variation and<space/><link><target>measurement uncertainty</target></link>; thus they are repeated and full experiments are replicated to help identify the sources of variation, to better estimate the true effects of treatments, to further strengthen the experiment's reliability and validity, and to add to the existing knowledge of the topic.<extension extension_name='ref'><template><target>cite web</target><arg name="last">Dr. Hani</arg><arg name="title">Replication study</arg><arg name="url">http://www.experiment-resources.com/replication-study.html</arg><arg name="accessdate">27 October 2011</arg><arg name="year">2009</arg></template></extension><space/>However, certain conditions must be met before the replication of the experiment is commenced: the original research question has been published in a<space/><link><target>peer-review</target><trail>ed</trail></link><space/>journal or widely cited, the researcher is independent of the original experiment, the researcher must first try to replicate the original findings using the original data, and the write-up should state that the study conducted is a replication study that tried to follow the original study as strictly as possible.<extension extension_name='ref'><template><target>cite web</target><arg name="last">Burman</arg><arg name="first">Leonard E.</arg><arg name="title">A call for replication studies</arg><arg name="url">http://pfr.sagepub.com</arg><arg name="publisher">Public Finance Review</arg><arg name="accessdate">27 October 2011</arg><arg name="author2">Robert W. Reed<space/></arg><arg name="author3">James Alm<space/></arg><arg name="pages">787–793</arg><arg name="format">journal article</arg><arg name="doi">10.1177/1091142110385210</arg><arg name="year">2010</arg></template></extension></listitem></list><list type='def'><listitem><defkey><link><target>Blocking (statistics)</target><part>Blocking</part></link></defkey></listitem></list><list type='ident'><listitem>Blocking is the arrangement of experimental units into groups (blocks/lots) consisting of units that are similar to one another. Blocking reduces known but irrelevant sources of variation between units and thus allows greater precision in the estimation of the source of variation under study.</listitem></list><list type='def'><listitem><defkey><link><target>Orthogonality#Statistics.2C econometrics.2C and economics</target><part>Orthogonality</part></link></defkey></listitem></list><paragraph><link><target>File:Factorial Design.svg</target><part>thumb</part><part>Example of orthogonal factorial design</part></link></paragraph><list type='ident'><listitem>Orthogonality concerns the forms of comparison (contrasts) that can be legitimately and efficiently carried out. Contrasts can be represented by vectors and sets of orthogonal contrasts are uncorrelated and independently distributed if the data are normal. Because of this independence, each orthogonal treatment provides different information to the others. If there are<space/><italics>T</italics><space/>treatments and<space/><italics>T</italics><space/>1 orthogonal contrasts, all the information that can be captured from the experiment is obtainable from the set of contrasts.</listitem></list><list type='def'><listitem><defkey><link><target>Factorial experiment</target><trail>s</trail></link></defkey></listitem></list><list type='ident'><listitem>Use of factorial experiments instead of the one-factor-at-a-time method. These are efficient at evaluating the effects and possible<space/><link><target>Interaction (statistics)</target><part>interactions</part></link><space/>of several factors (independent variables). Analysis of<space/><link><target>experiment</target></link><space/>design is built on the foundation of the<space/><link><target>analysis of variance</target></link>, a collection of models that partition the observed variance into components, according to what factors the experiment must estimate or test.</listitem></list><heading level='2'>Example</heading><paragraph><link><target>File:Balance tabac 1850.JPG</target><part>right</part><part>240px</part></link>This example is attributed to<space/><link><target>Harold Hotelling</target></link>.<extension extension_name='ref' name="ref3"><link><target>Herman Chernoff</target></link>,<space/><italics>Sequential Analysis and Optimal Design</italics>,<space/><link><target>Society for Industrial and Applied Mathematics</target><part>SIAM</part></link><space/>Monograph, 1972.</extension><space/>It conveys some of the flavor of those aspects of the subject that involve combinatorial designs.</paragraph><paragraph>Weights of eight objects are measured using a<space/><link><target>pan balance</target></link><space/>and set of standard weights. Each weighing measures the weight difference between objects in the left pan vs. any objects in the right pan by adding calibrated weights to the lighter pan until the balance is in equilibrium. Each measurement has a<space/><link><target>errors and residuals in statistics</target><part>random error</part></link>. The average error is zero; the<space/><link><target>standard deviation</target><trail>s</trail></link><space/>of the<space/><link><target>probability distribution</target></link><space/>of the errors is the same number on different weighings; and errors on different weighings are<space/><link><target>statistical independence</target><part>independent</part></link>. Denote the true weights by</paragraph><list type='ident'><listitem><extension extension_name='math'>\theta_1, \dots, \theta_8.\,</extension></listitem></list><paragraph>We consider two different experiments:</paragraph><list type='numbered'><listitem>Weigh each object in one pan, with the other pan empty. Let<space/><italics>X</italics><xhtml:sub><italics>i</italics></xhtml:sub><space/>be the measured weight of the<space/><italics>i</italics>th object, for<space/><italics>i</italics><space/>= 1, ..., 8.</listitem><listitem>Do the eight weighings according to the following schedule and let<space/><italics>Y</italics><xhtml:sub><italics>i</italics></xhtml:sub><space/>be the measured difference for<space/><italics>i</italics><space/>= 1, ..., 8:</listitem></list><list type='ident'><listitem><list type='ident'><listitem><extension extension_name='math'>
\begin{matrix}
&amp; \mbox{left pan} &amp; \mbox{right pan} \\
\mbox{1st weighing:} &amp; 1\ 2\ 3\ 4\ 5\ 6\ 7\ 8 &amp; \text{(empty)} \\ 
\mbox{2nd:} &amp; 1\ 2\ 3\ 8\ &amp; 4\ 5\ 6\ 7 \\
\mbox{3rd:} &amp; 1\ 4\ 5\ 8\ &amp; 2\ 3\ 6\ 7 \\
\mbox{4th:} &amp; 1\ 6\ 7\ 8\ &amp; 2\ 3\ 4\ 5 \\
\mbox{5th:} &amp; 2\ 4\ 6\ 8\ &amp; 1\ 3\ 5\ 7 \\
\mbox{6th:} &amp; 2\ 5\ 7\ 8\ &amp; 1\ 3\ 4\ 6 \\
\mbox{7th:} &amp; 3\ 4\ 7\ 8\ &amp; 1\ 2\ 5\ 6 \\
\mbox{8th:} &amp; 3\ 5\ 6\ 8\ &amp; 1\ 2\ 4\ 7
\end{matrix}
</extension></listitem></list></listitem></list><list type='ident'><listitem>Then the estimated value of the weight &amp;theta;<xhtml:sub>1</xhtml:sub><space/>is</listitem></list><list type='ident'><listitem><list type='ident'><listitem><extension extension_name='math'>\widehat{\theta}_1 = \frac{Y_1 + Y_2 + Y_3 + Y_4 - Y_5 - Y_6 - Y_7 - Y_8}{8}.<space/></extension></listitem></list></listitem></list><list type='ident'><listitem>Similar estimates can be found for the weights of the other items. For example</listitem></list><list type='ident'><listitem><list type='ident'><listitem><extension extension_name='math'>\widehat{\theta}_2 = \frac{Y_1 + Y_2 - Y_3 - Y_4 + Y_5 + Y_6 - Y_7 - Y_8}{8}.</extension></listitem></list></listitem></list><paragraph>The question of design of experiments is: which experiment is better?</paragraph><paragraph>The variance of the estimate<space/><italics>X</italics><xhtml:sub>1</xhtml:sub><space/>of<space/><xhtml:sub>1</xhtml:sub><space/>is<space/><xhtml:sup>2</xhtml:sup><space/>if we use the first experiment. But if we use the second experiment, the variance of the estimate given above is<space/><xhtml:sup>2</xhtml:sup>/8. Thus the second experiment gives us 8 times as much precision for the estimate of a single item, and estimates all items simultaneously, with the same precision. What the second experiment achieves with eight would require 64 weighings if the items are weighed separately. However, note that the estimates for the items obtained in the second experiment have errors that correlate with each other.</paragraph><paragraph>Many problems of the design of experiments involve<space/><link><target>combinatorial design</target><trail>s</trail></link>, as in this example and others.<extension extension_name='ref' name="yout_Howt"><template><target>Cite web</target><arg name="title"><space/>How to Use Design of Experiments to Create Robust Designs With High Yield
</arg><arg name="author"><space/>Jack Sifri
</arg><arg name="work"><space/>youtube.com
</arg><arg name="date"><space/>8 December 2014
</arg><arg name="accessdate"><space/>2015-02-11
</arg><arg name="url"><space/>https://www.youtube.com/watch?v</arg><arg name="quote"><space/>
</arg></template></extension></paragraph><heading level='2'>Avoiding false positives</heading><paragraph><link><target>False positive</target></link><space/>conclusions, often resulting from the<space/><link><target>Publish or perish</target><part>pressure to publish</part></link><space/>or the author's own<space/><link><target>confirmation bias</target></link>, are an inherent hazard in many fields, and experimental designs with undisclosed degrees of freedom are a problem.<extension extension_name='ref'><template><target>cite journal</target><arg name="last"><space/>Simmons</arg><arg name="first"><space/>Joseph</arg><arg name="author2">Leif Nelson<space/></arg><arg name="author3">Uri Simonsohn<space/></arg><arg name="title"><space/>False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant</arg><arg name="journal"><space/>Psychological Science</arg><arg name="volume"><space/>22</arg><arg name="issue"><space/>11</arg><arg name="pages"><space/>1359–1366</arg><arg name="publisher"><space/>Association for Psychological Science</arg><arg name="location"><space/>Washington DC</arg><arg name="date"><space/>November 2011</arg><arg name="url"><space/>http://pss.sagepub.com/content/22/11/1359.full</arg><arg name="issn"><space/>0956-7976</arg><arg name="doi"><space/>10.1177/0956797611417632</arg><arg name="accessdate"><space/>29 January 2012</arg><arg name="pmid"><space/>22006061</arg></template></extension><space/>This can lead to conscious or unconscious &quot;<link><target>p-hacking</target></link>&quot;: trying multiple things until you get the desired result. It typically involves the manipulation - perhaps unconsciously - of the process of<space/><link><target>statistical analysis</target></link><space/>and the degrees of freedom until they return a figure below the p&lt;.05 level of statistical significance.<extension extension_name='ref'><template><target>cite news</target><arg name="url">http://www.kplu.org/post/science-trust-and-psychology-crisis
<space/></arg><arg name="title">Science, Trust And Psychology In Crisis<space/></arg><arg name="work">[[KPLU]]
<space/></arg><arg name="date">2014-06-02
<space/></arg><arg name="accessdate">2014-06-12<space/></arg></template></extension><extension extension_name='ref'><template><target>cite news</target><arg name="url">http://www.psmag.com/navigation/nature-and-technology/statistically-significant-studies-arent-necessarily-significant-82832/
<space/></arg><arg name="title">Why Statistically Significant Studies Can Be Insignificant
<space/></arg><arg name="work">Pacific Standard
<space/></arg><arg name="date">2014-06-04
<space/></arg><arg name="accessdate">2014-06-12<space/></arg></template></extension><space/>So the design of the experiment should include a clear statement proposing the analyses to be undertaken.</paragraph><paragraph>Clear and complete documentation of the experimental methodology is also important in order to support replication of results.<extension extension_name='ref'><template><target>cite news</target><arg name="url">http://www.theguardian.com/science/head-quarters/2014/jun/10/physics-envy-do-hard-sciences-hold-the-solution-to-the-replication-crisis-in-psychology
<space/></arg><arg name="title">Physics envy: Do ‘hard’ sciences hold the solution to the replication crisis in psychology?
<space/></arg><arg name="work">theguardian.com
<space/></arg><arg name="author">Chris Chambers
<space/></arg><arg name="date">2014-06-10
<space/></arg><arg name="accessdate">2014-06-12<space/></arg></template></extension></paragraph><heading level='2'>Discussion topics when setting up an experimental design</heading><paragraph>An experimental design or randomized clinical trial requires careful consideration of several factors before actually doing the experiment.<extension extension_name='ref'>Ader, Mellenberg &amp; Hand (2008) &quot;Advising on Research Methods: A consultant's companion&quot;</extension><space/>An experimental design is the laying out of a detailed experimental plan in advance of doing the experiment. Some of the following topics have already been discussed in the principles of experimental design section:</paragraph><list type='numbered'><listitem>How many factors does the design have? and are the levels of these factors fixed or random?</listitem><listitem>Are control conditions needed, and what should they be?</listitem><listitem>Manipulation checks; did the manipulation really work?</listitem><listitem>What are the background variables?</listitem><listitem>What is the sample size. How many units must be collected for the experiment to be generalisable and have enough<space/><link><target>Statistical power</target><part>power</part></link>?</listitem><listitem>What is the relevance of interactions between factors?</listitem><listitem>What is the influence of delayed effects of substantive factors on outcomes?</listitem><listitem>How do response shifts affect self-report measures?</listitem><listitem>How feasible is repeated administration of the same measurement instruments to the same units at different occasions, with a post-test and follow-up tests?</listitem><listitem>What about using a proxy pretest?</listitem><listitem>Are there lurking variables?</listitem><listitem>Should the client/patient, researcher or even the analyst of the data be blind to conditions?</listitem><listitem>What is the feasibility of subsequent application of different conditions to the same units?</listitem><listitem>How many of each control and noise factors should be taken into account?</listitem></list><heading level='2'>Statistical control</heading><paragraph>It is best that a process be in reasonable statistical control prior to conducting designed experiments. When this is not possible, proper blocking, replication, and randomization allow for the careful conduct of designed experiments.<extension extension_name='ref'>Bisgaard, S (2008) &quot;Must a Process be in Statistical Control before Conducting Designed Experiments?&quot;,<space/><italics>Quality Engineering</italics>, ASQ, 20 (2), pp 143 - 176</extension>To control for nuisance variables, researchers institute<space/><bold>control checks</bold><space/>as additional measures. Investigators should ensure that uncontrolled influences (e.g., source credibility perception) do not skew the findings of the study. A<space/><link><target>manipulation checks</target><part>manipulation check</part></link><space/>is one example of a control check. Manipulation checks allow investigators to isolate the chief variables to strengthen support that these variables are operating as planned.</paragraph><paragraph>One of the most important requirements of experimental research designs is the necessity of eliminating the effects of<space/><link><target>spurious relationship</target><part>spurious</part></link>, intervening, and<space/><link><target>antecedent variable</target><trail>s</trail></link>. In the most basic model, cause (X) leads to effect (Y). But there could be a third variable (Z) that influences (Y), and X might not be the true cause at all. Z is said to be a spurious variable and must be controlled for. The same is true for<space/><link><target>intervening variable</target><trail>s</trail></link><space/>(a variable in between the supposed cause (X) and the effect (Y)), and anteceding variables (a variable prior to the supposed cause (X) that is the true cause). When a third variable is involved and has not been controlled for, the relation is said to be a<space/><link><target>zero order (statistics)</target><part>zero order</part></link><template><target>disambiguation needed</target><arg name="date">August 2012</arg></template><space/>relationship. In most practical applications of experimental research designs there are several causes (X1, X2, X3). In most designs, only one of these causes is manipulated at a time.</paragraph><heading level='2'>Experimental designs after Fisher</heading><paragraph>Some efficient designs for estimating several main effects were found independently and in near succession by<space/><link><target>Raj Chandra Bose</target></link><space/>and K. Kishen in 1940 at the<space/><link><target>Indian Statistical Institute</target></link>, but remained little known until the<space/><link><target>Plackett-Burman design</target><trail>s</trail></link><space/>were published in<space/><italics><link><target>Biometrika</target></link></italics><space/>in 1946. About the same time,<space/><link><target>C. R. Rao</target></link><space/>introduced the concepts of<space/><link><target>orthogonal array</target><trail>s</trail></link><space/>as experimental designs. This concept played a central role in the development of<space/><link><target>Taguchi methods</target></link><space/>by<space/><link><target>Genichi Taguchi</target></link>, which took place during his visit to Indian Statistical Institute in early 1950s. His methods were successfully applied and adopted by Japanese and Indian industries and subsequently were also embraced by US industry albeit with some reservations.</paragraph><paragraph>In 1950,<space/><link><target>Gertrude Mary Cox</target></link><space/>and<space/><link><target>William Gemmell Cochran</target></link><space/>published the book<space/><italics>Experimental Designs,</italics><space/>which became the major reference work on the design of experiments for statisticians for years afterwards.</paragraph><paragraph>Developments of the theory of<space/><link><target>linear model</target><trail>s</trail></link><space/>have encompassed and surpassed the cases that concerned early writers. Today, the theory rests on advanced topics in<space/><link><target>linear algebra</target></link>,<space/><link><target>algebraic statistics</target><part>algebra</part></link><space/>and<space/><link><target>combinatorial design</target><part>combinatorics</part></link>.</paragraph><paragraph>As with other branches of statistics, experimental design is pursued using both<space/><link><target>frequentist statistics</target><part>frequentist</part></link><space/>and<space/><link><target>Bayesian experimental design</target><part>Bayesian</part></link><space/>approaches: In evaluating statistical procedures like experimental designs,<space/><link><target>frequentist statistics</target></link><space/>studies the<space/><link><target>sampling distribution</target></link><space/>while<space/><link><target>Bayesian statistics</target></link><space/>updates a<space/><link><target>Bayesian probability</target><part>probability distribution</part></link><space/>on the parameter space.</paragraph><paragraph>Some important contributors to the field of experimental designs are<space/><link><target>Charles Sanders Peirce</target><part>C. S. Peirce</part></link>,<space/><link><target>R. A. Fisher</target></link>,<space/><link><target>Frank Yates</target><part>F. Yates</part></link>,<space/><link><target>C. R. Rao</target></link>,<space/><link><target>R. C. Bose</target></link>,<space/><link><target>Jagdish N. Srivastava</target><part>J. N. Srivastava</part></link>,<space/><link><target>Shrikhande S. S.</target></link>,<space/><link><target>D. Raghavarao</target></link>,<space/><link><target>William G. Cochran</target><part>W. G. Cochran</part></link>,<space/><link><target>Oscar Kempthorne</target><part>O. Kempthorne</part></link>, W. T. Federer, V. V. Fedorov, A. S. Hedayat,<space/><link><target>John Nelder</target><part>J. A. Nelder</part></link>,<space/><link><target>Rosemary A. Bailey</target><part>R. A. Bailey</part></link>,<space/><link><target>Jack Kiefer (mathematician)</target><part>J. Kiefer</part></link>, W. J. Studden, A. Pzman, F. Pukelsheim,<space/><link><target>David R. Cox</target><part>D. R. Cox</part></link>, H. P. Wynn, A. C. Atkinson,<space/><link><target>G. E. P. Box</target></link><space/>and<space/><link><target>Genichi Taguchi</target><part>G. Taguchi</part></link>.<template><target>citation needed</target><arg name="date">November 2011</arg></template><space/>The textbooks of D. Montgomery and R. Myers have reached generations of students and practitioners.<extension extension_name='ref'><template><target>cite book</target><arg name="last"><space/>Montgomery<space/></arg><arg name="first"><space/>Douglas 
</arg><arg name="title"><space/>Design and analysis of experiments 
</arg><arg name="publisher"><space/>John Wiley & Sons, Inc<space/></arg><arg name="location"><space/>Hoboken, NJ
</arg><arg name="edition"><space/>8th 
</arg><arg name="year"><space/>2013<space/></arg><arg name="isbn"><space/>9781118146927<space/></arg></template></extension><extension extension_name='ref'><template><target>cite book</target><arg name="last1"><space/>Walpole<space/></arg><arg name="first1"><space/>Ronald E.
</arg><arg name="last2"><space/>Myers<space/></arg><arg name="first2"><space/>Raymond H. 
</arg><arg name="last3"><space/>Myers<space/></arg><arg name="first3"><space/>Sharon L.
</arg><arg name="last4"><space/>Ye<space/></arg><arg name="first4"><space/>Keying
</arg><arg name="title"><space/>Probability & statistics for engineers & scientists 
</arg><arg name="publisher"><space/>Pearson Prentice Hall<space/></arg><arg name="location"><space/>Upper Saddle River, NJ
</arg><arg name="edition"><space/>8 
</arg><arg name="year"><space/>2007<space/></arg><arg name="isbn"><space/>978-0131877115<space/></arg></template></extension><extension extension_name='ref'><template><target>cite book</target><arg name="last1"><space/>Myers<space/></arg><arg name="first1"><space/>Raymond H.
</arg><arg name="last2"><space/>Montgomery<space/></arg><arg name="first2"><space/>Douglas C.
</arg><arg name="last3"><space/>Vining<space/></arg><arg name="first3"><space/>G. Geoffrey
</arg><arg name="last4"><space/>Robinson<space/></arg><arg name="first4"><space/>Timothy J. 
</arg><arg name="title"><space/>Generalized linear models : with applications in engineering and the sciences 
</arg><arg name="publisher"><space/>Wiley<space/></arg><arg name="location"><space/>Hoboken, N.J
</arg><arg name="edition"><space/>2 
</arg><arg name="year"><space/>2010<space/></arg><arg name="isbn"><space/>978-0470454633<space/></arg></template></extension></paragraph><heading level='2'>Human participant experimental design constraints</heading><paragraph>Laws and ethical considerations preclude some carefully designed experiments with human subjects. Legal constraints are dependent on<space/><link><target>Human subject research</target><part>jurisdiction</part></link>. Constraints may involve<space/><link><target>institutional review board</target><trail>s</trail></link>,<space/><link><target>informed consent</target></link><space/>and<space/><link><target>confidentiality</target></link><space/>affecting both clinical (medical) trials and behavioral and social science experiments.<extension extension_name='ref'><template><target>cite book</target><arg name="last1"><space/>Moore<space/></arg><arg name="first1"><space/>David S. 
</arg><arg name="last2"><space/>Notz<space/></arg><arg name="first2"><space/>William I.
</arg><arg name="title"><space/>Statistics : concepts and controversies 
</arg><arg name="publisher"><space/>W.H. Freeman<space/></arg><arg name="location"><space/>New York<space/></arg><arg name="year"><space/>2006 
</arg><arg name="isbn"><space/>9780716786368<space/></arg><arg name="edition"><space/>6th
</arg><arg name="pages"><space/>Chapter 7: Data ethics</arg></template></extension>In the field of toxicology, for example, experimentation is performed on laboratory<space/><italics>animals</italics><space/>with the goal of defining safe exposure limits for<space/><italics>humans</italics>.<extension extension_name='ref'><template><target>cite book</target><arg name="last"><space/>Ottoboni<space/></arg><arg name="first"><space/>M. Alice 
</arg><arg name="title"><space/>The dose makes the poison : a plain-language guide to toxicology 
</arg><arg name="publisher"><space/>Van Nostrand Reinhold<space/></arg><arg name="location"><space/>New York, N.Y 
</arg><arg name="year"><space/>1991<space/></arg><arg name="isbn"><space/>0442006608<space/></arg><arg name="edition"><space/>2nd<space/></arg></template></extension><space/>Balancingthe constraints are views from the medical field.<extension extension_name='ref'><template><target>cite book</target><arg name="last"><space/>Glantz<space/></arg><arg name="first"><space/>Stanton A.
</arg><arg name="title"><space/>Primer of biostatistics<space/></arg><arg name="edition"><space/>3rd<space/></arg><arg name="year"><space/>1992
</arg><arg name="isbn"><space/>0-07-023511-2<space/></arg></template></extension><space/>Regarding the randomization of patients, &quot;... if no one knows which therapy is better, there is no ethical imperative to use one therapy or another.&quot; (p 380) Regarding experimental design, &quot;...it is clearly not ethical to place subjects at risk to collect data in a poorly designed study when this situation can be easily avoided...&quot;. (p 393)</paragraph><heading level='2'>See also</heading><paragraph><template><target>Portal</target><arg>Statistics</arg></template><template><target>div col</target><arg>2</arg></template></paragraph><list type='bullet'><listitem><link><target>Adversarial collaboration</target></link></listitem><listitem><link><target>Bayesian experimental design</target></link></listitem><listitem><link><target>Clinical trial</target></link></listitem><listitem><link><target>Computer experiment</target></link></listitem><listitem><link><target>Control variable</target></link></listitem><listitem><link><target>Controlling for a variable</target></link></listitem><listitem><link><target>Experimetrics</target></link><space/>(<link><target>econometrics</target></link>-related experiments)</listitem><listitem><link><target>Factor analysis</target></link></listitem><listitem><link><target>First-in-man study</target></link></listitem><listitem><link><target>Glossary of experimental design</target></link></listitem><listitem><link><target>Grey box model</target></link></listitem><listitem><link><target>Instrument effect</target></link></listitem><listitem><link><target>Law of large numbers</target></link></listitem><listitem><link><target>Manipulation checks</target></link></listitem><listitem><link><target>Multifactor design of experiments software</target></link></listitem><listitem><link><target>Probabilistic design</target></link></listitem><listitem><link><target>Protocol (natural sciences)</target></link></listitem><listitem><link><target>Quasi-experimental design</target></link></listitem><listitem><link><target>Randomized block design</target></link></listitem><listitem><link><target>Randomized controlled trial</target></link></listitem><listitem><link><target>Research design</target></link></listitem><listitem><link><target>Robust parameter design (RPD)</target><part>Robust parameter design</part></link></listitem><listitem><link><target>PlackettBurman design#Supersaturated designs</target><part>Supersaturated</part></link><space/>design</listitem><listitem><link><target>Survey sampling</target></link></listitem><listitem><link><target>System identification</target></link></listitem><listitem><link><target>Taguchi methods</target></link></listitem></list><paragraph><template><target>div col end</target></template></paragraph><heading level='2'>Notes</heading><paragraph><template><target>Reflist</target><arg>30em</arg></template></paragraph><heading level='2'>References</heading><list type='bullet'><listitem><link><target>Charles Sanders Peirce</target><part>Peirce, C. S.</part></link><space/>(18771878), &quot;Illustrations of the Logic of Science&quot; (series),<space/><italics>Popular Science Monthly</italics>, vols. 12-13. Relevant individual papers:<list type='bullet'><listitem>(1878 March), &quot;The Doctrine of Chances&quot;,<space/><italics>Popular Science Monthly</italics>, v. 12, March issue, pp.<space/><link type='external' href='https://books.google.com/books?id=ZKMVAAAAYAAJ&amp;amp;jtp=604'>604</link>615.<space/><italics>Internet Archive</italics><space/><link type='external' href='https://archive.org/stream/popscimonthly12yoummiss#page/612/mode/1up'>Eprint</link>.</listitem><listitem>(1878 April), &quot;The Probability of Induction&quot;,<space/><italics>Popular Science Monthly</italics>, v. 12, pp.<space/><link type='external' href='https://books.google.com/books?id=ZKMVAAAAYAAJ&amp;amp;jtp=705'>705</link>718.<space/><italics>Internet Archive</italics><space/><link type='external' href='https://archive.org/stream/popscimonthly12yoummiss#page/715/mode/1up'>Eprint</link>.</listitem><listitem>(1878 June), &quot;The Order of Nature&quot;,<space/><italics>Popular Science Monthly</italics>, v. 13, pp.<space/><link type='external' href='https://books.google.com/books?id=u8sWAQAAIAAJ&amp;amp;jtp=203'>203</link>217.<italics>Internet Archive</italics><space/><link type='external' href='https://archive.org/stream/popularsciencemo13newy#page/203/mode/1up'>Eprint</link>.</listitem><listitem>(1878 August), &quot;Deduction, Induction, and Hypothesis&quot;,<space/><italics>Popular Science Monthly</italics>, v. 13, pp.<space/><link type='external' href='https://books.google.com/books?id=u8sWAQAAIAAJ&amp;amp;jtp=470'>470</link>482.<space/><italics>Internet Archive</italics><space/><link type='external' href='https://archive.org/stream/popularsciencemo13newy#page/470/mode/1up'>Eprint</link>.</listitem></list></listitem><listitem><link><target>Charles Sanders Peirce</target><part>Peirce, C. S.</part></link><space/>(1883), &quot;A Theory of Probable Inference&quot;,<space/><italics>Studies in Logic</italics>, pp.<space/><link type='external' href='https://books.google.com/books?id=V7oIAAAAQAAJ&amp;amp;pg=PA126'>126-181</link>, Little, Brown, and Company. (Reprinted 1983, John Benjamins Publishing Company, ISBN 90-272-3271-7)</listitem></list><heading level='2'>Further reading</heading><paragraph><template><target>further cleanup</target><arg name="date">November 2014</arg></template></paragraph><list type='bullet'><listitem><template><target>Cite book</target><arg name="author">[http://stats.lse.ac.uk/atkinson/ Atkinson, A. C.] and [http://www.maths.manchester.ac.uk/~adonev/ Donev, A. N.] and [http://support.sas.com/publishing/bbu/companion_site/index_author.html#tobias Tobias, R. D.]</arg><arg name="title">Optimum Experimental Designs, with SAS<space/></arg><arg name="url">http://books.google.se/books?id</arg><arg name="publisher">[http://www.us.oup.com/us/catalog/general/subject/Mathematics/ProbabilityStatistics/~~/dmlldz11c2EmY2k9OTc4MDE5OTI5NjYwNg</arg><arg name="year">2007<space/></arg><arg name="pages">511+xvi<space/></arg><arg name="isbn">978-0-19-929660-6<space/></arg><arg name="doi"></arg></template></listitem><listitem><template><target>Cite book</target><arg name="authorlink">Rosemary A. Bailey</arg><arg name="first">R.A.</arg><arg name="last">Bailey</arg><arg name="title">Design of Comparative Experiments</arg><arg name="publisher">Cambridge University Press</arg><arg name="year">2008<space/></arg><arg name="isbn">978-0-521-68357-9</arg><arg name="url">http://www.maths.qmul.ac.uk/~rab/DOEbook</arg></template><space/>Pre-publication chapters are available on-line.</listitem><listitem>Box, G. E. P., &amp; Draper, N. R. (1987).<space/><italics>Empirical model-building and response surfaces</italics>. New York: Wiley.</listitem><listitem><link><target>George E. P. Box</target><part>Box, G. E.</part></link>, Hunter,W.G., Hunter, J.S., Hunter,W.G., &quot;Statistics for Experimenters: Design, Innovation, and Discovery&quot;, 2nd Edition, Wiley, 2005, ISBN 0-471-71813-0</listitem><listitem><template><target>Cite book</target><arg name="author">Caliński, Tadeusz and Kageyama, Sanpei
</arg><arg name="title">Block designs: A Randomization approach, Volume '''I''': Analysis
</arg><arg name="series">Lecture Notes in Statistics
</arg><arg name="volume">150
</arg><arg name="publisher">Springer-Verlag
</arg><arg name="location">New York
</arg><arg name="year">2000
</arg><arg name="isbn">0-387-98578-6
</arg></template></listitem><listitem><template><target>cite book</target><arg name="author">[[George Casella]]
</arg><arg name="year">2008
</arg><arg name="title">Statistical design
</arg><arg name="url">http://www.springer.com/statistics/statistical+theory+and+methods/book/978-0-387-75964-7
</arg><arg name="publisher">[[Springer Science+Business Media|Springer]]
</arg><arg name="isbn">978-0-387-75965-4<space/></arg></template></listitem><listitem><template><target>Cite book</target><arg name="title">Design and Analysis of Experiments<space/></arg><arg name="series">Handbook of Statistics</arg><arg name="volume">13</arg><arg name="editor">Ghosh, S. and [[Calyampudi Radhakrishna Rao|Rao, C. R.]]<space/></arg><arg name="publisher">North-Holland</arg><arg name="year">1996</arg><arg name="isbn">0-444-82061-2</arg></template></listitem><listitem><template><target>Cite book</target><arg name="author">Goos, Peter and Jones, Bradley 
</arg><arg name="year">2011
</arg><arg name="url">http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470744618.html</arg><arg name="title"><space/>Optimal Design of Experiments: A Case Study Approach 
</arg><arg name="publisher">Wiley
</arg><arg name="isbn">978-0-470-74461-1</arg></template></listitem><listitem><template><target>cite journal</target><arg name="first">Ian<space/></arg><arg name="last">Hacking</arg><arg name="authorlink">Ian Hacking<space/></arg><arg name="title">Telepathy: Origins of Randomization in Experimental Design</arg><arg name="journal">[[Isis (journal)|Isis]]</arg><arg name="issue">3</arg><arg name="volume">79</arg><arg name="date">September 1988<space/></arg><arg name="pages">427–451</arg><arg name="jstor">234674<space/></arg><arg name="mr">1013489</arg><arg name="doi">10.1086/354775</arg></template></listitem><listitem><template><target>Cite book</target><arg name="author">Hinkelmann, Klaus and [[Oscar Kempthorne|Kempthorne, Oscar]]
</arg><arg name="year">2008
</arg><arg name="title">Design and Analysis of Experiments
</arg><arg name="volume">I and II
</arg><arg name="edition">Second
</arg><arg name="publisher">[http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470385510.html Wiley]
</arg><arg name="isbn">978-0-470-38551-7</arg></template><list type='bullet'><listitem><template><target>Cite book</target><arg name="author">Hinkelmann, Klaus and [[Oscar Kempthorne|Kempthorne, Oscar]]
</arg><arg name="year">2008
</arg><arg name="title">Design and Analysis of Experiments, Volume I: Introduction to Experimental Design
</arg><arg name="url">https://books.google.com/?id</arg><arg name="edition">Second
</arg><arg name="publisher">[http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0471727563.html Wiley]
</arg><arg name="isbn">978-0-471-72756-9
</arg></template></listitem><listitem><template><target>Cite book</target><arg name="author">Hinkelmann, Klaus and [[Oscar Kempthorne|Kempthorne, Oscar]]
</arg><arg name="year">2005
</arg><arg name="title">Design and Analysis of Experiments, Volume 2: Advanced Experimental Design
</arg><arg name="url">https://books.google.com/books?id</arg><arg name="edition">First
</arg><arg name="publisher">[http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0471551775.html Wiley]
</arg><arg name="isbn">978-0-471-55177-5
</arg></template></listitem></list></listitem><listitem>Mason, R. L., Gunst, R. F., &amp; Hess, J. L. (1989).<space/><italics>Statistical design and analysis of experiments with applications to engineering and science</italics>. New York: Wiley.</listitem><listitem><link><target>Judea Pearl</target><part>Pearl, Judea</part></link>.<space/><italics>Causality: Models, Reasoning and Inference</italics>, Cambridge University Press, 2000.</listitem><listitem><link><target>Charles Sanders Peirce</target><part>Peirce, C. S.</part></link><space/>(1876), &quot;Note on the Theory of the Economy of Research&quot;, Appendix No. 14 in<space/><italics>Coast Survey Report</italics>, pp.&amp;nbsp;197201,<space/><link type='external' href='http://docs.lib.noaa.gov/rescue/cgs/001_pdf/CSC-0025.PDF#page=222'>NOAA PDF Eprint</link>. Reprinted 1958 in<space/><italics>Collected Papers of Charles Sanders Peirce</italics><space/><bold>7</bold>, paragraphs 139157 and in 1967 in<space/><italics><link type='external' href='http://or.journal.informs.org/cgi/content/abstract/15/4/643'>Operations Research</link></italics><space/><bold>15</bold><space/>(4): pp.&amp;nbsp;643648,<space/><link type='external' href='http://www.jstor.org/stable/168276'>abstract at JSTOR</link>.<space/><template><target>cite journal</target><arg name="doi">10.1287/opre.15.4.643</arg><arg name="title">Note on the Theory of the Economy of Research</arg><arg name="year">1967</arg><arg name="last1">Peirce</arg><arg name="first1">C. S.</arg><arg name="journal">Operations Research</arg><arg name="volume">15</arg><arg name="issue">4</arg><arg name="pages">643</arg></template></listitem><listitem><template><target>cite journal</target><arg name="author">Smith, Kirstine
</arg><arg name="title">On the Standard Deviations of Adjusted and Interpolated Values of an Observed Polynomial Function and its Constants and the Guidance They Give Towards a Proper Choice of the Distribution of the Observations</arg><arg name="year">1918
</arg><arg name="journal">[[Biometrika]]
</arg><arg name="volume">12
</arg><arg name="pages">1&ndash;85
</arg><arg name="issue">1
</arg><arg name="doi">10.2307/2331929 
</arg></template></listitem><listitem>Taguchi, G. (1987).<space/><italics>Jikken keikakuho</italics><space/>(3rd ed., Vol I &amp; II). Tokyo: Maruzen. English translation edited by D. Clausing.<space/><italics>System of experimental design</italics>. New York: UNIPUB/Kraus International.</listitem></list><heading level='2'>External links</heading><paragraph><template><target>Library resources box</target><arg name="by">no 
</arg><arg name="onlinebooks">no 
</arg><arg name="others">no 
</arg><arg name="about">yes 
</arg><arg name="label">Experimental design</arg></template></paragraph><list type='bullet'><listitem>A<space/><link type='external' href='http://www.itl.nist.gov/div898/handbook/pri/section1/pri1.htm'>chapter</link><space/>from a<space/><link type='external' href='http://www.itl.nist.gov/div898/handbook/'>&quot;NIST/SEMATECH Handbook on Engineering Statistics&quot;</link><space/>at<space/><link><target>National Institute of Standards and Technology</target><part>NIST</part></link></listitem><listitem><link type='external' href='http://www.itl.nist.gov/div898/handbook/pri/section3/pri3362.htm'>BoxBehnken designs</link><space/>from a<space/><link type='external' href='http://www.itl.nist.gov/div898/handbook/'>&quot;NIST/SEMATECH Handbook on Engineering Statistics&quot;</link><space/>at<space/><link><target>National Institute of Standards and Technology</target><part>NIST</part></link></listitem><listitem><link type='external' href='http://www.curiouscat.net/library/designofexperiments.cfm'>Articles on Design of Experiments</link></listitem><listitem><link type='external' href='http://www.statease.com/articles.html'>Case Studies and Articles on Design of Experiments (DOE)</link></listitem><listitem><link type='external' href='http://www.questia.com/googleScholar.qst?docId=5001888588'>Czitrom (1999) &quot;One-Factor-at-a-Time Versus Designed Experiments&quot;, American Statistician, 53, 2.</link></listitem><listitem><link type='external' href='http://www.iasri.res.in/design'>Design Resources Server</link><space/>a mobile library on Design of Experiments. The server is dynamic in nature and new additions would be posted on this site from time to time.</listitem><listitem><link type='external' href='http://www.research.att.com/~njas/gosset/index.html'>Gosset: A General-Purpose Program for Designing Experiments</link></listitem><listitem><link type='external' href='http://www.wright.edu/~dvoss/book/DeanVoss.html'>SAS Examples for Experimental Design</link></listitem><listitem><link type='external' href='http://sumowiki.intec.ugent.be'>Matlab '''SU'''rrogate '''MO'''deling Toolbox - SUMO Toolbox</link><space/><link><target>MATLAB</target></link><space/>code for Design of Experiments + Sequential Design + Surrogate Modeling</listitem><listitem><link type='external' href='http://web.cs.dal.ca/~peter/designdb/'>Design DB</link>: A database of combinatorial, statistical, experimental block designs</listitem><listitem><link type='external' href='http://obdoe.com/student/DOEResources/Assistant/assistantintro.php'>The I-Optimal Design Assistant</link>: a free on-line library of I-Optimal designs</listitem><listitem><link type='external' href='http://norvig.com/experiment-design.html'>Warning Signs in Experimental Design and Interpretation</link><space/>by Peter Norvig, chief of research at Google</listitem><listitem><link type='external' href='http://www.socialresearchmethods.net/kb/desexper.php'>Knowledge Base, Research Methods</link>: A good explanation of the basic idea of experimental designs</listitem><listitem><link type='external' href='http://www.juliantrubin.com/fairguide/scientificmethod.html'>The Controlled Experiment vs. The Comparative Experiment</link>: &quot;How to experiment&quot; for science fair projects</listitem><listitem><link type='external' href='http://dx.doi.org/10.1109/MCS.2010.937677'>Spall, J. C. (2010), &quot;Factorial Design for Choosing Input Values in Experimentation: Generating Informative Data for System Identification,&quot; IEEE Control Systems Magazine, vol. 30(5), pp. 3853.</link><space/>General introduction from a systems perspective</listitem><listitem><link type='external' href='http://www.etas.com/en/products/ascmo.php'>DOE used for engine calibration reduces fuel consumption by 2 to 4 percent</link></listitem><listitem><link type='external' href='https://itunes.apple.com/us/app/zheng-jiao-she-ji-zhu-shou/id1039211022?l=zh&amp;amp;ls=1&amp;amp;mt=8'>A Orthogonal Experiment Design Application for iPad</link></listitem></list><paragraph><template><target>Experimental design</target><arg name="state">collapsed</arg></template><template><target>Design</target></template><template><target>Statistics</target><arg>collection</arg><arg name="state">collapsed</arg></template><template><target>Medical research studies</target><arg name="state">collapsed</arg></template></paragraph><paragraph><template><target>Authority control</target></template></paragraph><paragraph><template><target>DEFAULTSORT:Design Of Experiments</target></template><link><target>Category:Design of experiments</target></link><link><target>Category:Statistical methods</target></link><link><target>Category:Statistical theory</target></link><link><target>Category:Industrial engineering</target></link><link><target>Category:Systems engineering</target></link><link><target>Category:Quality control</target></link><link><target>Category:Quality</target></link><link><target>Category:Quantitative research</target></link><link><target>Category:Engineering statistics</target></link><link><target>Category:Experiments</target></link></paragraph></article>